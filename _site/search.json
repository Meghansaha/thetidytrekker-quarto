[
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "The Tidy Trekker",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nPlease Let Me Merge Before I Start Crying: And Other Things Iâ€™ve Said At The Git Terminal\n\n\nâ€˜Please Let Me Mergeâ€™ is geared towards those who may feel comfortable working independently with Git but need some confidence when working collaborativelyâ€¦.\n\n\n\n\n\nAug 13, 2024\n\n\nPosit::conf(2024)\n\n\n\n\n\n\n\n\n\n\n\n\nItâ€™s All About Perspective: Making A Case for Generative Art\n\n\nâ€œItâ€™s All About Perspectiveâ€ is a retrospective journey that aims to invite participants to learn about generative art while focusing on â€œwhyâ€ people should create it and its potential place in Data Science â€¦\n\n\n\n\n\nSep 20, 2023\n\n\nPosit::conf(2023)\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Data Validation With The pointblank Package\n\n\nData validation is a very important component that should not be ignored when working in data analytics or data science. While there are many ways to perform data validation in R, this talk will explore Rich Iannone and Mauricio Vargasâ€™ pointblank package for this purpose.\n\n\n\n\n\nOct 26, 2022\n\n\nCleveland R User Group\n\n\n\n\n\n\n\n\n\n\n\n\nCollages and Patterns: Making Art in R\n\n\nHave you just started creating generative art in R, or are you interested in starting? Have you tried to start the process but couldnâ€™t wrap your head around how to do it? If so, â€œCollages and Patterns: Making art in Râ€, might be of interest!\n\n\n\n\n\nOct 12, 2022\n\n\nR-Ladies Philly\n\n\n\n\n\n\n\n\n\n\n\n\nMaking Data Pipelines in R: A Story from a Self-Taught Perspective\n\n\nWhen people first learn about Râ€™s capabilities to create fully integrated systems, automated visuals, and seamless data pipelines, the reaction can span from disbelief to amazementâ€¦\n\n\n\n\n\nJul 27, 2022\n\n\nRStudio::conf(2022)\n\n\n\n\n\n\n\n\n\n\n\n\nMaking Functions For Rtistry\n\n\nThe Functions in Rtistry workshop will dive into using functions to create, add variation to, and streamline generative art pieces made in the R languageâ€¦\n\n\n\n\n\nMay 24, 2022\n\n\nR-Ladies Johannesburg\n\n\n\n\n\n\n\n\n\n\n\n\nAn Introduction to Rtistry Using ggplot2 in R\n\n\nIf youâ€™ve ever seen pictures of generative art made in R and wondered if you could ever create art like that, the answer is â€œYes.â€â€¦\n\n\n\n\n\nJan 13, 2022\n\n\nTunis R User Group\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/pipelines_in_r/pipeline_in_r.html#description",
    "href": "talks/pipelines_in_r/pipeline_in_r.html#description",
    "title": "Making Data Pipelines in R: A Story from a Self-Taught Perspective",
    "section": "Description",
    "text": "Description\n\nRâ€™s expansive capabilities can leave some feeling overwhelmed when tasked with larger projects like data pipelines. This talk invites the participant to hear the perspective of a self-taught R user who used curiosity and patience to create a functional data pipeline in R for a local health department. Specifically, this talk will touch on the following concepts:\n\n\nSurveying Data Landscapes\nFile Structures\nSaving Yourself with Data Validation\nModularizing Code and Connecting R Scripts\nThinking about Pipeline Sustainability\nRemaining Calm in Unfamiliar R Territoriesâ€"
  },
  {
    "objectID": "talks/pipelines_in_r/pipeline_in_r.html#slides",
    "href": "talks/pipelines_in_r/pipeline_in_r.html#slides",
    "title": "Making Data Pipelines in R: A Story from a Self-Taught Perspective",
    "section": "Slides",
    "text": "Slides\nThe slides for the presentation is available on GitHub here."
  },
  {
    "objectID": "talks/pipelines_in_r/pipeline_in_r.html#recorded-presentation",
    "href": "talks/pipelines_in_r/pipeline_in_r.html#recorded-presentation",
    "title": "Making Data Pipelines in R: A Story from a Self-Taught Perspective",
    "section": "Recorded Presentation",
    "text": "Recorded Presentation\nThis presentation was recorded and is now accessible on the RStudio::conf(2022) website here"
  },
  {
    "objectID": "talks/pipelines_in_r/pipeline_in_r.html#talk-materials-and-github-repository",
    "href": "talks/pipelines_in_r/pipeline_in_r.html#talk-materials-and-github-repository",
    "title": "Making Data Pipelines in R: A Story from a Self-Taught Perspective",
    "section": "Talk Materials and GitHub Repository",
    "text": "Talk Materials and GitHub Repository\nThis talk has a supplemental GitHub repository that can be accessed here"
  },
  {
    "objectID": "talks/intro_to_rtistry/intro_to_rtistry.html#description",
    "href": "talks/intro_to_rtistry/intro_to_rtistry.html#description",
    "title": "An Introduction to Rtistry Using ggplot2 in R",
    "section": "Description",
    "text": "Description\n\nIn this introductory presentation, we will briefly go over the basics of creating generative art in R (Rtistry) using the ggplot2 package. This presentation will go over the common geoms (geometries), aesthetics, layering, and functions that can be used for Rtistry creation. The presentation will conclude with a live code review session of one Rtistry pieces. Full annotated code will be shared with participants for further practice and use."
  },
  {
    "objectID": "talks/intro_to_rtistry/intro_to_rtistry.html#slides",
    "href": "talks/intro_to_rtistry/intro_to_rtistry.html#slides",
    "title": "An Introduction to Rtistry Using ggplot2 in R",
    "section": "Slides",
    "text": "Slides\nThe slides for the presentation is available in a PDF format here."
  },
  {
    "objectID": "talks/intro_to_rtistry/intro_to_rtistry.html#recorded-presentation",
    "href": "talks/intro_to_rtistry/intro_to_rtistry.html#recorded-presentation",
    "title": "An Introduction to Rtistry Using ggplot2 in R",
    "section": "Recorded Presentation",
    "text": "Recorded Presentation\nThe recorded presentation for this talk is available on YouTube here."
  },
  {
    "objectID": "talks/intro_to_rtistry/intro_to_rtistry.html#github-repository-with-example-code",
    "href": "talks/intro_to_rtistry/intro_to_rtistry.html#github-repository-with-example-code",
    "title": "An Introduction to Rtistry Using ggplot2 in R",
    "section": "GitHub Repository with Example Code",
    "text": "GitHub Repository with Example Code\nThe example R script for the live-coded piece for this talk is available on GitHub here."
  },
  {
    "objectID": "talks/exploring_validation/exploring_validation.html#description",
    "href": "talks/exploring_validation/exploring_validation.html#description",
    "title": "Exploring Data Validation With The pointblank Package",
    "section": "Description",
    "text": "Description\n\nThis talk will provide information on what data validation is, why itâ€™s important, and how R users can begin using the pointblank package to validate their own data in R. Participants can read more about the pointblank package here"
  },
  {
    "objectID": "talks/exploring_validation/exploring_validation.html#slides",
    "href": "talks/exploring_validation/exploring_validation.html#slides",
    "title": "Exploring Data Validation With The pointblank Package",
    "section": "Slides",
    "text": "Slides\nThe slides for the presentation is available on GitHub here."
  },
  {
    "objectID": "talks/exploring_validation/exploring_validation.html#recorded-presentation",
    "href": "talks/exploring_validation/exploring_validation.html#recorded-presentation",
    "title": "Exploring Data Validation With The pointblank Package",
    "section": "Recorded Presentation",
    "text": "Recorded Presentation\nThis presentation was recorded and is now accessible on YouTube here"
  },
  {
    "objectID": "talks/exploring_validation/exploring_validation.html#talk-materials-and-github-repository",
    "href": "talks/exploring_validation/exploring_validation.html#talk-materials-and-github-repository",
    "title": "Exploring Data Validation With The pointblank Package",
    "section": "Talk Materials and GitHub Repository",
    "text": "Talk Materials and GitHub Repository\nThis talk has a supplemental GitHub repository that can be accessed here"
  },
  {
    "objectID": "rtistry.html",
    "href": "rtistry.html",
    "title": "Rtistry Gallery",
    "section": "",
    "text": "â€œRtistryâ€ is a term that is used to refer to generative art thatâ€™s created by coding in the R programming language. Here youâ€™ll find various Rtistry pieces Iâ€™ve created as I continue to explore and learn how to create aRt. I have publicly shared some code for certain pieces in my Data Art repository on GitHub. If youâ€™re a beginner interested in getting started in Rtistry, you may find my Intro to Data Art blog post helpful.\n\n\n\n\n\n\nâ€˜Be Squaredâ€™\n\n\n\n,\n\n\n\nâ€˜Blue Wavesâ€™\n\n\n\n,\n\n\n\nâ€˜Buildingsâ€™\n\n\n\n,\n\n\n\nâ€˜Candy Ballâ€™\n\n\n\n,\n\n\n\nâ€˜Candy Ropeâ€™\n\n\n\n,\n\n\n\nâ€˜City Limitsâ€™\n\n\n\n,\n\n\n\nâ€˜crossoverâ€™\n\n\n\n,\n\n\n\nâ€˜Eggâ€™\n\n\n\n,\n\n\n\nâ€˜Fall Flowerâ€™\n\n\n\n,\n\n\n\nâ€˜Glass Ballâ€™\n\n\n\n,\n\n\n\nâ€˜Glass Tornadoâ€™\n\n\n\n,\n\n\n\nâ€˜Groovyâ€™\n\n\n\n,\n\n\n\nâ€˜Manic Panicâ€™\n\n\n\n,\n\n\n\nâ€˜Moonscapeâ€™\n\n\n\n,\n\n\n\nâ€˜Mountainsâ€™\n\n\n\n,\n\n\n\nâ€˜Planet Quadâ€™\n\n\n\n,\n\n\n\nâ€˜Polar Waveâ€™\n\n\n\n,\n\n\n\nâ€˜Polycystâ€™\n\n\n\n,\n\n\n\nâ€˜Rainbow Roseâ€™\n\n\n\n,\n\n\n\nâ€˜Red Swirlâ€™\n\n\n\n,\n\n\n\nâ€˜Snazzy Trianglesâ€™\n\n\n\n,\n\n\n\nâ€˜String Ballsâ€™\n\n\n\n,\n\n\n\nâ€˜Swirlâ€™\n\n\n\n,\n\n\n\nâ€˜Treesâ€™\n\n\n\n,\n\n\n\nâ€˜Waterstonesâ€™\n\n\n\n,\n\n\n\nâ€˜Wave Patchâ€™"
  },
  {
    "objectID": "post/vibe-conf-ing/posit_conf_2025.html",
    "href": "post/vibe-conf-ing/posit_conf_2025.html",
    "title": "My First Time Vibe-Confâ€™ing",
    "section": "",
    "text": "Before I recap my experience at posit::conf(2025), letâ€™s talk about â€œvibe confâ€™ingâ€ (Vibe Conf- Ing). I was first introduced to this term by Ted Laderas:\n\n\nI am a person of my word\n\nThis came after I posted that I was going to posit::conf(2025) without participating in workshops, being a TA, or presenting talks. I couldnâ€™t understand why I struggled to just go â€œfor the vibesâ€ â€“ attending without any expectation to â€œgive something in return.â€\nAfter some introspection, it clicked: Iâ€™ve never had the privilege to just go to a conference. No matter where I worked, I always HAD to get a talk accepted to afford the conference ticket that comes with it.\nWhile submitting talks is cost-efficient, thereâ€™s a hidden cost of stress and labor. Last year I did a talk at posit::conf(2024) and promptly got covid for the first time immediately afterwards. As I isolated in my room, missing conf events and Tidy Dev Day, I promised myself Iâ€™d take â€œa breakâ€ next year.\nFast forward to this week: I actually listened to myself. I attended with no talks submitted, no expectations, just good vibes. I donâ€™t know if Iâ€™ll submit next year (I have a backlog of ideas) or just vibe again. For now, let me dive into what this experience was like."
  },
  {
    "objectID": "post/vibe-conf-ing/posit_conf_2025.html#talk-sessions",
    "href": "post/vibe-conf-ing/posit_conf_2025.html#talk-sessions",
    "title": "My First Time Vibe-Confâ€™ing",
    "section": "Talk Sessions",
    "text": "Talk Sessions\nAs Iâ€™ve mentioned, Posit conf is really what you make it. This year, with no obligations, I felt â€œfree to learnâ€ for the first time. Having this freedom solidified something Iâ€™d been noticing: Iâ€™m increasingly drawn to the development side of data work.\nIâ€™ve found myself on a path that may be familiar to some data scientists. Thereâ€™s a subset of us who dip a toe into the â€œDevelopment Pondâ€ â€“ maybe we need to build tools for data processing that dance on the edge of software engineering. Some pull their feet out once theyâ€™ve gotten what they needed, but others realize these skills could transform how we approach data problems entirely.\nItâ€™s an exciting challenge: wanting to deepen these development skills while applying them to the work I already love. This yearâ€™s conf was perfect for me because I was intentional about attending development-focused sessions that could enhance my current toolkit. Here are some talks that stood out:\n(Links are provided to the slides if I can find them!) Check the Posit conf github to see if links are updated in the future:\n\nPositron\n\n\nWhich included:\n\n\nIDE-ntity Crisis: Choosing the Right Tool for Me by Isabel Zimmerman\nTips & tricks from the maintainers of Positron by Sharon Wang and Melissa Barca\nOutgrowing Your Laptop with Positron by Austin Dickey\nExploring Datasets in Positron by Wes Mckinney\n\n\nLightning Talks\n\n\nWhich included:\n\n\nUse Your Data Skills for Good: Ideas for Community Service by Sharon Machalis\nMake Big Geospatial Data Accessible with Arrow by Cari Gostic\nApproaching Positron from RStudio by Mauro Lepore\nBrand YML and Dark Mode in Quarto by Gordon Woodhull\nAutomating Event Scheduling with Python in Positron by Becky Hodge\nPutting an {ellmer} AI in production with the blessing of IT by Andrie de Vries\nEnabling geospatial workflow management with targets: an R package origin story by Eric Scott\nPlotgardener â€“ Genomic Data Visualization Made Easy by Rishabh Sharma Vemuri and Abiye Berhanu\nWhat weâ€™re doing to make Quarto fast(er) by Carlos Scheidegger\nMultiple Console Sessions in Positron by Dhruvi Sompura\nItâ€™s all fun and games til your analysis code is finished: the player package in R by Alex Rossell Hayes\nBirthing the pregnancy package by Ella Kaye\n\n\nSparking Development Joy\n\n\nWhich included:\n\n\nEnemies to lovers: How non-programmers can make sparks fly when using testthat during package development by Libby McKenna\nAir - A blazingly fast R code formatter by Davis Vaughan and Lionel Henry\nMaking Things Nice in Python by Rich Iannone\nThe Curse of Documentation by Michael Chow\n\n\nKeynote: The Psychology of Technologists by Cat Hicks\nStrengthening the R Ecosystem\n\n\nWhich included:\n\n\nPurrrfectly parallel, purrrfectly distributed by Charlie Gao\nR-multiverse: a new way to publish R packages by Will Landau\nPractical {renv} by Shannon Pileggi\nExtending the horizons of R with Rust by AndrÃ©s Quintero\n\n\nFacepalm-driven Development: Learning From AI and Human Errors\n\n\nWhich included:\n\n\nHow I got unstuck with Python by Julia Silge\nHacking Productivity with LLMs: What Works (and What Doesnâ€™t) by Nic Crane\nAI missteps as stepping stones: Opportunities gained when your LLM coding assistant gets it wrong by Ryan Timpe\nFailure (and Mistakes) by Laura Gast\n\n\nMultilingual Data Science\n\n\nWhich included:\n\n\nBuilding Multilingual Data Science Teams by Michael Thomas\nPolyglot Data Science: Why and How to Combine R and Python by Jeroen Janssens\nWhen R Met Python: A Meet Cute on Posit Connect by Blake Abbenante\nR & Python playing nice, in production by Claudia Penaloza"
  },
  {
    "objectID": "post/vibe-conf-ing/posit_conf_2025.html#the-georgia-aquarium",
    "href": "post/vibe-conf-ing/posit_conf_2025.html#the-georgia-aquarium",
    "title": "My First Time Vibe-Confâ€™ing",
    "section": "The Georgia Aquarium",
    "text": "The Georgia Aquarium\nThis was hands-down the BEST social event in conf history (for me). Iâ€™m biased as I love water, but this event was great â€“ and the food was surprisingly good. Posit rented out the Georgia Aquarium for us at night, and I had way more fun than expected. It gave me a chance to talk to people I hadnâ€™t run into at conf yet, and having the run of the place at night was awesome.\n\n\nI had the BEST time at the aquarium"
  },
  {
    "objectID": "post/vibe-conf-ing/posit_conf_2025.html#tidy-dev-day-tdd",
    "href": "post/vibe-conf-ing/posit_conf_2025.html#tidy-dev-day-tdd",
    "title": "My First Time Vibe-Confâ€™ing",
    "section": "Tidy Dev Day (TDD)",
    "text": "Tidy Dev Day (TDD)\nOk yâ€™all. I have a confession: this was my favorite thing about conf HANDS DOWN, even though it technically happened after. As I mentioned, Iâ€™ve been discovering I love development work, and Tidy Dev Day (TDD) gave me the PERFECT opportunity to explore this further in a low-stress, supportive environment.\nThe day started with an ice-breaker bingo sheet, then a group photo, followed by the Posit team explaining the workflow (forking/cloning/PRs, etc.) before turning us loose to work.\nWe could jump right in because the Posit team does reconnaissance beforehand, looking through tidyverse, r-lib, and tidymodels issues good for beginners. They print snippets on post-it notes for the â€œissue wallâ€ where participants choose what to work on. Once you open a PR, you get to ring â€œThe Gongâ€ â€“ and if you open multiple PRs, you ring it multiple times:\n\n\nMy first time ringing â€œThe Gongâ€\n\nBefore everyone really dove in, Hadley reassured everyone by saying something akin to:\n\nâ€œI have written a lot of shitty code. Itâ€™s OK if your code is shitty. Weâ€™re here to learn.â€\nâ€” Hadley Wickham\n\nI have 7+ years of R programming under my belt, so while Iâ€™m confident tackling obscure problems, I admit when my code might be â€œshitty.â€ One example? I constantly struggle to write concisely (my coworkers can confirm Iâ€™m anything but brief). Going into TDD, I tried cutting through brain noise to make my annotations and documentation short and sweetâ€¦ only to be advised to add MORE info in places ğŸ˜…. What I loved was how feedback was delivered â€“ positive or clever contributions were celebrated and corrections came with grace and compassion. This gave me confidence to contribute to tidyverse packages more often, which Iâ€™m making a goal moving forward.\nAs the day progressed, I continued vibing and working, stopping only for provided snacks and lunch. Looking back, I was nervous beforehand about what skills Iâ€™d need to be â€œusefulâ€ to the tidyverse team. I can confidently say that basic GitHub functionality is enough, and if you lack that, they provide virtual â€œoffice hoursâ€ before TDD to get you ready. For direct function work, knowing how to debug is super helpful â€“ Shannon Pileggi has workshops on this here.\nBy dayâ€™s end, I opened 4 PRs with 2 accepted and merged so far for ggplot2, dplyr, purrr, and cli â€“ all packages I use frequently for my artpack development.\n\n\nMy Tidy Dev Day Badge"
  },
  {
    "objectID": "post/tallying-checkbox-survey-responses-r-walkthrough/tallying-checkbox-survey-responses-r-walkthrough.html",
    "href": "post/tallying-checkbox-survey-responses-r-walkthrough/tallying-checkbox-survey-responses-r-walkthrough.html",
    "title": "Tallying â€œCheckboxâ€ Survey Responses: R Walkthrough",
    "section": "",
    "text": "The Problem: You need to tally (add) checkbox survey responses, but they are combined and comma-separated together in one string.\nThe Fix: You need to count the occurrences of each response within each observationâ€™s string. You can do this in a few lines with tidyr and dplyr, or in a more involved way while practicing string manipulation with regex/grepl and stringr."
  },
  {
    "objectID": "post/tallying-checkbox-survey-responses-r-walkthrough/tallying-checkbox-survey-responses-r-walkthrough.html#the-example",
    "href": "post/tallying-checkbox-survey-responses-r-walkthrough/tallying-checkbox-survey-responses-r-walkthrough.html#the-example",
    "title": "Tallying â€œCheckboxâ€ Survey Responses: R Walkthrough",
    "section": "The Example:",
    "text": "The Example:\nLetâ€™s say we have a simple survey question that asks participants to select colors that they like. We allow them to â€œCheck all that applyâ€ and give them eight choices to choose from. It might look like this:\n\n\n\n\n\nâ€œA snapshot of example checkbox survey questionsâ€\n\n\n\n\n\nCheckbox question-types allow participants to select multiple choices. This can be useful for building strong analyses. However, we may find that the â€œcheckboxâ€ question-type produces undesirable data that will have to be dealt with. Letâ€™s explore this by setting up our R session.\nIf youâ€™d like to follow along within the R project files you can download them from the Tidy Trekker Github Repository. Be sure to fully extract the ZIP. folders for proper access. You can also download the data set used and load it into your own session for practice.\n\n\n\nDirect download link for this postâ€™s example data"
  },
  {
    "objectID": "post/tallying-checkbox-survey-responses-r-walkthrough/tallying-checkbox-survey-responses-r-walkthrough.html#using-separate_rows-from-tidyr-and-count-from-dplyr",
    "href": "post/tallying-checkbox-survey-responses-r-walkthrough/tallying-checkbox-survey-responses-r-walkthrough.html#using-separate_rows-from-tidyr-and-count-from-dplyr",
    "title": "Tallying â€œCheckboxâ€ Survey Responses: R Walkthrough",
    "section": "Using â€œseparate_rowsâ€ from Tidyr and â€œcountâ€ from Dplyr:",
    "text": "Using â€œseparate_rowsâ€ from Tidyr and â€œcountâ€ from Dplyr:\nThe simplest and fastest way to tally up these results is to use tidyr and dplyr together. We start by loading in the packages we need: readr, dplyr, and tidyr. These allow us to get our data into the environment and prepare it for cleaning and manipulation. Weâ€™ll name the resulting data set â€œColors.â€\n\n\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\nColors &lt;- read_csv(\"Data/Colors.csv\", col_types = cols(`What colors do you like?` = col_character()))\n\n\n\n Pay attention to the file path in the â€œread_csvâ€ function. If you copy and paste that command and are not using the project files within the Github link above, you will get an error!\n\n\nWe can see our data set in the data viewer. Notice that each observation has a combined, comma-separated string for each response:\n\n\n\n\n\n\nâ€œA snapshot of example checkbox survey question loaded into a dataframeâ€\n\n\n\n\n\nWe need to tell R to separate the values in the What colors do you like? column into individual rows and then count and tally those occurrences. Letâ€™s do this and store it in a data set called TidyrColors. The code for this can be written in one chunk with the following:\n\n\nTidyrColors &lt;- Colors %&gt;%\n  separate_rows(`What colors do you like?`, sep = \", \") %&gt;%\n  count(`What colors do you like?`, sort = TRUE, name = \"Tally\")\n\nThe separate_rows() function from tidyr separates all the values in the column while using â€œ,â€ as the characters to separate on. Note that we have a whitespace after the comma in the sep= option. This is because whitespaces are present in the original data. If you had options that were only separated by commas and no spaces, you would just need a comma there.\nNext, we used the count() function from dplyr to count the occurrences of our colors. Setting the sort= option to TRUE will arrange the observations in descending order in the dataset. The name= option will allow us to set the column name that will hold the count of the values. In this case, weâ€™ve set it to Tally.\n\n\n\n\n\n\nâ€œA snapshot of example checkbox survey results separated and tallied togetherâ€\n\n\n\n\n\nAnd thatâ€™s it! Pretty simple and straightforward. Continue on for more involved ways to do this that will give you some string/regex practice if interested!"
  },
  {
    "objectID": "post/tallying-checkbox-survey-responses-r-walkthrough/tallying-checkbox-survey-responses-r-walkthrough.html#using-grepl-or-stringr-dplyr-and-tidyr",
    "href": "post/tallying-checkbox-survey-responses-r-walkthrough/tallying-checkbox-survey-responses-r-walkthrough.html#using-grepl-or-stringr-dplyr-and-tidyr",
    "title": "Tallying â€œCheckboxâ€ Survey Responses: R Walkthrough",
    "section": "Using Grepl (or Stringr), Dplyr, and Tidyr:",
    "text": "Using Grepl (or Stringr), Dplyr, and Tidyr:\nThere are other ways we can do this that are a bit more involved, but can provide some grepl/regex and string manipulation practice if desired. If you choose to use Stringr instead of grepl, you can load in the stringr package as well.\n\n\n# If using the stringr package===\nlibrary(stringr)\n\n\nIn order to get a tally of the individual responses, we need to break up these strings and create variables for each color. We do this by creating a new column for each of our color options available for our survey question. Letâ€™s create a reference vector of all of our color options to help us. Weâ€™ll name it Colorref:\n\n\nColorref &lt;- c(\"Red\",\"Blue\",\"Green\",\"Yellow\",\"Black\",\"Orange\",\n\"Brown\",\"Pink\")\n\n\n\n Pay attention to the strings you enter into your reference vector. These strings need to match your survey responses/options PERFECTLY. Be mindful of any discrepancies in capitalization, spelling, spaces, or punctuations.\n\n\nUsing the reference vector we just created, we can now create an empty data frame that we can populate with our color tallies. Weâ€™ll call it Colorsnew. We can use base functions in R to do this. To ensure the tallies are properly recorded in the new data frame, weâ€™ll set the number of columns to match the number of options (Colors) we have and the number of rows to match the number of observations (or rows) we have in the original data set. Afterwards, we replace the column names with the name of each color choice. This can be done with the names function.\n\n\nColorsnew &lt;- as.data.frame(matrix(ncol = length(Colorref), nrow = nrow(Colors)))\nnames(Colorsnew) &lt;- Colorref\n\n\nThe next step is to simultaneously populate all the columns in the data set with an accurate tally for each response. We can do this with the ifelse and grepl functions within one single â€œfor-loop.â€ This will populate our currently empty Colorsnew data set so we can easily see our changes. The for-loop function will run iterations along the length of the Colorref vector and use the vectorâ€™s values to fill in the column names of our data. At the same time weâ€™ll be getting getting a count of how often each color is present in the original Colors dataset with the grepl function. Detailed information about for-loops can be found in the Iteration chapter in the free textbook R for Data Science (written by Hadley Wickham and Garrett Grolemund) :\n\n\nfor (i in seq_along(Colorref)){\n  Colorsnew[i] = ifelse(grepl(Colorref[i],Colors$`What colors do you like?`),1,0)}\n\n\nTo reiterate, this code uses the i variable as a placeholder to rename the columns within the Colorsnew data set with the strings found in Colorref (All of our color options.) For each column, we are using an ifelse() test to scan the original strings in the What colors do you like column from the Colors data set (Colors$What colors do you like?). Simultaneously, we check for matches using the grepl function. If you arenâ€™t a fan of using grepl, you can also opt for Stringrâ€™s str_detect() function that performs the same action.\n\n\nfor (i in seq_along(Colorref)){\n  Colorsnew[i] = ifelse(str_detect(Colors$`What colors do you like?`,Colorref[i]),1,0)}\n\nWhether you use grepl or stringr, the result will be the same. Each match will produce a â€œ1â€ while non-matches produce a â€œ0.â€ The result is a matrix of observations for all of our color choices:\n\n\n\n\n\n\nâ€œA snapshot of example checkbox survey results separatedâ€\n\n\n\n\n\nOur last step will be to transpose this wide data into a long data format for easier graphing and analyses. (You can check out a tutorial on wide and long data in R from DataCamp here.) We do this using the pivot_longer, group_by, and summarise functions from the dplyr and tidyr packages. In our pivot_longer function, we tell R we want to transpose all of the columns in the â€œColorsnewâ€ dataset with dplyrâ€™s everything() option. We tell R that we want all of our current column names to be put into one variable called Color and that we want the values in these columns to be put into its own column called Tally. Finally, we want to group the data set observations by the â€œColorâ€ column and add all of the tallies up so we get a sum for each value within the Tally column. This will produce a data frame with a complete tabulation of all the color choices that were picked in our survey.\n\n\nColorsnew &lt;- Colorsnew %&gt;% \n  pivot_longer(everything(),\n  names_to = \"Color\", \n  values_to = \"Tally\") %&gt;%\n  group_by(Color) %&gt;%\n  summarise(Tally = sum(Tally))\n\n\n\n\n\n\n\nâ€œA snapshot of example checkbox survey results separated and tallied togetherâ€\n\n\n\n\n\nHave any thoughts or suggestions? Know of a better solution or way to make this process more efficient? Feel free to contact me directly! Respectful discourse towards efficient solutions or new insights is always welcomed!"
  },
  {
    "objectID": "post/orderingmonths/ordering-months.html",
    "href": "post/orderingmonths/ordering-months.html",
    "title": "Ordering Months",
    "section": "",
    "text": "The Problems: 1) You need to order your â€œMonthâ€ categories chronologically on a ggplot but they keep plotting alphabetically.\n2) You donâ€™t have data for all 12 months of the year, but want to have every month of the year plotted on your graph.\nThe First Example:\nHere we have simple aggregated data for total new patients enrolled in a clinic during the year. The dataset might look like this:\n\n\n\n\nThe â€œPatientsâ€ Example Data\n\n\n\nFor those of you who are just starting out in ggplot and have managed to plot your first graphs, you may have realized that ggplot doesnâ€™t always display your categorical data as you see it in your view pane. Often times, ggplot will plot categorical variables in alphabetical order. This happens because the categorical variable you are trying to graph (â€œMonthâ€) is not set as an ordered factor. In R, factors are categorical variables that have values assigned to them. To learn a bit more about factors, I highly recommend referring to chapter 15 (Factors) in Wickham and Grolemundâ€™s book R For Data Science.\nIf youâ€™d like to follow along within the R project files you can download them from the Tidy Trekker Github Repository. Be sure to fully extract the ZIP. folders for proper access. You can also download the data set used and load it into your own session for practice by clicking the GitHub button below:\n\n\n\nDirect download link for this postâ€™s example data\n\n\n\n\n\nFor this example, weâ€™ll use the readr, dplyr, tidyr, and ggplot2 tidyverse packages to load in our data, do some wrangling, and get it visualized on to a graph. Weâ€™ll load in our libraries and our first dataset named Patients.\n\n\n# Loading in the appropriate libraries===\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Loading the data into the environment===\nPatients &lt;- read_csv(\"data/Patients.csv\")\n\nRows: 5 Columns: 2\n\n\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): Month\ndbl (1): New Patients\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n Pay attention to the file path in the read_csv function. If you copy and paste that command and are not using the project files within the Github link above, you will get an error!\n\n\n\n\n\nSo we have our data in, and we decide we want to make a simple bar chart of these counts. Weâ€™ll use a basic ggplot framework to do this. Weâ€™ll call the resulting plot Patientgraph. If youâ€™re rusty or just learning ggplot, I highly recommend downloading the ggplot cheat sheet to get up to speed!\n\n\n# Making a ggplot with the data \"as-is\"====\nPatientgraph &lt;- ggplot(Patients, aes(x = Month, y = `New Patients`)) +\n  geom_bar(stat = \"identity\", fill = \"#693ead\")\n  \n# Let's view the graph===\nPatientgraph\n\n\n\n\n\n\n\n\n\nWe can see that weâ€™ve got our data onto the graph, but the Month categories are displayed alphabetically. This may be fine in some cases, but usually we expect to see months listed chronologically (January - December).\nWe can already see from the graph and dataset that we have 5 distinct months to work with. We can confirm this by asking R to show us the unique values for the Month variable. We should also take the time to identify the Month variableâ€™s class. (Data Type)\n\n\n# Viewing the unique values in the \"Month\" variable===\nunique(Patients$Month)\n\n[1] \"February\"  \"May\"       \"August\"    \"September\" \"December\" \n\n# Identifying the class of the \"Month\" variable===\nclass(Patients$Month)\n\n[1] \"character\"\n\n\n\n\n\n\nAs I mentioned earlier, in order to adjust these categories on a ggplot, we need to change the variable type, or itâ€™s class, into a factor. Letâ€™s make this change and save the results into a new dataset called â€œPatients2.â€\n\n\nPatients2 &lt;- Patients %&gt;%\n  mutate(Month = factor(Month, levels = c(\"February\",\"May\",\"August\",\"September\",\"December\")))\n\n Using the pipe operator %&gt;% with the dplyr verb mutate, we can alter the existing Month variable into a factor using base Râ€™s â€œfactorâ€ function. In this function, you simply tell R which variable you want to convert and then pass a â€œlevelsâ€ argument. This argument manually dictates the order in which categories will be seen on the ggplot. Note that because we are using the pipe operator, we do not need to do a direct subset to this variable in the factor function. ex: (Patients$Month)\n\n Although cumbersome, manually setting your factor levels may be required from time to time. Make sure capitalization, spelling, and punctuation match whatâ€™s in your data set exactly. Even having whitespace in your data can cause issues. You can tackle whitespace issues with Stringrâ€™s str_trim function.\n\n\nNow letâ€™s replot the graph with the Patients2 data.\n\n\n# Plotting Patients2===\nPatientgraph2 &lt;- ggplot(Patients2, aes(x = Month, y = `New Patients`))+ \n  geom_bar(stat = \"identity\", fill= \"#693ead\")\n\n#Viewing Patients2 graph===\nPatientgraph2\n\n\n\n\n\n\n\n\n\nNow this is more like it! Now I did say that this method was cumbersome. Thankfully, there are ways to cut some of this work down. Weâ€™ll do this by using some constants in R.\n\n\n\nIf you donâ€™t know about constants, you can read about them here! They are basically preset values that come in base R. We can use the month.name constant in this particular example. Letâ€™s look at it first though to get familiar.\n\n\n# Printing out the month.name constant to take a look at it===\nmonth.name\n\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\n\n\nWe can see all the months are here in this constant ready for us to use! So how do we apply this to help us out with our coding? By calling on the month.name constant for our levels argument when factoring! Recall that we have five months in our dataset. In order to use the â€œmonth.namesâ€ constant, it has to only contain those five months (Remember that the levels have to match exactly.) We do this by subsetting out only the months we need. Weâ€™ll do this and store the results into a dataset called â€œPatients3â€ with the following code:\n\n\n# Refactoring the \"easier\" way===\n    Patients3 &lt;- Patients %&gt;%\n        mutate(Month = factor(Month, levels = month.name[month.name %in% unique(Month)]))\n\n\nYou may see that our code looks similar to the last factoring we did. The only thing that has changed is the addition of whatâ€™s passed into the levels argument:\n\n\nmonth.name[month.name %in% unique(Month)]\n\n\nThe code above tells R to â€œlookâ€ within the â€œmonth.nameâ€ constant and only return the values that are also uniquely in (%in%) our â€œMonthâ€ variable. If needed, you can learn more about Râ€™s operators like %in% here. If we plot Patients3, we can see the result is the same as the original refactored graph we made.\n\n\nPatients3\n\n# A tibble: 5 Ã— 2\n  Month     `New Patients`\n  &lt;fct&gt;              &lt;dbl&gt;\n1 February              21\n2 May                   16\n3 August                33\n4 September             40\n5 December              11\n\n\n\nThe only difference here is not having to do the cumbersome coding of spelling out our months in our factor function.\n\n\n\nSo what if we have a dataset with all the months accounted for in the year? We can do less work! Letâ€™s load in our Patients_complete dataset to take a look.\n\n\n# Loading in the \"complete\" Patients dataset\nPatients_complete &lt;- read_csv(\"data/Patients_complete.csv\")\n\nRows: 12 Columns: 2\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): Month\ndbl (1): New Patients\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n Pay attention to the file path in the read_csv function. If you copy and paste that command and are not using the project files within the Github link above, you will get an error!\n\n\n\n\n\n\nThe â€œPatients Completeâ€ Example Data\n\n\n\n So you mightâ€™ve guessed that this dataset would also return a graph in which the months are ordered alphabetically. Weâ€™ll make a quick one and store it in Patientgraph4.\n\n\n# Confirming assumptions with the \"Patients_complete\" dataset===\n  Patientgraph4 &lt;- ggplot(Patients_complete, aes(x = Month, y = `New Patients`)) +\n  geom_bar(stat = \"identity\", fill= \"#693ead\")\n  \n# Viewing it==\nPatientgraph4\n\n\n\n\n\n\n\n\n\nThis time, because we have all of the months in the dataset, the code for refactoring can be simplified. Weâ€™ll store it in a dataset called Patients4 then graph it in a ggplot called Patientgraph5.\n\n\n# Easier refactoring when all months are present ===\nPatients4 &lt;- Patients_complete %&gt;%\n  mutate(Month = factor(Month, levels = month.name))\n  \n# Creating the plot ===\nPatientgraph5 &lt;- ggplot(Patients4, aes(x = Month, y = `New Patients`))+\n  geom_bar(stat = \"identity\", fill= \"#693ead\")\n\n# Viewing it ===\nPatientgraph5\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, letâ€™s go back to our original Patients dataset. What do you do if you donâ€™t have all the months of the year, but you want to plot all of the months? To do this, we need to create â€œplaceholderâ€ data points within our dataset. We do this by adding the months we are missing to our dataset and assigning them a numeric value of 0. Weâ€™ll do this and store it into a final dataset called Patients_modified. Be sure to remember to refactor this as well!\n\n\n # Adding missing months to our \"Patients\" data set===\n Patients_modified &lt;- left_join(tibble(\"Month\" = month.name),Patients, by = \"Month\") \n \n #Replacing coerced NAs from the previous code to a numeric 0 then refactoring our new dataset===\nPatients_modified &lt;- Patients_modified %&gt;%\n  mutate(`New Patients` = ifelse(is.na(`New Patients`),0,`New Patients`)) %&gt;%\n  mutate(Month = factor(Month, levels = month.name))\n\n\nEssentially what weâ€™ve done is transformed our vector of month.name constants into a data frame, or tibble. Doing this allows us to complete a left join and merge all of the â€œMonthâ€ names in the constant into our dataset. The first mutate function uses the ifelse function to replace all the NAs of this merge with numeric values of 0. The second mutate function is just the refactoring method that was previously introduced. Letâ€™s create the graph, call it Patientgraph6, and view it.\n\n\n\n\n\nPatientgraph6 &lt;- ggplot(Patients_modified, aes(x = Month, y = New Patients)) + geom_bar(stat = â€œidentityâ€, fill= â€œ#693eadâ€)\n#And view it=== Patientgraph6\n````\n\nAnd there we are! All of our data is plotted and we can see all of the months in the year! Youâ€™ll notice those pesky month labels may be colliding with each other. This may vary based on the machine/browser window youâ€™re working with. If you need to fix cases like these, Iâ€™d recommend the str_wrap() function from the stringr package.\nHave any thoughts or suggestions? Know of a better solution or way to make this process more efficient? Feel free to leave a comment below to share or contact me directly! Respectful discourse towards efficient solutions or new insights is always welcomed!"
  },
  {
    "objectID": "post/orderingmonths/ordering-months.html#loading-in-your-libraries-and-data",
    "href": "post/orderingmonths/ordering-months.html#loading-in-your-libraries-and-data",
    "title": "Ordering Months",
    "section": "",
    "text": "For this example, weâ€™ll use the readr, dplyr, tidyr, and ggplot2 tidyverse packages to load in our data, do some wrangling, and get it visualized on to a graph. Weâ€™ll load in our libraries and our first dataset named Patients.\n\n\n# Loading in the appropriate libraries===\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# Loading the data into the environment===\nPatients &lt;- read_csv(\"data/Patients.csv\")\n\nRows: 5 Columns: 2\n\n\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): Month\ndbl (1): New Patients\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n Pay attention to the file path in the read_csv function. If you copy and paste that command and are not using the project files within the Github link above, you will get an error!"
  },
  {
    "objectID": "post/orderingmonths/ordering-months.html#plotting-your-data",
    "href": "post/orderingmonths/ordering-months.html#plotting-your-data",
    "title": "Ordering Months",
    "section": "",
    "text": "So we have our data in, and we decide we want to make a simple bar chart of these counts. Weâ€™ll use a basic ggplot framework to do this. Weâ€™ll call the resulting plot Patientgraph. If youâ€™re rusty or just learning ggplot, I highly recommend downloading the ggplot cheat sheet to get up to speed!\n\n\n# Making a ggplot with the data \"as-is\"====\nPatientgraph &lt;- ggplot(Patients, aes(x = Month, y = `New Patients`)) +\n  geom_bar(stat = \"identity\", fill = \"#693ead\")\n  \n# Let's view the graph===\nPatientgraph\n\n\n\n\n\n\n\n\n\nWe can see that weâ€™ve got our data onto the graph, but the Month categories are displayed alphabetically. This may be fine in some cases, but usually we expect to see months listed chronologically (January - December).\nWe can already see from the graph and dataset that we have 5 distinct months to work with. We can confirm this by asking R to show us the unique values for the Month variable. We should also take the time to identify the Month variableâ€™s class. (Data Type)\n\n\n# Viewing the unique values in the \"Month\" variable===\nunique(Patients$Month)\n\n[1] \"February\"  \"May\"       \"August\"    \"September\" \"December\" \n\n# Identifying the class of the \"Month\" variable===\nclass(Patients$Month)\n\n[1] \"character\""
  },
  {
    "objectID": "post/orderingmonths/ordering-months.html#refactoring-your-data-for-plotting",
    "href": "post/orderingmonths/ordering-months.html#refactoring-your-data-for-plotting",
    "title": "Ordering Months",
    "section": "",
    "text": "As I mentioned earlier, in order to adjust these categories on a ggplot, we need to change the variable type, or itâ€™s class, into a factor. Letâ€™s make this change and save the results into a new dataset called â€œPatients2.â€\n\n\nPatients2 &lt;- Patients %&gt;%\n  mutate(Month = factor(Month, levels = c(\"February\",\"May\",\"August\",\"September\",\"December\")))\n\n Using the pipe operator %&gt;% with the dplyr verb mutate, we can alter the existing Month variable into a factor using base Râ€™s â€œfactorâ€ function. In this function, you simply tell R which variable you want to convert and then pass a â€œlevelsâ€ argument. This argument manually dictates the order in which categories will be seen on the ggplot. Note that because we are using the pipe operator, we do not need to do a direct subset to this variable in the factor function. ex: (Patients$Month)\n\n Although cumbersome, manually setting your factor levels may be required from time to time. Make sure capitalization, spelling, and punctuation match whatâ€™s in your data set exactly. Even having whitespace in your data can cause issues. You can tackle whitespace issues with Stringrâ€™s str_trim function.\n\n\nNow letâ€™s replot the graph with the Patients2 data.\n\n\n# Plotting Patients2===\nPatientgraph2 &lt;- ggplot(Patients2, aes(x = Month, y = `New Patients`))+ \n  geom_bar(stat = \"identity\", fill= \"#693ead\")\n\n#Viewing Patients2 graph===\nPatientgraph2\n\n\n\n\n\n\n\n\n\nNow this is more like it! Now I did say that this method was cumbersome. Thankfully, there are ways to cut some of this work down. Weâ€™ll do this by using some constants in R."
  },
  {
    "objectID": "post/orderingmonths/ordering-months.html#the-month.name-constant-for-easier-refactoring",
    "href": "post/orderingmonths/ordering-months.html#the-month.name-constant-for-easier-refactoring",
    "title": "Ordering Months",
    "section": "",
    "text": "If you donâ€™t know about constants, you can read about them here! They are basically preset values that come in base R. We can use the month.name constant in this particular example. Letâ€™s look at it first though to get familiar.\n\n\n# Printing out the month.name constant to take a look at it===\nmonth.name\n\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\n\n\nWe can see all the months are here in this constant ready for us to use! So how do we apply this to help us out with our coding? By calling on the month.name constant for our levels argument when factoring! Recall that we have five months in our dataset. In order to use the â€œmonth.namesâ€ constant, it has to only contain those five months (Remember that the levels have to match exactly.) We do this by subsetting out only the months we need. Weâ€™ll do this and store the results into a dataset called â€œPatients3â€ with the following code:\n\n\n# Refactoring the \"easier\" way===\n    Patients3 &lt;- Patients %&gt;%\n        mutate(Month = factor(Month, levels = month.name[month.name %in% unique(Month)]))\n\n\nYou may see that our code looks similar to the last factoring we did. The only thing that has changed is the addition of whatâ€™s passed into the levels argument:\n\n\nmonth.name[month.name %in% unique(Month)]\n\n\nThe code above tells R to â€œlookâ€ within the â€œmonth.nameâ€ constant and only return the values that are also uniquely in (%in%) our â€œMonthâ€ variable. If needed, you can learn more about Râ€™s operators like %in% here. If we plot Patients3, we can see the result is the same as the original refactored graph we made.\n\n\nPatients3\n\n# A tibble: 5 Ã— 2\n  Month     `New Patients`\n  &lt;fct&gt;              &lt;dbl&gt;\n1 February              21\n2 May                   16\n3 August                33\n4 September             40\n5 December              11\n\n\n\nThe only difference here is not having to do the cumbersome coding of spelling out our months in our factor function."
  },
  {
    "objectID": "post/orderingmonths/ordering-months.html#when-all-months-are-present-in-your-dataset",
    "href": "post/orderingmonths/ordering-months.html#when-all-months-are-present-in-your-dataset",
    "title": "Ordering Months",
    "section": "",
    "text": "So what if we have a dataset with all the months accounted for in the year? We can do less work! Letâ€™s load in our Patients_complete dataset to take a look.\n\n\n# Loading in the \"complete\" Patients dataset\nPatients_complete &lt;- read_csv(\"data/Patients_complete.csv\")\n\nRows: 12 Columns: 2\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (1): Month\ndbl (1): New Patients\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n Pay attention to the file path in the read_csv function. If you copy and paste that command and are not using the project files within the Github link above, you will get an error!\n\n\n\n\n\n\nThe â€œPatients Completeâ€ Example Data\n\n\n\n So you mightâ€™ve guessed that this dataset would also return a graph in which the months are ordered alphabetically. Weâ€™ll make a quick one and store it in Patientgraph4.\n\n\n# Confirming assumptions with the \"Patients_complete\" dataset===\n  Patientgraph4 &lt;- ggplot(Patients_complete, aes(x = Month, y = `New Patients`)) +\n  geom_bar(stat = \"identity\", fill= \"#693ead\")\n  \n# Viewing it==\nPatientgraph4\n\n\n\n\n\n\n\n\n\nThis time, because we have all of the months in the dataset, the code for refactoring can be simplified. Weâ€™ll store it in a dataset called Patients4 then graph it in a ggplot called Patientgraph5.\n\n\n# Easier refactoring when all months are present ===\nPatients4 &lt;- Patients_complete %&gt;%\n  mutate(Month = factor(Month, levels = month.name))\n  \n# Creating the plot ===\nPatientgraph5 &lt;- ggplot(Patients4, aes(x = Month, y = `New Patients`))+\n  geom_bar(stat = \"identity\", fill= \"#693ead\")\n\n# Viewing it ===\nPatientgraph5"
  },
  {
    "objectID": "post/orderingmonths/ordering-months.html#when-you-want-to-fill-in-missing-months-on-a-plot",
    "href": "post/orderingmonths/ordering-months.html#when-you-want-to-fill-in-missing-months-on-a-plot",
    "title": "Ordering Months",
    "section": "",
    "text": "Finally, letâ€™s go back to our original Patients dataset. What do you do if you donâ€™t have all the months of the year, but you want to plot all of the months? To do this, we need to create â€œplaceholderâ€ data points within our dataset. We do this by adding the months we are missing to our dataset and assigning them a numeric value of 0. Weâ€™ll do this and store it into a final dataset called Patients_modified. Be sure to remember to refactor this as well!\n\n\n # Adding missing months to our \"Patients\" data set===\n Patients_modified &lt;- left_join(tibble(\"Month\" = month.name),Patients, by = \"Month\") \n \n #Replacing coerced NAs from the previous code to a numeric 0 then refactoring our new dataset===\nPatients_modified &lt;- Patients_modified %&gt;%\n  mutate(`New Patients` = ifelse(is.na(`New Patients`),0,`New Patients`)) %&gt;%\n  mutate(Month = factor(Month, levels = month.name))\n\n\nEssentially what weâ€™ve done is transformed our vector of month.name constants into a data frame, or tibble. Doing this allows us to complete a left join and merge all of the â€œMonthâ€ names in the constant into our dataset. The first mutate function uses the ifelse function to replace all the NAs of this merge with numeric values of 0. The second mutate function is just the refactoring method that was previously introduced. Letâ€™s create the graph, call it Patientgraph6, and view it."
  },
  {
    "objectID": "post/making-my-first-shiny-app/making-my-first-shiny-app.html",
    "href": "post/making-my-first-shiny-app/making-my-first-shiny-app.html",
    "title": "Making My First Shiny App",
    "section": "",
    "text": "This year was the first time that I ever competed in a RStudio Shiny competition by submitting my first ever Shiny app, the TarotreadR. For those of you that read one of my previous blog posts â€œHow I Became a â€˜Not-Beginnerâ€™ in Râ€, youâ€™ll know that I tried to make Shiny apps first before doing anything else in R and RStudio. This was before I tried learning basic programming in, or even learning how to load data into, the RStudio environment. I can credit Shiny with being the reason why I almost gave up on learning R and almost did not make a transition into the field of data science.\nNow fast forward about 2-3 years to present day; I can comfortably say that I still know so little about Shiny. In March of this year, RStudioâ€™s 3rd Annual Shiny Competition was first announced and, for some reason, I felt compelled to face my fears and enter the competition. The thought of competing was honestly terrifying and daunting because I had never worked in Shinyâ€” well, besides my first failed attempt over 2 years ago. Just like in the past with my machine learning experiences, every time I tried to get started with reading materials about creating my own app in Shiny, I would just freeze up mentally. Everything always seemed overwhelming, and I could never understand how people could create such amazing and intricate apps just using Shiny. Despite all of this, I somehow managed to pull together a working app. The process involved a lot of resources, a lot of time, some tears, and some sleepless nights. Although I got no honorable mentions or placements in the competition, I have to say that it is something I am extremely proud of. Plus, I also got my first hex stickers for free so I canâ€™t complain at all!\nA few months ago, I could never have imagined that I would be able to create a working app that I made by myself in Shiny. The TarotreadR isnâ€™t the best app and might not be the most creative, but it is something that is a huge accomplishment for me. Especially so because it was made in about three months with no prior Shiny experience. I wanted to take the time to talk about this process of creating the TarotreadR and what I learned from the experience, so letâ€™s dive in!"
  },
  {
    "objectID": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#the-idea",
    "href": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#the-idea",
    "title": "Making My First Shiny App",
    "section": "The Idea",
    "text": "The Idea\n\n\n\nThe Modern Witch Tarot Deck by Lisa Sterle. Image credit: Lauren Panepinto | Muddycolors.com\n\n\n\nMy TarotreadR idea was thought up before the Shiny competition this year. Recently, Iâ€™ve personally become interested in tarot cards (and was gifted The Modern Witch Tarot Deck by Lisa Sterle.) This is not because I was planning my career transition into tarot reading, but because I grew fond of the different art styles that different decks can have. I find it so interesting to look at how artistsâ€™ interpretations of these decks vary. I must also admit that I do like pulling cards for myself from time to time. I find that some people get surprised when I tell them that. Iâ€™m viewed as this highly analytical person that works in data science and â€œreal things.â€ For me, I liken reading cards to using a fidget spinner in some sense.\n\nAs a mental health advocate, Iâ€™ve always been open about my mental health struggles and I must say that sometimes pulling tarot cards prompts me to use the Barnum Effect to my advantage by creating some distance from my anxious thoughts. This gives me the space to acknowledge what I already know within me. Being that I started doing this more frequently, I wanted an app that could spell out full interpretations of groups of tarot cards based on what was pulled. Interpreting tarot cards can get messy and confusing if you start doing more than one, and if you allow them to be reversed. It can get complicated because a reversed tarot card can have subtle but key differences in interpretations when compared to upright cards. So, given that I was already interested in this and wanted to do it, the idea of a simpler app, the TarotreadR, was born.\n\nInstead of making fully tailored interpretations, the app would randomly pull cards for the user and give them keywords for each card based on if the card was upright or reversed. To get started with this, I wanted to do the tasks that I thought would take the longest: making the card images and creating tarot card data."
  },
  {
    "objectID": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#making-the-card-art-and-data",
    "href": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#making-the-card-art-and-data",
    "title": "Making My First Shiny App",
    "section": "Making the Card Art and Data",
    "text": "Making the Card Art and Data\n\n\n\n\nOne of my favorite cards that I made. This gif shows all the pieces I had to individually find to create the visual for this card.\n\n\n\nThe process of making the card art was a bit daunting but something I really wanted to do. The original tarot deck consists of 78 cards in total. Making the card art did take about 2 months over the course of a few sessions. It was the perfect time to get some use out of my Pro Canva account. I created each image by â€œcollagingâ€ various icons, graphics, and shapes together. This was a tedious process as it required thinking outside of the box to get the shapes and figures I wanted. The hardest part was trying to keep the figures (human silhouettes) consistent. Letâ€™s just say I like some cards more than others.\n\n\n\n\nOne of my best cards and one of my worst. Note the inconsistency in the style and design of the human silhouettes.\n\n\n\nWhile I was making the card art, I was also creating a dataset to go with it. For an app like this, the dataset was straightforward. I would just need three variables: The cardâ€™s name, the associated keywords (card meanings), and the position (upright or reversed/upside down) of the card. I used a combination of published meanings from biddytarot.com and labyrinthos.co to fill in the keywords of each card. This process also took about a few months as I only filled in the data once I completed the art for the card.\n\n\n\n\nThe finished tarot card dataset in the TarotreadR Github Repository\n\n\n\nCreating the dataset was an iterative process. While I was working on the cards and data, I did start to think about the app structure. Trial and error eventually lead to me figuring out that the text in the â€œkeywordsâ€ variable could be in plaintext HTML. This required me fixing the data to follow plaintext HTML and to then introduce line breaks in the UI of the app when keywords were displayed.\n\n\n\n\nThe Three of Cups card displayed in the TarotreadR app and a snip of the dataset. Plaintext HTML was used to format the keywords.\n\n\n\nAfter I had a good foundation going with the cards and dataset, I had to finally face my fears and start trying to build the app in Shiny. I thought the best way to do this would be to try to wrap my head around the Shiny environment. I would be lying if I said I wasnâ€™t terrified."
  },
  {
    "objectID": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#understanding-the-shiny-environment-and-reactivity",
    "href": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#understanding-the-shiny-environment-and-reactivity",
    "title": "Making My First Shiny App",
    "section": "Understanding the Shiny Environment and Reactivity",
    "text": "Understanding the Shiny Environment and Reactivity\n\n\n\nMe opening a new default Shiny app script in R.\n\n\n\nSpoiler Alert: this part was actually not that bad! The worst is designing your app to make it look pretty and Iâ€™ll get to that nightmare shortly. If youâ€™ve read one of my previous R walkthroughs, Making Dull Dashboards, you may recall me talking about the concept of reactivity when creating flexdashboards. The concepts I learned using the Crosstalk and SummaryWidgets packages to make flexdashboards prepared me to comprehend how the Shiny environment works. While I am still a Shiny noob in my mind, itâ€™s definitely not as scary when you have a basic understanding of how the two major components of a Shiny app work together.\n\n\n\n\nA basic thought process that helped me understand the Shiny environment.\n\n\n\nI think of a Shiny app as if it were a car made of two main components: the Server and the UI (User Interface). I think of the Server as everything under the hood of the car: the engine, fuel tank, electrical system, etc. I think of the UI as the frame of the car, the seats, the steering wheel, and anything else I would need to comfortably control the car.\nI think of it this way: thereâ€™s a bare minimum thatâ€™s required for a car to turn on and operate. This is like having functions in your Server that, at its bare minimum, will allow the app to operate regardless of efficiency or the warnings that we might ignore in the console while our app is deploying. At its bare minimum, the UI should similarly be able to give the user basic functionality. In our car comparison this could be something as simple as making sure the car has a working ignition and a steering wheel. In the same sense, while our cars can operate with these bare minimums, weâ€™d prefer to not see a check engine light, weâ€™d prefer seat belts, and maybe some nice leather seats to sit on.\nOnce I started thinking about Shiny apps this way, I realized the importance of the interaction between the UI and the Server. Iâ€™m very excited to build from this knowledge to make better apps in the future, but for now, this basic understanding was all I needed to make the TarotreadR happen."
  },
  {
    "objectID": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#designing-the-ui",
    "href": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#designing-the-ui",
    "title": "Making My First Shiny App",
    "section": "Designing the UI",
    "text": "Designing the UI\n\n\n\nA piece of the UI code used to make the TarotreadR. This code creates a one card draw.\n\n\n\nCreating the UI was also an iterative process. It seemed I was constantly going back and forth between the UI and Server through trial and error. I expected this as I was essentially teaching myself as I progressed. One of the biggest challenges was learning that itâ€™s REALLY helpful to have some knowledge of HTML, CSS, and even JavaScript when designing a Shiny appâ€™s UI. While itâ€™s not required to make an app functional, it is required to make an app pretty. I had a vision of what I wanted the app to look like, and to get that vision, I definitely had to spend some nights refreshing my HTML skills and learning new skills in CSS and JavaScript. These backgrounds were needed to figure out small things like not having cards appear until a user has clicked on an action button and having the cards animate onto the screen when a user â€œpulledâ€ them.\nAnother challenge was figuring out spacing and sizing. It required thinking about the app and its components in a modular fashion. Boxes within boxes, if you will. Again, trial and error was my best friend here. The code you see above is a â€œFrankensteinâ€ masterpiece that came to be after many iterations and failed deployments."
  },
  {
    "objectID": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#setting-up-the-server",
    "href": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#setting-up-the-server",
    "title": "Making My First Shiny App",
    "section": "Setting Up the Server",
    "text": "Setting Up the Server\nBesides trying to teach myself CSS and minimal JavaScript in less than a month, one of the most difficult things about building the TarotreadR was figuring out the Server component. I needed to figure out how to randomize cards being pulled, but I also needed to get images to show up in the UI based on those randomizations. Things get even more difficult once you add in the reversed card positions.\nMy original thought was to only make the deck of cards one time and then figure out how to get the images to display in a reversed position programmatically. In my darkest hour, I gave up trying to figure out the CSS to make this happen. Every time I thought I had the answer, the image would somehow be off and not displaying correctly. In that moment, I shed a tear, closed RStudio, and opened up Canva and proceeded to make â€œreversedâ€ images for each of the cards. In retrospect, I really wish that I would have stuck it out as it might have improved the TarotreadRâ€™s performance (instead of loading 78 card images, it was now loading 156 card images for upright and reversed positions).\nHaving separate images did end up working for me with the help of this post by Jeroen Ooms. Once I got over the biggest hurdle of getting the images to display properly, I was able to add things like toggling (so that cards are only shown after a button is clicked) and sounds that play with the card animations.\n\n\n\n\nA snip of the animations and interactions coded for the TarotreadR. Most of these functions came from packages like ShinyAnimate."
  },
  {
    "objectID": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#putting-it-all-together",
    "href": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#putting-it-all-together",
    "title": "Making My First Shiny App",
    "section": "Putting It All Together",
    "text": "Putting It All Together\nFinally, after about three months, all of the work paid off! I finally finished all of the cards, completed all of the data entry, got the UI and Server to talk to each other, and successfully deployed the TarotreadR to Shinyapps.io. If you havenâ€™t seen it action and would like to, you can here.\nIf youâ€™d like to see the full code and files used to make all of this, you can find it in my Github Repo here.\n\n\n\n\nThe completed TarotreadR app. My first Shiny app!"
  },
  {
    "objectID": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#lessons-learned",
    "href": "post/making-my-first-shiny-app/making-my-first-shiny-app.html#lessons-learned",
    "title": "Making My First Shiny App",
    "section": "Lessons Learned",
    "text": "Lessons Learned\nAfter this whole experience, my professional and personal life got extremely hectic, and I didnâ€™t get a chance to really talk about this publicly (which is what prompted this post). There are a few lessons Iâ€™ve learned that I want to highlight:\n\nCSS, HTML, and JavaScript are crucial to making attractive UIs (in my opinion).\nSometimes itâ€™s OK if your code is not the most efficient. You can still get your app to work â€“ but it is in good practice to try and revisit the code to improve it if possible.\nFlexdashboards, Crosstalk, and SummaryWidgets are absolutely the reason why I was able to do all of this in three months. Learning these packages can ease you into understanding how app reactivity works.\nI have even more respect for web devs and those that make Shiny apps for a living (I already had a lot of respect for you guys, now itâ€™s just astronomical).\nShiny isnâ€™t all that scary once you slow down and take the time to understand the environment.\n\n\nHave you ever made Shiny apps before? Do you have â€œShinyphobiaâ€ like I did? Are you screaming at the inefficiency of my program? (I know, Iâ€™m sorry!) Feel free to contact me directly! Respectful discourse towards efficient solutions or new insights is always welcomed!"
  },
  {
    "objectID": "post/lets-talk-about-2022/lets-talk-about-2022.html",
    "href": "post/lets-talk-about-2022/lets-talk-about-2022.html",
    "title": "Letâ€™s Talk About 2022",
    "section": "",
    "text": "Yes, hello. Itâ€™s been a while. I have been neglecting The Tidy Trekker as of late (and to be honest, I still might this year after this overhaul is done, but weâ€™ll see.) I had all the intentions of being super active here in 2022, but life happened. The good news is, instead of the usual negative BS, I was inundated with EXCELLENT things in 2022. I was afraid to even step into 2023 for fear that all my good luck would â€œrun outâ€ this year. (Iâ€™m joking, btw life is what you make it, and your enjoyment of it depends on a lot of things like perspective, if you need/go to therapy, circumstances, etc.)\n\nBut enough general rambling; letâ€™s start with some targeted rambling. So what happened in 2022?\n\nIn this post:\n\nConferences and Talks\nJob Change\nFamily and Home Changes\nSo, What About 2023?\n\n\n\nConferences and Talks\nSo this one is probably the most known. I had A LOT of talks to prepare for and do. Some of you may have found out about me throughÂ one of the various talksÂ I did in 2022. Most of the talks were about #rtistry (generative art in the R language), but I also gave more practical ones. The biggest one was obviously RStudio::Conf(2022). This was BY FAR the best conference experience I ever had despite being pregnant and in the middle of so many life-changing things all at once. I was literally onboarding at my new job and had jumped on a plane to D.C. less than a few days after unexpectedly closing on my first home. It was an absolute cluster of chaotic good.\nAt the conference, I assisted with theÂ Making Art From Code workshop, was a diversity scholar, and gave my own talk, â€œMaking Data Pipelines in R.â€\n\n Had to take pictures so I could know it was âœ¨real.âœ¨ \n\n\nSide note. If you LOVE R and are on the fence about ever going to a (Now Posit) conference, you should go if you can! In the past, if you submit a presentation or even a lightning talk, Posit has provided traveling and boarding assistance. If you are from an underrepresented group in tech, you can also apply for a diversity scholarship. Itâ€™s a great way to gain any needed assistance as well. Just like how Twitter used to be greatÂ (before the Twitter Exodus), imagine having that in real life for a few days. It was awesome. And I mean, come on, who doesnâ€™t like stickers???\n\n\nSoâ€¦Manyâ€¦STICKERS!!!!\n\n\n\nJob Change\nOne of the cool things about attending the conference was that I could meet some of my co-workers in real life! I recently changed jobs in 2022. I now work at the Prostate Cancer Clinical Trials Consortium (PCCTC) at Memorial Sloan Kettering Cancer Center. This has been a significant change so far, as it has allowed me to stop working so much. I went from having three jobs to one full-time one (and a Per Diem contract one if needed from time to time.)\nAt the time of writing this, Iâ€™m on parental leave now, but Iâ€™m excited to get to work when I get back. Some of my work will focus on streamlining internal stuff for reporting on prostate cancer studies, and Iâ€™m SUPER hyped about it. Iâ€™ve been using R for about four, going on five years now, and I think Iâ€™m finally starting to hone in on my â€œniche.â€ Besides making art with R, I get a lot of satisfaction from automating things. Building (hopefully) seamless pipelines that make work easier for people. I realized Iâ€™d rather spend months building pipelines than doing analyses, external client-facing, and the like. In other words, my current role as a data scientist in this capacity perfectly aligns with my pragmatic interests. Honestly, Iâ€™m super lucky there.\n\n\nFamily and Home Changes\nWorking at the PCCTC also went perfectly with home life. For those of you that missed it, I was very open about myÂ infertility strugglesÂ after I got pregnant. But as life would have it, after trying aggressively for three years, I got pregnant right before I found out about the open position at the PCCTC. I almost didnâ€™t apply for it because it felt wrong to do so, knowing that I would have to leave for parental leave.\nLooking back, switching jobs was the best thing I could have done. I could support myself financially, stop trying to run a one-person data science team (like I had to do at my old job), and really just focus on working while learning new things everyday. An added bonus is being able to spend time getting to know my son and just being grateful that all the years of feeling like I was working myself to death eventually paid off (yes, even during late nights while I was on the verge of tears trying to console a crying baby ğŸ˜…)\nI have a lot to be grateful for. I feel like I have changed so much as a person and that I am really coming into the best version of myself that I can be. Whether weâ€™re talking professionally or personally.\n\n\nSo, What About 2023?\nSoâ€¦ whatâ€™s next? Honestly, this year Iâ€™d like to â€œlay low.â€ I want to actively stay home, study up on things, be a mother, and work. Thatâ€™s all I want. So, professionally speaking, this is what Iâ€™ve got on my to-do list for 2023:\n\nGet projects done/foundations started at work (This has to be done as I have to work lol)\nOpen up my online art store (This doesnâ€™t have to be done, but I probably should since I already made the store and everything.)\nRe-launch the new version of my website (If youâ€™re reading this, that means I did this! Go Me!!!)\nContribute to the textbook â€œRtistry: Methods for Visual Generative Art Using Râ€ along with Antonio Paez, Antonio Sanchez, and Jacquie Tran. (This has to be done as a contract was signed)\n\nThatâ€™s it. If I have energy for a blog post here or there, or if my job wants to send me to Chicago for Posit Conf this year (Travis, pls.) Then Iâ€™ll do that. But the goal is to work â€œpassivelyâ€ this year (if that makes any sense at all.)"
  },
  {
    "objectID": "post/how-i-became-a-not-beginner-in-r/not-beginner.html",
    "href": "post/how-i-became-a-not-beginner-in-r/not-beginner.html",
    "title": "How I Became A â€œNot-Beginnerâ€ in R",
    "section": "",
    "text": "Iâ€™ve been in my current position as a Data Integration Specialist for about nine months now and I absolutely love it! I have achieved a lot of professional development that intertwined perfectly with my actual position. Iâ€™ve learned how to clean data more efficiently, deal with multiple data sources, and even learned how to create automated reports and dashboards in R and R Markdown.\nMore recently, Iâ€™ve had a local opioid dashboard (that I created in R) featured on our local news station. Like on actual TV (yeah, Iâ€™m still in shock about that one.)\nIt was then that I realized: Iâ€™m not a beginner in R anymore\n\n\n\n\nâ€œMe realizing Iâ€™m not a beginner anymoreâ€\n\n\n\nThat realization made me think about things though. It was clear that I wasnâ€™t a beginner anymore, but if I wasnâ€™t a beginner, what was I? I suddenly had an existential moment where I realized I needed to have a conversation with Data Science and R programming (as if they were actual people) and ask them about our relationship status. I had to ask them:\n\nâ€œWhat are we?â€\n\n\nIâ€™m definitely not an expert, not by a long shot, but I can do A LOT of really essential things in R now. Whenever Iâ€™m interacting with others in the field, or assisting others with their programming, I always felt I needed to give a disclaimer that â€œIâ€™m still learning.â€ People would then kind of roll their eyes at me after I explain things by telling me Iâ€™m a â€œwizardâ€ or â€œexpertâ€ and to stop being modest. So that made me think about it. How should I be labeling myself? The more I tried to put a label on my data science/R programming proficiency, the more I realized that Iâ€™m currently in some weird gray area of my journey; and honestly? I donâ€™t think itâ€™s talked about enough.\nThereâ€™s a wide range of resources out there for aspiring R programmers and data scientists. The first thing everyone tells you to do (myself included) is to start reading R for Data Science and to just practice. Thereâ€™s also a wealth of information about more advanced R topics like modeling and advanced Shiny app development. I remember longing to join discussions about these things at the RStudio::Global conference this year, but I ultimately felt like I wasnâ€™t quite ready to join those conversations yet. This made me feel like the space wasnâ€™t for me and that I couldnâ€™t really participate or engage with anyone. I found myself asking â€œwhere are the resources for people who arenâ€™t beginners or experts?â€\n\n\n\n\nâ€œMe looking for something labeled â€˜Intermediate R Resourcesâ€™â€\n\n\n\nSo itâ€™s not like there arenâ€™t any resources available at an intermediate level. DataCamp has a course (if youâ€™re willing to pay) and there are also other resources crafted by wonderful heroes in the field that can be found by googling. But there isnâ€™t a lot of consistency between the resources available.\nThese inconsistencies are to be expected though because there isnâ€™t a standardized guideline that lets you know how youâ€™re doing in the field or in R programming in general. How do aspiring data scientists/R programmers know when theyâ€™re experts? Do we ever know? Or do we have to wait until enough people deem us as â€œexpertsâ€? Context also matters. The set of skills one person may have may be above-and-beyond whatâ€™s needed at one company but might not cut it at another.\nI also spent way too much time thinking about when you can officially â€œearnâ€ the right to call yourself a data scientist. Do you absolutely need to master machine learning and AWS before doing so? How do you know youâ€™re not crossing into data engineering territory as those lines are kind of murky as well? Do you need to actually go out and get a degree in data science? (My opinion on that is no by the way, although for students who know this is what they want to do, it canâ€™t hurt to get that degree if you like the program?)\nToward the end of my existential crises, I asked myself if thinking about all of this was worth it. Is it really important to label myself? Does it matter if Iâ€™m seen as an expert in the field? Does it matter if people say Iâ€™m not a data scientist until I learn more things? As long as Iâ€™m employed, probably not. What I do think is important to realize is that the climate of the data science field in general is very fluid. Especially when bringing R proficiency into the mix. I mean think about it: if you want to be a doctor, or a lawyer, or many other professions, you normally have some sort of standardized â€œguideâ€ to let you know if youâ€™re proficient in what you do. You may have options to be certified in specialized domains as well as obtain a degree to â€œproveâ€ what you can do. In Data Science and R Programming, itâ€™s a bit different.\nYou can get certified to be a tidyverse instructor. But from what I could tell, thereâ€™s no â€œofficialâ€ or standardized certifications that exist globally for R programming. The certifications that I could find were either a part of newly designed data science programs at various universities, or certifications from Massive Open Online Courses (MOOC) on sites like Coursera or Udemy. I wonder if this is because R is an open-sourced program.\nWell, after spending a good week thinking about all of this, I came to the conclusion that I didnâ€™t really determine too much of anything. The only thing that I WAS able to determine is this:\n\nIâ€™m not a beginner anymoreâ€¦ Iâ€™m a â€œNot-Beginnerâ€\n\n\nI use the term â€œNot-Beginnerâ€ because I donâ€™t know if I could even call myself intermediate! I know a lot about some things, and little about others. So I am fully comfortable and proud to use this term to describe myself!\nSo how did I do it? How did I cross the imaginary boundary into â€œNot-Beginnerâ€ territory in data science/R programming? Keep in mind that weâ€™re all different. Everyone learns and operates differently, but I can retrospectively tell you how I think I got here:\n\n\nEnvironment\nThis was absolutely the BIGGEST factor for me. I fell in love with R programming/Data Science in a past position while attending an AEA conference a few years back. When I returned to work, I was bursting with motivation and energy and was itching to put all of my time and effort into learning R and Data Science. The environment I was in allowed me to do this to some degree, but it wasnâ€™t sustainable. I found myself putting in LOADS of overtime for professional development and I always felt like others in the environment didnâ€™t have the bandwidth to really help guide me on the journey. Although itâ€™s understandable (due to the initial learning curve you need to get over with R), that work environment left me feeling unsupported and stagnated in the process. I was forced to continue working on my skills outside of work to eventually get to the position Iâ€™m in now because it turns out it is really hard to learn new things if youâ€™re constantly in daily Zoom meetings (I partially blame COVID on that one).\nWhile Iâ€™m the only person utilizing R in my department now, the current environment I work in is conducive to my development. Itâ€™s nurturing, flexible, and supportive which I think helps a lot.\n\n(Also not spending 70% of my time in meetings is a big help. This is a PSA and plea to abolish unnecessary meetings âœŠğŸ¾)\n\n\n\n\n\n\n\nâ€œHow I feel logging into work most daysâ€\n\n\n\n\n\n\n\nCommunity/Online Presence\nI mentioned Iâ€™m the only one that uses R in my department and thatâ€™s totally OK. (Absolutely nothing wrong with Excel, SAS, and other data tools.) Consequently, I was prompted to create an online presence for myself to get some support. Along with the Tidy Trekker site, I also joined Twitter and made more of an effort to join data science/R programming groups on Facebook and LinkedIn. Being engaged in a community can give an extra level of support that you might not be able to get within your department. Sometimes (if data agreements allow) it can be so helpful to get outside opinions on visualizations or general assistance with programming. In particular, the #rstats and #r4ds Twitter communities are places that should be cherished and treasured.\n\n\n\n\n\n\nCome hang out on Twitter if you arenâ€™t already there (@meghansharris)\n\n\n\n\n\n\n\nPassion/Motivation\nI recently saw a post on Twitter that stated that you should not get into the Data Science field if youâ€™re just in it for the money, and I fully agree. I cannot tell you how many nights I accidentally stayed up coding and learning for hours. Not because I â€œhadâ€ to, but because I absolutely wanted to. People that are here because they are passionate about the field can understand. There were times where I had to sit and ask myself if this career choice was what I wanted purely because the process of getting through those initial phases of R programming/data science were BRUTAL. If youâ€™re trying to get your way out of the â€œbeginnerâ€ phases of your journey, or even if youâ€™re just beginning, you have to be honest with yourself and make sure that it is something you truly want to do. That passion is whatâ€™s going to excel you forward in your journey.\nBack in a past position, I was overworked and sick as a result. This was around the time I was learning R. I remembered having a legitimate fever dream about coding. I would close my eyes and see the RStudio IDE staring back at me. Once that fever broke, I was thrilled to return to whatever script I was working on at the time. Thatâ€™s when I knew this was for me. Now you donâ€™t have to be at the same level of insanity that I am, clearly, but this isnâ€™t something you should fake. If youâ€™re not passionate about it, get out while you still can!\n\n\n\n\n\n\nâ€œMe grinding everyday because â€˜coding is a lifestyleâ€™â€\n\n\n\n\n\n\n\nPatience\nThis is the one I hate the most. I am admittedly NOT a patient person. I want to be a data science/R wizard and I wanted that status yesterday. I think of a personal example whenever this comes to mind.\nWhen I first started learning to program in R, I immediately tried to make a Shiny app. Needless to say I failed miserably and had almost quit the journey entirely. I felt so inadequate and not smart at all. I gave R a break for a week or two and realized I really wanted to learn. So I restarted the â€œrightâ€ way and started with the basics. I canâ€™t tell you how long it took to get the basics down, but one day, it really did seem like things were starting to click together.\nSoon, daunting data wrangling and mining became a breeze and an enjoyable puzzle to solve. And while I am far from where I began in my journey, I still have to remember to have patience; especially as I try to navigate these murky â€œnot-beginnerâ€ waters. Having this level of discipline can ensure that you are learning things effectively. For me personally? I just reached the point where I am finally ready to dig into the basics of machine learning and Shiny app development. Iâ€™ll be sure to document these endeavors as I trek through them.\n\nAre you a â€œNot-Beginner?â€ How did you know you werenâ€™t a beginner anymore? If you ARE a beginner, what do you think will put you into that next category of data science â€œproficiencyâ€? Feel free to leave a comment below to share or contact me directly! Respectful discourse is always welcomed!"
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html",
    "href": "post/dull-dashboards/dull-dashboards.html",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "",
    "text": "Donâ€™t have time to read and just want the source code? Click Here\nThe Problem: You want to put cleaned/prepared data into an interactive dashboard but you canâ€™t or donâ€™t want to code with Shiny at the moment.\nThe Fix: You need to use the flexdashboard package and create a markdown document instead."
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html#getting-started",
    "href": "post/dull-dashboards/dull-dashboards.html#getting-started",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "Getting Started:",
    "text": "Getting Started:\nTo start, weâ€™ll look at a cleaned and prepped dataset that includes a mix of categorical and geographic variables. The data is publicly sourced from the New York State Department of Mental Health and contains information for New York Stateâ€™s Local Mental Health Programs.\nFor this example, Iâ€™ve already cleaned and prepped the set. If youâ€™re interested, you can view the cleaning script and geoprocessing* script. Our main purpose for this project is to create a dashboard with a map, filters for the map, and a data table that letâ€™s us view selected data points.\n*The geoprocessing coding in this script came from Dmitry Kislerâ€™s article â€œOSM Nominatim with R: getting Locationâ€™s Geo-coordinates by its Addressâ€ Check it out to learn more about the process if youâ€™d like!\nIf youâ€™d like to follow along within the R project files you can download them from the Tidy Trekker Github Repository. Be sure to fully extract the ZIP. folders for proper access. You can also download the data set used and load it into your own session for practice.\n\n\n\nDirect download link for this postâ€™s example data"
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html#creating-the-markdown-file",
    "href": "post/dull-dashboards/dull-dashboards.html#creating-the-markdown-file",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "Creating the Markdown File",
    "text": "Creating the Markdown File\nIn order to create the dashboard, we need to write out code in an R Markdown file (.RMD) instead of an R Script (.R). If you donâ€™t have the flexdashboard package installed already youâ€™ll want to do that first:\n\n# Installing the flexdashboard package===\ninstall.packages(\"flexdashboard\")                                                    \n\nAfter installing flexdashboard, you should be able to create a new markdown document with the flexdashboard template. You can do so by going to create a new markdown document like you normally wouldâ€¦\n\n\n\n\nCreating a new markdown document in the R Studio IDE\n\n\n\nâ€¦but instead of accepting the default document settings, click on the â€œFrom Templateâ€ option in the left pane, select the â€œFlex Dashboardâ€ template in the right pane, and finally click â€œOKâ€ at the bottom:\n\n\n\n\nR Markdown Template Menu in R Studio IDE\n\n\n\nYouâ€™ll now see a pre-generated Flex Dashboard markdown script! You can use this for practice. If you have some time and are interested, play around with the syntax and get a feel for how changes to this template will affect the final knitted document. You can read up more about Flex Dashboard basics here. If you want more information about different layout options you can find them here. For this guide, weâ€™ll be using the â€œChart Stack (fill)â€ layout."
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html#setting-the-yaml",
    "href": "post/dull-dashboards/dull-dashboards.html#setting-the-yaml",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "Setting the YAML",
    "text": "Setting the YAML\nThe first part of the markdown code that we see is the YAML (Yet Another Markup Language or YAML Ainâ€™t Markup Language) Header. Without getting bogged down with an explanation, this is basically a special block of code thatâ€™s going to tell R how to process our markdown document. Itâ€™s the â€œmagic batteryâ€ thatâ€™s needed to power the translation process that converts code to pretty documents. For this project our YAML looks like this:\n\n---\ntitle: \"New York State's (Brooklyn,NY) Local Mental Health Programs\"\noutput:\n  flexdashboard::flex_dashboard:\n    vertical_layout: fill\n    source_code: embed\n    css: scripts/nycmhstyle.css\n---\n\n\nThe Components of this YAML:\n\nTitle: This is the string that will show up in the top left corner of your dashboard.\nOutput: This is where the document type is set. You can set options for this on the same line, or underneath it (shown here.)\nOutput Options: In this YAML, our options are underneath the â€œoutputâ€ line and are indented. The indents are extremely important. If these options arenâ€™t indented in a hierarchical (ordered) fashion, it will not work! Letâ€™s look at them further:\n\n\n\n Please be mindful that the YAML output options are properly ordered and indented! Youâ€™ll know if itâ€™s not because you will get an error.\n\n\n\nflexdashboard::flex_dashboard: Note how this is tabbed or indented only once under the output option. This tells R we want this document processed as a Flex Dashboard.\nvertical_layout: fill: Also note how itâ€™s indented/tabbed again. This tells R that these are options that we want applied to this dashboard. This option tells R that we want the dashboard to fill the page vertically. This option can also be set to â€œscroll.â€ You can always play around with it and see which is best for your needs.\nsource_code: embed: This option tells R that we want to share our source code on the dashboard. This will appear as a button in the top right corner of the dashboard. If we have source code elsewhere on the internet (like GitHub) you can replace â€œembedâ€ with the actual URL as a string (with quotation marks - â€œhttps://github.com/user/codeâ€)\ncss: scripts/nycmhstyle.css: This option tells R that we want to use an external css file to change the appearance of our flexdashboard. This file is included on the GitHub repository if youâ€™re interested."
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html#configuring-the-setup-code-chunk",
    "href": "post/dull-dashboards/dull-dashboards.html#configuring-the-setup-code-chunk",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "Configuring the â€œSetupâ€ Code Chunk",
    "text": "Configuring the â€œSetupâ€ Code Chunk\nNow that the YAML is set, we need to load in all the packages weâ€™ll use and our data.\n\n\n#Library load in.#\nlibrary(flexdashboard)\nlibrary(knitr)\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.4     âœ” readr     2.1.5\nâœ” forcats   1.0.0     âœ” stringr   1.5.2\nâœ” ggplot2   3.5.2     âœ” tibble    3.3.0\nâœ” lubridate 1.9.4     âœ” tidyr     1.3.1\nâœ” purrr     1.1.0     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(leaflet)\nlibrary(leafem)\nlibrary(crosstalk)\nlibrary(DT)\nlibrary(summarywidget)\nlibrary(raster)\n\nLoading required package: sp\n\nAttaching package: 'raster'\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\n\nThereâ€™s a good amount of packages here. Iâ€™ve already mentioned flexdashboard, leaflet, crosstalk, DT, and summary widgets, but thereâ€™s a few more needed for our particular example: - knitr: Helps with markdown/report generation - leafem: Gives extensions and additional options for the leaflet (map) package. - tidyverse: Group of packages used to aid with data wrangling/manipulation - raster: Helps with geographical data analysis and modelling.\n\nAfter loading in all of the libraries, we can now load in our data. The data for this project is stored as an .RDS object. The original csv file was converted to an .RDS object to ensure reproducibility and maintain integrity of the dataâ€™s structure. The readRDS() function will automatically open the object and restore it as a data frame with all original components intact. This code stores the data frame as MHprograms\n\n\n#Loading the datasets into the environment.#\n#MH programs with geocodes#\n\nMHprograms &lt;- readRDS(\"data/mhprogramsnyc.RDS\")\n\n\nNow that our data is in the environment, we can use the crosstalk package to translate our data into a shared data object. This will allow interactivity between our dashboard components.\n\n#Converting data frames into shared data objects with crosstalk. This will allow the map, filters, and tables to be interactive and dynamic.#\nSharedgeodata &lt;- SharedData$new(MHprograms)"
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html#thinking-about-dashboard-components-and-real-estate",
    "href": "post/dull-dashboards/dull-dashboards.html#thinking-about-dashboard-components-and-real-estate",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "Thinking about Dashboard Components and Real Estate",
    "text": "Thinking about Dashboard Components and Real Estate\nWhen creating our dashboard we must think about the type of data we have and how that data will fill the space on our dashboard. Before thinking about where things will go, we need to think about what would be useful to have on our dashboard. Thereâ€™s 17 variables in the set, but for the sake of this example letâ€™s focus on the following:\n\n Agency Name Program Name Agency Phone Program Address 1 Program State Program Zip Program Category Program Subcategory Populations Served\n\n\nThese variables should be just enough to give the user basic description information about the programs in the data set. Keeping this in mind, we might now start to think about what would be useful to add to our dashboard and map. How about the following?\n\nOn the map itself:\n\nA â€œHome Buttonâ€ - A button that will snap our map view back to our data if we go wondering off in the map.\nConditional Formatting - for map icons based on the program category (i.e.Â different icons based on the program type)\n\nOn the dashboard, separate of the map:\n\nReactive Values - Values that change based on the data thatâ€™s shown on the map. For this example weâ€™ll do a simple â€œcountâ€ of all mental health programs that were found.\nA Simple Data Table - A simple table that can display information about all programs shown on the map.\nFilters - Filters that will limit what locations are seen on the map based on options that the user selects.\n\n When you start to work with flexdashboard more, youâ€™ll learn about the quirks of layout templates and will begin to see whatâ€™s possible. Itâ€™s recommended to take time to understand how you want your components to work and look together. For some people this may mean taking the time to draw on paper or making a â€œmockâ€ dashboard in MS Paint. Whatever your method of planning, just make sure you have a plan! Hereâ€™s our mock plan drawn up for our dashboard:\n\n\n\n\nMock-up Plan for our NY Mental Health Dashboard"
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html#setting-up-our-first-column-and-map",
    "href": "post/dull-dashboards/dull-dashboards.html#setting-up-our-first-column-and-map",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "Setting up our First Column and Map",
    "text": "Setting up our First Column and Map\nSo looking at our mock-up, we just need two columns. One on the left with just a map and one of the right with three modules and some text at the bottom. To set flexdashboard columns in markdown you need to put the following â€œoutsideâ€ of r code chunks in the regular markdown editor:\n\nColumn {data-width=550}\n-----------------------------------------------------------------------\n\n### \n\nBecause we want the first column to be filled with our map, weâ€™ll set the width to be a bit wider than the second column. The series of dashes (â€”) under the â€œcolumnâ€ option along with the three hashes (#) letâ€™s R know to place everything underneath those hashes in itâ€™s own column within itâ€™s own box. The hashes are also where you can place the title of your box within your column. This one will be left blank to maximize the space for the map.\nNow that the column is initialized, we can place more r code chunks underneath it to get our data in. Our first chunk will be for our map. Recall that we designate the beginning of R code chunks with three back-ticks (aka: Grave Accents) and square brackets with options and end them with an additional three back-ticks at the bottom of the chunk:\n```{r map}\n\n```"
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html#creating-the-home-button-bounding-box-and-map-center",
    "href": "post/dull-dashboards/dull-dashboards.html#creating-the-home-button-bounding-box-and-map-center",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "Creating the Home Button, Bounding Box, and Map Center",
    "text": "Creating the Home Button, Bounding Box, and Map Center\nLetâ€™s recall what we wanted on our map. A home button and conditional formatting for program types. Letâ€™s code for our home button to start. Say we want an actual image of a home. Weâ€™ve gone ahead and found a url of one. To create this button, weâ€™ll need to use the HTML function in the htmltools package to use some HTML for this:\n\n\n#Pulling a \"Home\" icon I've hosted on the internet===\nHomeimg &lt;- htmltools::HTML(paste(\"&lt;img src='https://i.ibb.co/D8tSw9q/Homebutton.png' width = '15', height '15', title = 'Home'&gt;\"))\n\n#Naming the home image for the addhomebutton function in the leaflet map===\nHome &lt;- list(\"Home\" = Homeimg)\n\n\nThis code will show us a pretty home icon, but weâ€™ll need to feed the button the bounding box (bbox) so that it knows where to set the mapâ€™s view when itâ€™s clicked on. We can do this easily with the make_bbox function in the ggmap package as long as our data has longitude and latitude columns with numeric values (Ours does!)\n\n\n#Generating a bounding box of the entire data set. This will act as our \"homebase\" to zoom back to when the home button is clicked on===\nhomebase &lt;- ggmap::make_bbox(lon, lat, data = MHprograms)\n\n\nWe may also want to designate a â€œcenterâ€ for our map that is first shown when the dashboard is open. We can do this by using the coordinates and proj4strings functions from the sp package, The extent function from the raster package, and the as function that comes from the methods package that usually loads in with base R.\n\n\n# Retrieving the center point for the map data to set the \"home\" view===\ncoordinates(MHprograms) &lt;- ~lon+lat\nproj4string(MHprograms) &lt;- \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\"\nmapcenter &lt;- coordinates(as(extent(MHprograms), \"SpatialPolygons\"))\n\n\nThe options set in the proj4string line is referring to the Coordinate Reference System that R uses to create our maps. You can learn more about it with some reading material provided by the National Center for Ecological Analysis and Synthesis if youâ€™re interested."
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html#creating-the-actual-map",
    "href": "post/dull-dashboards/dull-dashboards.html#creating-the-actual-map",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "Creating the Actual Map",
    "text": "Creating the Actual Map\nNow we can finally get our map into the column. The code is as follows:\n\n#Creating the leaflet map from the shared geo data object===\nSharedgeodata %&gt;%\n  leaflet() %&gt;%\n  addProviderTiles(providers$OpenStreetMap) %&gt;%\n  addAwesomeMarkers(\n    popup = ~paste0(\n      \"&lt;b&gt;&lt;h3&gt;\",MHprograms$`Agency Name`, \"&lt;/h3&gt;&lt;/b&gt;&lt;br&gt;\",\n      \"&lt;h4&gt;\",MHprograms$`Program Name`,\"&lt;/h4&gt;&lt;br&gt;\",\n      \"Phone: \",MHprograms$`Agency Phone`, \"&lt;br&gt;\",\n      MHprograms$`Program Address 1`, \"&lt;br&gt;\",\n      MHprograms$City, MHprograms$`Program State`, MHprograms$`Program Zip`), \n    icon = awesomeIcons(\n      library = \"fa\",\n      icon = ifelse(\n        test = MHprograms$`Program Category Description` == \"Outpatient\", \n        yes = \"fa-stethoscope\",\n        no = ifelse(\n        test = MHprograms$`Program Category Description` == \"Inpatient\", \n        yes =  \"fa-bed\",\n        no = ifelse(\n        test = MHprograms$`Program Category Description` == \"Emergency\", \n        yes = \"fa-ambulance\",\n        no = \"fa-users\"\n      ))),\n      iconColor = \"#ffffff\",\n      markerColor = \"darkpurple\")) %&gt;%\n  addHomeButton(ext = homebase, \n                group = Home,\n                position = \"topright\") %&gt;%\n  setView(lng = mapcenter[1] , lat = mapcenter[2], zoom = 12)\n\n\nThis part of the code starts out by using a pipe operator (%&gt;%) to connect our leaflet map functions to our shared data object Sharedgeodata. Letâ€™s break down the main functions we have here:\n\n\nleaflet(): Initiates our leaflet map widget.\naddProviderTiles(): This draws on actual map tiles to create a basemap. In this example we are using OpenStreetMaps. Being as this is Leafletâ€™s default, we could replace this with addTiles() with no options set inside and it would produce the same result.\naddAwesomeMarkers(): This allows us to add markers on our map with custom color and icons on them.\n\nArguments within the addAwesomeMarkers() function:\n\npopup = This is the text that will popup when a marker is clicked on. You can paste data from the original data set that was converted into a shared data object (in this case, the MHprograms set). In this example, weâ€™re pasting the Agency Name, Program Name, Phone Number and Address associated with each marker (observation) in the data set. Iâ€™m utilizing HTML here to assist with formatting because I did not spend years learning it on Myspace for nothing. If youâ€™d like to learn more about HTML basics you can do so here.\nicon = These are the options that we set for our icons that show up on our marker. For this example we are using an additional function awesomeIcons() which will allow us to further customize the icons that are shown on our markers. In this function we have two additional arguments (library= & icon=.) In this example we set library= to \"fa\" because we are using the Font Awesome library. Our icon argument is set to an ifelse function because we want the icons to change conditionally based on the type of program we are displaying at the marker.\niconcolor = & markercolor = Self-explanatory. Changes the color of the icon in the marker and the marker itself.\naddHomeButton(): This allows us to add a â€œhome/zoom toâ€ button onto our map. Recall that we did some work for this already. This is where we fill in details to make the magic happen.\n\n Arguments within the addHomeButton() function:\n\next = This is the extent variable or bounding box that youâ€™d like the home button to take the user to when clicked on. We already created our bounding box earlier and named it homebase.\ngroup = This is the group or layer that will be shown in the home button on the map. A character string is expected here. Because we wish to use the home icon for our button that we set up earlier, we use the name we set it to earlier (home). This tells R to place our picture there instead of the text â€œhome.â€\nposition = Self-explanatory. This lets us choose where our home button will be displayed on the map. The options are topleft, topright, bottomleft, or bottomright. The default is bottomright.\nsetView(): This allows us to determine the view that is seen when the map is open. lng and lat refer to longitude and latitude respectively. We can pull these values from the object weâ€™ve already created called mapcenter. We do this by subsetting the first and second elements of mapcenter which is our longitude and lattiude values for the center of all of our data. We can also set the zoom level with the zoom argument. The zoom scale for Leaflet goes from 0-18 with 0 being a view of the entire world and 18 being the closest you can get to a â€œstreetâ€ view."
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html#setting-up-our-second-column",
    "href": "post/dull-dashboards/dull-dashboards.html#setting-up-our-second-column",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "Setting up our Second Column",
    "text": "Setting up our Second Column\n\nReactive Summary Count of Records\nGreat! Our first column is done. Now we need to create our second (right) column. Looking at our mock-up will let us know what order we wanted our elements to appear in. The first element is a reactive count of the amount of locations that are present on our map at any given time. Because we are creating a new column, we can repeat the same coding header we used for the last column with some tweaks to the sizing. Weâ€™ll make this column smaller because we want the map to take up most of the space on the page. Weâ€™ll get our reactive count by using the summarywidget function:\n\n#Start of the second Column\nColumn {data-width=450}\n-----------------------------------------------------------------------\n\n### **Total Locations Found:** {data-height=70}\n&lt;center&gt;&lt;h4&gt;&lt;font color=\"#593869\"&gt;&lt;b&gt;`r summarywidget(Sharedgeodata, statistic='count', digits=0)`&lt;/b&gt;&lt;/font&gt;&lt;/h4&gt;&lt;/center&gt;\n\n\nRecall that we tell R that we want to create a box within our column with the three hashes (###). This time we will give it the name â€œTotal Location Found:â€ and we will bold it by wrapping it in two asterisks (If you need a quick cheat sheet for R Markdown formatting, you can find one here!) We will also set the height of this box which is similar to setting widths of columns.\nUsing some HTML tags, we can center and change the size and color of the inline code we are using. In R Markdown, if you would like to insert R code to be evaluated within the lines of your markdown document, you can use backticks with an â€œrâ€ inside of it before the code you wish to evaluate. Letâ€™s pull this inline code out and look at whatâ€™s happening really quick:\n\n\n`r summarywidget(Sharedgeodata, statistic='count', digits=0)`\n\n\nThe first backtick and â€œrâ€ letâ€™s R know that itâ€™s about to evaluate whatever comes next and then print that result in the markdown document as if itâ€™s not code, meaning itâ€™ll just print out the result. The summarywidget function is interacting with our shared data object Sharedgeodata to grab our statistic of choice (a count) for the records that are available at any given time. Because this is the same shared data object thatâ€™s used in our map (and our data table and filters that weâ€™ll create in a moment), whenever anything on the dashboard is changed, this value with reactively change as well. Finally, we also set the digits in this function to zero to avoid any decimal numbers.\n\n\n\nCreating a Simple Reactive Data Table\nWe can now move on to our next box which is a data table. We set it up similarly with the hashes and set the data height like we did for the previous box. To display a data table, weâ€™ll now use the datatable function from the DT package. Note that this code will go into itâ€™s own R code chunk named datatable.\n\n\n### **Program Information:** {data-height=200}\n\n```{r datatable}\nSharedgeodata %&gt;% \n  datatable(\n    rownames = FALSE,  \n    style = \"bootstrap\",\n    class = \"compact\",\n    selection = \"multiple\",\n    options = list(\n      dom = \"tip\", \n      columnDefs = list(\n        list(width = '50%',\n          visible = FALSE,\n          targets = c(0,4:13,15:16))),\n    colnames = c(\n      \"Location Name\" = \"Program Name\",\n      \"Ages Served\" = \"Populations Served\",\n      \"Phone Number\" = \"Program Phone\",\n      \"Address\" = \"Complete Address\"\n      ))) \n```\n\nAfter using the pipe operator (%&gt;%) to link to our shared data object Sharedgeodata, we use the datatable() function to make our table. Thereâ€™s a lot going on here so letâ€™s break it down:\n\n\nrownames = Simply the option for controlling the row names on the table. You can also set this to a character vector with the strings desired in it.\nstyle = The table style youâ€™d like. You can learn more about the DT table styles here. Sources say that R can only utilize the options \"default\", \"bootstrap\", and \"bootstrap4\" at this time.\nselection = Controls how many rows/columns the user can select at a time. Options are \"multiple\", \"single\", and \"none\".\noptions = This contains a list of options used to initialize our data table. Letâ€™s break the options down further:\n\n Arguments within options=:\n\ndom = This is the Document Object Model for the table and can be seen in JavaScript usually. This is how we can get things like the actual table, pagination control, and more. For our example weâ€™ve set it to â€œtipâ€. This translates to t-â€œtableâ€, i-â€œtable information summaryâ€, and p-â€œpagination controlâ€. These options can be placed in any order you wish, but it will affect the order in which itâ€™s layered onto the dashboard. In this example our table gets printed first, then our information summary with the pagination buttons at the very bottom. To learn more about possible DOM options, you can read more about them here.\ncolumnDefs = These are the options we apply specifically to our columns. Note that R needs this info within a nested list (a list within a list) to interpret it properly. width = simply controls the sizing of the columns in the table. You can play around with this to see which percentage is better for your needs. visible = tells R whether or not we want specific columns to be shown or not. We have ours set to FALSE because we want R to hide most of our columns. targets = is where we tell R which columns to hide with the column index numbers. Note that the indexing within datatable arguments are zero-based. Meaning that the first column in the dataset is considered index â€œ0â€ instead of index â€œ1â€ like R normally does.\ncolnames = Self-explanatory. This is a vector of names that you want shown in the table. The function expects the name you want displayed first set to the name of the column in the actual data set."
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html#setting-up-reactive-filters",
    "href": "post/dull-dashboards/dull-dashboards.html#setting-up-reactive-filters",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "Setting up Reactive Filters",
    "text": "Setting up Reactive Filters\n\nCreating a Checkbox Filter\nWe can finally set up our filters that will interact with our map and data table. We do so by creating a new box in our dashboard. Weâ€™ll bold its title and name it â€œMap Filters:â€.\n\n\n### **Map Filters:**\n&lt;center&gt;\n\n```{r mapfilters}\n\n  filter_checkbox(\n    id = \"Program Category Description\",\n    label = \"Program Type\",\n    sharedData = Sharedgeodata,\n    group = ~`Program Category Description`,\n    inline = TRUE\n  )\n\n```\n&lt;/center&gt;\n\nWeâ€™ve wrapped the R code block in some HTML tags to center the filter within the box. Using the crosstalk package, we can create our filter with the filter_checkbox() function.\nArguments within filter_Checkbox():\nid = Reserved for element IDs. In this example we use the datasetâ€™s column name that we want to filter on.\nlabel = Expects a character string that will be shown on the actual dashboard.\nsharedData = Where we put our shared data object we created (the same object thatâ€™s used in the datatable and map).\ngroup = Is where we put a formula that will be used for filling the data within this particular filter. Normally this is just a column thatâ€™s either filled with factors or character vectors. The tilde (~) letâ€™s R know it needs to interpret it as a function. In our example, our data is already cleaned and prepared for use but in other cases where special selections need to be made, you can enter more complicated functions on a column to achieve your desired result.\ninline = Tells R whether to display the filter options horizontally (TRUE) or vertically (FALSE).\n\n\n\nCreating Selection Filters\n\nSelection filters are very similar in itâ€™s syntax but will display the options in a drop-down menu instead:\n\n```{r mapfilters2}\n\n  filter_select(\n    id = \"Program Subcategory Description\",\n    label = \"Program Setting\",\n    sharedData = Sharedgeodata,\n    group = ~`Program Subcategory Description`,\n    multiple = TRUE\n  )\n\n```\n```{r mapfilters3}\n\n  filter_select(\n    id = \"Populations Served\",\n    label = \"Ages Served\",\n    sharedData = Sharedgeodata,\n    group = ~`Populations Served`,\n    multiple = FALSE\n  )\n\n```\n\nNote that we have two more R code chunks. Both of these filters could go in one code chunk, but I personally like to break my filters up into different chunks for easier debugging if things go wrong. Itâ€™s a matter of preference. The code for the filter_select() function is very similar to the filter_checkbox() function we just used. The only addition is that of the multiple = argument. This dictates whether the user can select multiple options at once. For example purposes, weâ€™ve set our Program Setting filter to TRUE for this (meaning we can select multiple options) and weâ€™ve set our Ages Served filter to FALSE (meaning we can only select one option at a time)."
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html#finishing-up-the-dashboard",
    "href": "post/dull-dashboards/dull-dashboards.html#finishing-up-the-dashboard",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "Finishing up the Dashboard",
    "text": "Finishing up the Dashboard\nTo finish up this dashboard, you can add some brief information about the data and itâ€™s source. I feel this code chunk is a perfect example of some of flexdashboard limitations:\n         Data provided by the New York State Office of Mental Health and found publicly on DATA.NY.GOV  Example created by  Meghan Harris with the flexdashboard,  Crosstalk,  SummaryWidget, and DT packages.\n````\n\nYou can see the finished dashboard in action on the github repo here.\n\n\n\n\nFinished FlexDashboard"
  },
  {
    "objectID": "post/dull-dashboards/dull-dashboards.html#limitations",
    "href": "post/dull-dashboards/dull-dashboards.html#limitations",
    "title": "Making Dull* Dashboards in R (* Without Shiny)",
    "section": "Limitations",
    "text": "Limitations\n\nWhile flexdashboard is great because it allows you to whip up some great dashboards without shiny, you are confined to the environment set by the template. It calls for some â€œhackingâ€ sometimes and if you want your dashboard appearance to be customized (color/themes), some knowledge in CSS/HTML will make it an easier process. You can also use preset themes to change the appearance of your dashboard as well.\nSizing is also a tricky issue with flexdashboards. Because the template uses a browser-based flexbox engine, the sizing will vary based on things like browser window and user monitor size. Youâ€™ll also have to consider mobile layouts for viewing the dashboard on mobile devices if this is of interest. Despite the limitations, flexdashboards can be pretty useful and a less intimidating way for those without experience in Shiny to start making dashboards in R.\nLastly, special thanks to Matt Dray for his presentation and work on these packages! Heâ€™s the reason I found flexdashboards!\nHave you ever used flexdashboards before? Have any thoughts or suggestions? Know of a better solution or way to make this script more efficient? Feel free to contact me directly! Respectful discourse towards efficient solutions or new insights is always welcomed!"
  },
  {
    "objectID": "post/applyfamilynotes/apply-family.html#data-frame-example",
    "href": "post/applyfamilynotes/apply-family.html#data-frame-example",
    "title": "Apply Family Notebook",
    "section": "Data Frame Example",
    "text": "Data Frame Example\n#Creating a mock data frame\nCity &lt;- c(\"Buffalo\",\"NYC\",\"Seattle\",\"Austin\",\"Orlando\",\"Minneapolis\")\nCases &lt;- c(500,2012,1876,635,4512,823)\nControls &lt;- c(3426,5210,6753,5633,2013,1890)\n\nrecords &lt;- data.frame(City,Cases,Controls, row.names = NULL)\n\nrecords\n##          City Cases Controls\n## 1     Buffalo   500     3426\n## 2         NYC  2012     5210\n## 3     Seattle  1876     6753\n## 4      Austin   635     5633\n## 5     Orlando  4512     2013\n## 6 Minneapolis   823     1890\n\nWe can use the apply function to calculate column sumsâ€¦\n\n#Calculating the column sum of all applicable columns\napply(records[,2:3], 2,sum)\n##    Cases Controls \n##    10358    24925\n\nâ€¦Or row sums. (Note that these both produce vectors and that we subset the dataframe with [,2:3] to avoid R throwing an error for the first column that has strings in it. Canâ€™t perform a mathematical function on character strings)\n\n#Calculating row sums\napply(records[,2:3], 1,sum)\n## [1] 3926 7222 8629 6268 6525 2713\n\nWe can name the vectors in one line of code with the names&lt;- function:\n\n#Calculating row sums, but applying names from the \"City\" column\n`City Totals` &lt;-  `names&lt;-`(apply(records[,2:3], 1,sum), records$City)\n\n`City Totals`\n##     Buffalo         NYC     Seattle      Austin     Orlando Minneapolis \n##        3926        7222        8629        6268        6525        2713"
  },
  {
    "objectID": "post/applyfamilynotes/apply-family.html#applying-statistic-more-complex-functions",
    "href": "post/applyfamilynotes/apply-family.html#applying-statistic-more-complex-functions",
    "title": "Apply Family Notebook",
    "section": "Applying Statistic (More Complex) Functions",
    "text": "Applying Statistic (More Complex) Functions\n\nWe can also do different statistical procedures based on each testâ€™s requirement. Letâ€™s do a T-test:\n\n#Making a mock data set for T-test\nEx1_grades &lt;- c(67,53)\nEx2_grades &lt;- c(90,89)\nEx3_grades &lt;- c(89,95)\nEx4_grades &lt;- c(95,87)\nEx5_grades &lt;- c(100,99)\nStudent &lt;- c(\"Student1\",\"Student2\")\n\nGrades &lt;- tibble(Student,Ex1_grades,Ex2_grades,Ex3_grades,Ex4_grades,Ex5_grades)\n\nGrades\n## # A tibble: 2 x 6\n##   Student  Ex1_grades Ex2_grades Ex3_grades Ex4_grades Ex5_grades\n##   &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n## 1 Student1         67         90         89         95        100\n## 2 Student2         53         89         95         87         99\n\nLetâ€™s just say we want the P.value of one sample T-tests for each student and we want to place it in this dataset as a new column. Whatâ€™s important to note is that arguments that would normally be passed through to your functions, go as separate arguments at the end of the apply function, after you declare which function you want used.\n\n#Turning off scientific notation formatting\noptions(scipen = 999)\n\n#Getting index of columns that end with the word \"grades\"\nGradeindexes &lt;- grep((\"grades$\"),names(Grades))\n\n#Using apply to apply the t.test.\ntestresults &lt;- apply(Grades[,Gradeindexes],1,t.test, alternative = \"two.sided\", conf.level = 0.95)\n\n#Using do.call to bind p values to the data set. Because results are in a list, we can use lapply and wrap it in \"as.vector\" for clean transfer into the dataframe\n\nGrades$`P Values` &lt;- as.vector(format(do.call(rbind, lapply(testresults, function(x){x$p.value})), digits = 2))\n\nGrades\n## # A tibble: 2 x 7\n##   Student  Ex1_grades Ex2_grades Ex3_grades Ex4_grades Ex5_grades `P Values`\n##   &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;     \n## 1 Student1         67         90         89         95        100 0.000098  \n## 2 Student2         53         89         95         87         99 0.000494"
  },
  {
    "objectID": "post/applyfamilynotes/apply-family.html#data-frame-example-1",
    "href": "post/applyfamilynotes/apply-family.html#data-frame-example-1",
    "title": "Apply Family Notebook",
    "section": "Data Frame Example",
    "text": "Data Frame Example\n\nWe can use lapply to make changes to a data frame.\n\n# Changing column names in the \"records\" data frame to be all CAPS\n\nnames(records) &lt;- lapply(names(records),str_to_upper)\n\nrecords\n##          CITY CASES CONTROLS\n## 1     Buffalo   500     3426\n## 2         NYC  2012     5210\n## 3     Seattle  1876     6753\n## 4      Austin   635     5633\n## 5     Orlando  4512     2013\n## 6 Minneapolis   823     1890"
  },
  {
    "objectID": "post/applyfamilynotes/apply-family.html#list-example",
    "href": "post/applyfamilynotes/apply-family.html#list-example",
    "title": "Apply Family Notebook",
    "section": "List Example",
    "text": "List Example\n\nWe can use lapply to make changes to a list. Need to create a mock list.\n\n#Creating list from randomly sampled numbers, then adding names from the \"fruit\" constant that comes with base R\n\n#Setting a seed for reproducibility\nset.seed(555)\n\n#Generating the random sample of numbers\nstock &lt;- sample(1:50,5)\n\n#Pulling the first five strings of the fruit constant from base R\nfruits &lt;- fruit[1:5]\n\n#Coercing the sampled numbers into a list  \nInventory &lt;- as.list(as.numeric(stock))\n\n#Setting the names of each randomly sampled number to each string in out fruits vector\nnames(Inventory) &lt;- fruits\n\nInventory\n## $apple\n## [1] 42\n## \n## $apricot\n## [1] 49\n## \n## $avocado\n## [1] 24\n## \n## $banana\n## [1] 16\n## \n## $`bell pepper`\n## [1] 29\n\nWe can alter the list by adding 100 to each fruitâ€™s count and assigning the result back to Inventory:\n\nInventory &lt;- lapply(Inventory, function(x) (x+100))\n\nInventory\n## $apple\n## [1] 142\n## \n## $apricot\n## [1] 149\n## \n## $avocado\n## [1] 124\n## \n## $banana\n## [1] 116\n## \n## $`bell pepper`\n## [1] 129"
  },
  {
    "objectID": "post/applyfamilynotes/apply-family.html#multiple-list-example",
    "href": "post/applyfamilynotes/apply-family.html#multiple-list-example",
    "title": "Apply Family Notebook",
    "section": "Multiple List Example",
    "text": "Multiple List Example\nWe can use mapply() to alter different elements within multiple lists, as oppose to lapply() which only works within one list. Letâ€™s create multiple lists to test mapply() out.\n#Want to take these separate list, add th last name \"Smith\" to all the names, then get the final result in one place (a list)\n\nnames1 &lt;- list(\"John\", \"Abigail\", \"Sam\",\"Judy\")\nnames2 &lt;- list(\"Mary\", \"Lauri\", \"Gus\")\nnames3 &lt;- list(\"Harold\", \"Peter\", \"Natalie\",\"Scott\",\"Fatima\")\n\n`Names List` &lt;- mapply(function(x) paste(x,\"Smith\"), c(names1,names2,names3))\n\n`Names List`\n##  [1] \"John Smith\"    \"Abigail Smith\" \"Sam Smith\"     \"Judy Smith\"    \"Mary Smith\"    \"Lauri Smith\"   \"Gus Smith\"     \"Harold Smith\"  \"Peter Smith\"   \"Natalie Smith\" \"Scott Smith\"   \"Fatima Smith\""
  },
  {
    "objectID": "post/applyfamilynotes/apply-family.html#multiple-vector-example",
    "href": "post/applyfamilynotes/apply-family.html#multiple-vector-example",
    "title": "Apply Family Notebook",
    "section": "Multiple Vector Example",
    "text": "Multiple Vector Example\nMapply() can be used to vectorize function results from multiple vectors.\nLetâ€™s same we have vectors of numbers and we want to know the mean of all of them separately:\n\n#Making mock vectors, setting a seed for reproducibility.\nset.seed(321)\n\n#Assigning the vectors\nvector1 &lt;- sample(1:100,12)\nvector2 &lt;- sample(1:100,5)\nvector3 &lt;- sample(1:100,9)\n\nvector1\n##  [1] 54 77 88 80 58 17 47 11 25 31 82 79\nvector2\n## [1] 98 75 31 82 36\nvector3\n## [1] 78 87 34 84  4 48 51 80 13\n\nBecause we want summaries (the mean) of each vector, we can use the list() function instead of the c() function. We can use the MoreArgs argument to pass the trim argument to the mean() function. By default, this is set at zero, but passing it through to demonstrate.\n\n#Calculating the mean of each vector\nvectormeans &lt;-mapply(mean,list(vector1,vector2,vector3), MoreArgs = list(trim = 0))\n\n#Setting names to the results\nnames(vectormeans) &lt;- c(\"vector1\",\"vector2\",\"vector3\")\n\nvectormeans\n##  vector1  vector2  vector3 \n## 54.08333 64.40000 53.22222"
  },
  {
    "objectID": "post/applyfamilynotes/apply-family.html#nested-list-example",
    "href": "post/applyfamilynotes/apply-family.html#nested-list-example",
    "title": "Apply Family Notebook",
    "section": "Nested list example",
    "text": "Nested list example\nLetâ€™s say we have a list of cities that have a list of restaurant types embedded in them:\nRestaurantdata &lt;- list(\"Buffalo\" = list(\"italian\",\"mexican\",\"japanese\",\"puerto rican\"),\n                       \"Seattle\" = list(\"japanese\",\"chinese\",\"southern\",\"steakhouse\"),\n                       \"Miami\" = list(\"seafood\",\"cuban\",\"italian\",\"polish\"))\n\nRestaurantdata\n## $Buffalo\n## $Buffalo[[1]]\n## [1] \"italian\"\n## \n## $Buffalo[[2]]\n## [1] \"mexican\"\n## \n## $Buffalo[[3]]\n## [1] \"japanese\"\n## \n## $Buffalo[[4]]\n## [1] \"puerto rican\"\n## \n## \n## $Seattle\n## $Seattle[[1]]\n## [1] \"japanese\"\n## \n## $Seattle[[2]]\n## [1] \"chinese\"\n## \n## $Seattle[[3]]\n## [1] \"southern\"\n## \n## $Seattle[[4]]\n## [1] \"steakhouse\"\n## \n## \n## $Miami\n## $Miami[[1]]\n## [1] \"seafood\"\n## \n## $Miami[[2]]\n## [1] \"cuban\"\n## \n## $Miami[[3]]\n## [1] \"italian\"\n## \n## $Miami[[4]]\n## [1] \"polish\"\n\nWe want to change all of the elements so that each restaurant type is capitalized. We can do this with either the tools or stringr packages. Iâ€™ll use the stringr package for this example. Note that the \"replace\" option in the how argument will actually alter the Restaurantdata list, but in order to save it as such, we have to assign in back to the Restaurantdata object.\n\nRestaurantdata &lt;- rapply(Restaurantdata,stringr::str_to_title,how = \"replace\")\n\n\nRestaurantdata\n## $Buffalo\n## $Buffalo[[1]]\n## [1] \"Italian\"\n## \n## $Buffalo[[2]]\n## [1] \"Mexican\"\n## \n## $Buffalo[[3]]\n## [1] \"Japanese\"\n## \n## $Buffalo[[4]]\n## [1] \"Puerto Rican\"\n## \n## \n## $Seattle\n## $Seattle[[1]]\n## [1] \"Japanese\"\n## \n## $Seattle[[2]]\n## [1] \"Chinese\"\n## \n## $Seattle[[3]]\n## [1] \"Southern\"\n## \n## $Seattle[[4]]\n## [1] \"Steakhouse\"\n## \n## \n## $Miami\n## $Miami[[1]]\n## [1] \"Seafood\"\n## \n## $Miami[[2]]\n## [1] \"Cuban\"\n## \n## $Miami[[3]]\n## [1] \"Italian\"\n## \n## $Miami[[4]]\n## [1] \"Polish\"\n\nWe can also get a vector of our results by using the unlist option in the how function instead. Letâ€™s add the word â€œrestaurantsâ€ to each of these elements then unlist the object to place it in a vector.\n\nRestaurantvector &lt;- rapply(Restaurantdata,function(x) paste(x,\"restaurants\"),how = \"unlist\")\n\n\nRestaurantvector\n##                   Buffalo1                   Buffalo2                   Buffalo3                   Buffalo4                   Seattle1                   Seattle2                   Seattle3                   Seattle4                     Miami1                     Miami2                     Miami3                     Miami4 \n##      \"Italian restaurants\"      \"Mexican restaurants\"     \"Japanese restaurants\" \"Puerto Rican restaurants\"     \"Japanese restaurants\"      \"Chinese restaurants\"     \"Southern restaurants\"   \"Steakhouse restaurants\"      \"Seafood restaurants\"        \"Cuban restaurants\"      \"Italian restaurants\"       \"Polish restaurants\""
  },
  {
    "objectID": "post/applyfamilynotes/apply-family.html#data-frame-example-2",
    "href": "post/applyfamilynotes/apply-family.html#data-frame-example-2",
    "title": "Apply Family Notebook",
    "section": "Data Frame Example",
    "text": "Data Frame Example\nWe can use tapply() to apply a function across a column in a dataframe. Letâ€™s make a simple data frame:\n# Setting a seed for reproducibility\nset.seed(789)\n\nTeams &lt;- c(\"UK\",\"USA\",\"Egypt\",\"Ireland\",\"UK\",\"USA\",\"USA\")\nSeconds &lt;- runif(length(Teams), min=30, max = 240)\nRunners &lt;- data.frame(Teams,Seconds)\n\nRunners\n##     Teams   Seconds\n## 1      UK 176.97782\n## 2     USA  49.63476\n## 3   Egypt  32.49623\n## 4 Ireland 154.23733\n## 5      UK 133.35138\n## 6     USA  34.23435\n## 7     USA 150.25773\n\nLetâ€™s say we want to calculate the average time (seconds) for each Team. We can use tapply() for this.\n\nRunner_means &lt;- tapply(Runners$Seconds, Runners$Teams, mean)\n\nRunner_means\n##     Egypt   Ireland        UK       USA \n##  32.49623 154.23733 155.16460  78.04228\n\nThe results are stored into an array. If a new table is desired it can be manipulated to do so:\n\nRunners_summary &lt;- data.frame(Team = names(Runner_means), Mean =Runner_means, row.names = NULL)\n\nRunners_summary\n##      Team      Mean\n## 1   Egypt  32.49623\n## 2 Ireland 154.23733\n## 3      UK 155.16460\n## 4     USA  78.04228"
  },
  {
    "objectID": "post/applyfamilynotes/apply-family.html#jagged-vectors-example",
    "href": "post/applyfamilynotes/apply-family.html#jagged-vectors-example",
    "title": "Apply Family Notebook",
    "section": "Jagged Vectors Example",
    "text": "Jagged Vectors Example\n\nWe can use tapply() to also preform tasks across multiple vectors of different lengths as long as the amount of factors matches the amount of the elements overall in each vector\n\n#Create a list of factors \nNames &lt;- c(\"Meghan\",\"Gus\",\"Jennifer\",\"Gus\",\"Jennifer\",\"Natalie\",\"Meghan\",\"Jennifer\",\"Gus\",\"Natalie\")\n\nScores1 &lt;- c(90,67,88,99,100)\nScores2 &lt;- c(99,99,78)\nScores3 &lt;- c(100,78)\n\n#Placing them together gives us a vector that has a length of 10. Same as the \"Names\" vector\nTest_scores &lt;- c(Scores1,Scores2,Scores3)\n\n#We can now apply the same function across this vectors and get summarized results\nTest_averages &lt;- tapply(Test_scores,Names,mean)\n\nTest_averages\n##      Gus Jennifer   Meghan  Natalie \n## 88.66667 88.66667 94.50000 88.50000"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "The Tidy Trekker",
    "section": "",
    "text": "My First Time Vibe-Confâ€™ing\n\n\nposit::conf(2025) was the first conference Iâ€™ve been to where I could just â€œvibeâ€ Hereâ€™s my personal recap of how that went.\n\n\n\n\n\nSep 22, 2025\n\n\nMeghan Harris\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\nArtpack 0.2.0\n\n\n{artpack} 0.2.0 is now on CRAN ğŸ‰\n\n\n\n\n\nSep 17, 2025\n\n\nMeghan Harris\n\n14 min\n\n\n\n\n\n\n\n\n\n\n\nGit Stash for Newbies.\n\n\nIn this post, weâ€™ll look at the basics of git stash, how to create and use Git stashes, why youâ€™d want to use stashes in the first place, and other relevant things to know about git stash because maybe one day, you might not feel like committing half-baked work to your repository while jumping between Git branches. ğŸ¤¸ğŸ¾â€â™€ï¸\n\n\n\n\n\nFeb 17, 2025\n\n\nMeghan Harris\n\n17 min\n\n\n\n\n\n\n\n\n\n\n\nMaking Circular Maps in ggplot\n\n\nI made a circular map cutout in ggplot and had it printed for my best friend. Letâ€™s talk about how I did that.\n\n\n\n\n\nFeb 15, 2023\n\n\nMeghan Harris\n\n31 min\n\n\n\n\n\n\n\n\n\n\n\nLetâ€™s Talk About 2022\n\n\nYes. Hi. Hello. Itâ€™s been over a year since Iâ€™ve blogged. Letâ€™s have a chat about 2022.\n\n\n\n\n\nJan 23, 2023\n\n\nMeghan Harris\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\nMaking Waves in ggplot: An Rtistry Tutorial\n\n\nAn Rtistry tutorial in ggplot about making waves in the R programming language.\n\n\n\n\n\nNov 24, 2021\n\n\nMeghan Harris\n\n16 min\n\n\n\n\n\n\n\n\n\n\n\nThinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.\n\n\nRecently Iâ€™ve discovered the courage to dive into creative coding and generative aRt in R. Something that the R community calls â€œRtistry.â€ My Rtistry journey so far has been an amazing and tranquil expedition into a world that seemed intimidating and scary on the outside but is honestly just a bottomless pit of fun and creativity on the inside.\n\n\n\n\n\nOct 19, 2021\n\n\nMeghan Harris\n\n37 min\n\n\n\n\n\n\n\n\n\n\n\nWhere Have I Been?\n\n\nSo, it has been a good five months since I last made a post on The Tidy Trekker. I can assure you that I am alive and kicking!\n\n\n\n\n\nSep 7, 2021\n\n\nMeghan Harris\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\nMaking My First Shiny App\n\n\nThis year was the first time that I ever competed in a RStudio Shiny competition by submitting my first ever Shiny app, the TarotreadR.\n\n\n\n\n\nSep 4, 2021\n\n\nMeghan Harris\n\n14 min\n\n\n\n\n\n\n\n\n\n\n\nTallying â€œCheckboxâ€ Survey Responses: R Walkthrough\n\n\nA guide on how to split up comma-separated survey responses in R using the grepl function in base R and various tidyverse packages . A common issue when processing â€œCheckboxâ€ question types. This guide assumes that you understand how to load data into R, work with vectors, and work with basic control and loop functions.\n\n\n\n\n\nMar 18, 2021\n\n\nMeghan Harris\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\nMaking Dull* Dashboards in R (* Without Shiny)\n\n\nA walkthrough on taking prepared data and creating an interactive dashboard in R without the use of Shiny. The leaflet, flexdashboard, crosstalk, DT, and SummaryWidget packages will be used for this. This guide assumes that you are somewhat familiar with Rmarkdown and knitting markdown code.\n\n\n\n\n\nMar 15, 2021\n\n\nMeghan Harris\n\n25 min\n\n\n\n\n\n\n\n\n\n\n\nHow I Became A â€œNot-Beginnerâ€ in R\n\n\nSome thoughts I have on being a â€œNot-beginnerâ€ (Intermediate) R programmer/Data Scientist.\n\n\n\n\n\nFeb 20, 2021\n\n\nMeghan Harris\n\n11 min\n\n\n\n\n\n\n\n\n\n\n\nApply Family Notebook\n\n\nAn apply() function notebook to explore the different apply functions in Base R\n\n\n\n\n\nJan 23, 2021\n\n\nMeghan Harris\n\n33 min\n\n\n\n\n\n\n\n\n\n\n\nOrdering Months\n\n\nA guide on ordering month â€œcategoriesâ€ chronologically and dealing with missing month data on a ggplot using Tidyverse packages and base R constants. This guide assumes that you understand how to load data into R, work with vectors, and are somewhat familiar with subsetting and ggplot2.\n\n\n\n\n\nJan 23, 2021\n\n\nMeghan Harris\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\nI Participated in My First Tidy Tuesday! : Project Recap\n\n\nI have always â€œhid in the shadowsâ€ with community challenges like this, but I took the leap and participated. Hereâ€™s a quick recapâ€¦\n\n\n\n\n\nJan 6, 2021\n\n\nMeghan Harris\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\nSetting Intentions\n\n\nAs the fiasco that is the year 2020 comes to an end, I figured Iâ€™d set some intentions for the Tidy Trekker site moving forward.\n\n\n\n\n\nDec 31, 2020\n\n\nMeghan Harris\n\n4 min\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I'm an R Engineer and Data Scientist at the Prostate Cancer Clinical Trials Consortium (PCCTC) at Memorial Sloan Kettering Cancer Center, where I fulfil the data needs of various prostate clinical trials while also developing and maintaining R packages with comprehensive test coverage and automated CI/CD pipelines to support our data infrastructure.\nI'm passionate about development quality, reproducible research, and building tools that make data work more reliable and accessible. My technical interests focus on package development, automated testing, data validation systems, and creating maintainable software.I'm the author of artpack (available on CRAN, and I've had the privilege of speaking publicly on topics ranging from Git workflows to generative art to data pipelines. I'm an advocate for open-source software, thorough testing practices, and thoughtful error messaging that helps users just focus on their goals.\nCurrently, I'm expanding my skills into Python package development and cross-language testing approaches. I use this platform to share my work, connect with the R and data science communities, and document my learning journey.\nWhen I'm not coding, I love creating generative art (rtistry), playing video games, traveling, and spending time with my son, my husband, and my Patterdale terrier, Patches."
  },
  {
    "objectID": "post/artpack-0-2-0/artpack-0-2-0.html",
    "href": "post/artpack-0-2-0/artpack-0-2-0.html",
    "title": "Artpack 0.2.0",
    "section": "",
    "text": "In this post:\n\nWhat is artpack?\nGeospatial Tools\nGroup Tools\nSequencing Tools\nTransformation Tools\nColor Tools\nMore Vignettes\nReminder\n\n\n\nWhat is artpack?\nartpack is a â€œnew-ishâ€ R package created to help generative artists of all levels create generative art in R. The artpack package is intended for use with the tidyverse suite, more specifically with the ggplot2 package. artpack aims to simplify the process of creating generative art while providing increased control over the actual data thatâ€™s used to create art on a ggplot. artpack does this by providing tools that create and transform data frames that can be mapped onto a ggplot to create art.\nYou can install artpack from CRAN with:\n\ninstall.packages(\"artpack\")\n\nYou can install the development version of artpack from GitHub with:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"Meghansaha/artpack\")\n\nThis post will cover the main new functions included in 0.2.0 that were not present in the original 0.1.0 CRAN release.\nYou can find all the changes implemented in the release notes here.\n\n\nGeospatial Tools\nNew to artpack is a geospatial function, point_in_polygon(), which analyzes points relative to a polygon. It was created in the spirit of {sp}â€™s point.in.polygon() function. The sp package is currently being deprecated, so point_in_polygon() attempts to provide similar results by using the more stable {sf} package instead. point_in_polygon() is a wrapper for various sf functions and returns a numeric vector of 0â€™s and 1â€™s where a value of 0 indicates that a point is outside of the polygon being tested and a value of 1 indicates that the point is either inside or on the border of the polygon being tested.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(artpack)\n\n# Create test points and polygon for visualization\ndf_points_prep &lt;-\n  tibble(\n    x = c(0.5, 1.5, 2.5, 1.0, 0.0, 3.0),\n    y = c(0.5, 1.5, 2.5, 0.0, 1.0, 1.0)\n  )\ndf_polygon &lt;-\n  tibble(\n    x = c(0, 2, 2, 0, 0),\n    y = c(0, 0, 2, 2, 0)\n  )\n\n# Test the points and add labels for the plot\ndf_points &lt;-\n  df_points_prep |&gt;\n  mutate(\n    position = point_in_polygon(x, y, df_polygon$x, df_polygon$y),\n    position_string = case_match(position,\n                                 0 ~ \"Outside\",\n                                 1 ~ \"Inside/On Boundary\"\n                                 ) |&gt; factor(),\n    color = case_match(position,\n                       0 ~ \"#e31a1c\",\n                       1 ~ \"#33a02c\"\n                       )\n  )\n\n# Pull out the colors for the plot points\nunique_df &lt;- unique(df_points[c(\"position_string\", \"color\")])\nvec_colors &lt;- setNames(unique_df$color, unique_df$position_string)\n\n\n# Plot it\nggplot() +\n  geom_polygon(data = df_polygon, aes(x = x, y = y),\n               fill = \"#104d70\", alpha = 0.3, color = \"black\", linewidth = 1) +\n  geom_point(data = df_points, aes(x = x, y = y, color = position_string), size = 4) +\n  scale_color_manual(values = vec_colors) +\n  labs(color = \"Position:\") +\n  coord_equal()\n\n\n\n\n\n\n\n\n\n\n\nGroup Tools\nIf youâ€™re a fan of using geom_polygon() in your generative art, chances are you know the importance of assigning grouping variables to your data where applicable. The group_sample() and group_slice() functions have been added to allow users to sample and slice their data frames by grouping variables. group_sample() and group_slice() were both created in the spirit of dplyrâ€™s slice() function family. Just like how slice() works on single rows, group_sample() and group_slice() will always keep the rows of a group intact. So if you decide to sample 2 groups out of 5, all of the rows labeled by the two groups will be returned while the other rows will be dropped. The same is true for group_slice().\n\nWe can demonstrate group_sample() and group_slice() with a simple grid, where each square is its own group:\n\n# Create a grid\ndf_grid &lt;-\n  grid_maker(\n    xlim = c(0,10),\n    ylim = c(0,10),\n    size = 10,\n    fill_pal = art_pals(\"sunnyside\", 5)\n  )\n\ndf_grid |&gt;\n  ggplot(aes(x,y, group = group)) +\n  geom_polygon(\n    fill = df_grid$fill,\n    color = \"#000000\"\n  ) +\n  theme_void() +\n  coord_equal()\n\n\n\n\n\n\n\n\n\nSampling 50% of the groups:\n\nset.seed(09132025)\n\n# Create a sampled df\ndf_grid_sampled &lt;-\n  df_grid |&gt;\n  group_sample(group = group, prop = .50)\n\ndf_grid_sampled |&gt;\n  ggplot(aes(x,y, group = group)) +\n  geom_polygon(\n    fill = df_grid_sampled$fill,\n    color = \"#000000\"\n  ) +\n  theme_void() +\n  coord_equal(xlim = c(0,10), ylim = c(0,10))\n\n\n\n\n\n\n\n\nSampling only 10 of the groups:\n\nset.seed(09132025)\n\n# Create a sampled df\ndf_grid_sampled &lt;-\n  df_grid |&gt;\n  group_sample(group = group, n = 10)\n\ndf_grid_sampled |&gt;\n  ggplot(aes(x,y, group = group)) +\n  geom_polygon(\n    fill = df_grid_sampled$fill,\n    color = \"#000000\"\n  ) +\n  theme_void() +\n  coord_equal(xlim = c(0,10), ylim = c(0,10))\n\n\n\n\n\n\n\n\n\nSlicing the data so that the groups in the bottom half is removed:\n\n# Create a sliced df\ndf_grid_slice &lt;-\n  df_grid |&gt;\n  group_slice(group = group, prop = .50, position = \"tail\")\n\ndf_grid_slice |&gt;\n  ggplot(aes(x,y, group = group)) +\n  geom_polygon(\n    fill = df_grid_slice$fill,\n    color = \"#000000\"\n  ) +\n  theme_void() +\n  coord_equal(xlim = c(0,10), ylim = c(0,10))\n\n\n\n\n\n\n\n\nSlicing the data so that 25 of the groups from the bottom remain:\n\n# Create a sliced df\ndf_grid_slice &lt;-\n  df_grid |&gt;\n  group_slice(group = group, n = 25, position = \"head\")\n\ndf_grid_slice |&gt;\n  ggplot(aes(x,y, group = group)) +\n  geom_polygon(\n    fill = df_grid_slice$fill,\n    color = \"#000000\"\n  ) +\n  theme_void() +\n  coord_equal(xlim = c(0,10), ylim = c(0,10))\n\n\n\n\n\n\n\n\n\n\n\nSequencing Tools\nseq_bounce() generates a regular sequence of numeric values that â€œbounceâ€ between a provided â€œstartâ€ and â€œendâ€ number. It will always return a numeric vector of the length provided.\nBy default, seq_bounce() creates sequences by increments of 1:\n\n#The length argument accepts any positive integer\nseq_bounce(start_n = 1, end_n = 5, length = 15)\n\n [1] 1 2 3 4 5 4 3 2 1 2 3 4 5 4 3\n\n\nMore precision can be obtained with the by argument:\n\n#The by argument accepts any positive numeric\nseq_bounce(start_n = 0, end_n = 10, length = 30, by = .247)\n\n [1] 0.000 0.247 0.494 0.741 0.988 1.235 1.482 1.729 1.976 2.223 2.470 2.717\n[13] 2.964 3.211 3.458 3.705 3.952 4.199 4.446 4.693 4.940 5.187 5.434 5.681\n[25] 5.928 6.175 6.422 6.669 6.916 7.163\n\n\n\n\n\nTransformation Tools\nresizer() is artpackâ€™s newest transformation tool. It can be used to â€œresizeâ€ or scale existing data points in a data frame based on either the first data point in the dataframe or a provided anchor point.\nResizing a square up by a factor of 6:\n\n# Make a data frame\ndf_square &lt;-\n  square_data(\n    x = 0,\n    y = 0,\n    size = 1\n  )\n\n# Resize it\ndf_square_resized &lt;-\n  df_square |&gt;\n  resizer(x, y, factor = 6)\n\n# Plot them\ndf_square |&gt;\n  ggplot(aes(x,y)) +\n  # resized square - red dashed line\n  geom_path(data = df_square_resized, color = \"#a83246\", linewidth = 2, linetype = 2) +\n  # original square - black solid line\n  geom_path(color = \"#000000\", linewidth = .8) +\n  coord_equal()\n\n\n\n\n\n\n\n\nResizing a circle down by a factor of 3 and manually setting an anchor point:\n\n# Make a dataframe\ndf_circle &lt;-\n  circle_data(x = 5, y = 5, radius = 5, group_var = TRUE)\n\n# Set the anchor point as the middle of the circle c(5,5)\n# Although the point 5,5 is in the circle's bounds,\n# it's not actually a row in `df_circle`\n# A message will display in cases like these and is \"fine\" to ignore.\n\ndf_circle_resized &lt;-\n  df_circle |&gt;\n  resizer(x,y, x_anchor = 5, y_anchor = 5, direction = \"down\", factor = 3)\n\n! The anchor point you've supplied (5, 5) is not found in your data.\nâ„¹ The data will be scaled relative to this external point\n\n\n\n# Plot it\ndf_circle |&gt;\n  ggplot(aes(x,y)) +\n  # resized circle - red dashed line\n  geom_path(data = df_circle_resized, color = \"#a83246\", linewidth = 2, linetype = 2) +\n  # original circle - black solid line\n  geom_path(color = \"#000000\", linewidth = .8) +\n  coord_equal()\n\n\n\n\n\n\n\n\n\n\n\nColor Tools\nTwo new functions, set_brightness() and set_saturation(), have been added to artpack. Both can be used to adjust original colors by percentage of desired brightness and saturation. These functions work by transforming hexadecimal webcolor values or any value from colors() into an RGB value, and then an HSL value to adjust the brightness or saturation. After the adjustment, the values are converted into a hexadecimal webcolor that is then returned to the environment for use.\nThese functions use a normalized scale of 0 to 1, meaning that 0% is the darkest/least saturated value in relation to the original color provided and 100% is the brightest/most saturated value in relation to the original color provided.\nAn example of adjusting the brightness of a color. Note how the â€œdarkerâ€ color shown is not much darker than the original, because the original color already had a brightness of 35%:\n\n# Create color values\noriginal_color &lt;- \"#94321c\" #(original brightness == %35)\ndarker_color &lt;- set_brightness(original_color, .30) #(brightness == %30)\nlighter_color &lt;- set_brightness(original_color, .7) #(brightness == %70)\n\n# Make a data frame with the color values\ndf_colors &lt;-\n  data.frame(\n    x = 0:2,\n    y = 1,\n    color = c(darker_color, original_color, lighter_color)\n  )\n\n# Add a label for clarity\ndf_colors$label &lt;- paste(c(\"Darker\", \"Original\", \"Lighter\"), \":\", df_colors$color)\n\n# Plot to see the brightness changes\ndf_colors |&gt;\n  ggplot(aes(x,y)) +\n  geom_label(aes(x = 0:2), y = 2, label = df_colors$label) +\n  geom_point(color = df_colors$color, shape = 15, size = 50) +\n  coord_cartesian(xlim = c(-1,3), ylim = c(0,3)) +\n  theme_void()\n\n\n\n\n\n\n\n\n\nSaturation is adjusted similarly:\n\n# Create color values\noriginal_color &lt;- \"#748c3f\" #(original saturation == %38)\ndesaturated_color &lt;- set_saturation(original_color, .2) #(saturation == %20)\nsaturated_color &lt;- set_saturation(original_color, .9) #(saturation == %90)\n\n# Make a data frame with the color values\ndf_colors &lt;-\n  data.frame(\n    x = 0:2,\n    y = 1,\n    color = c(desaturated_color, original_color, saturated_color)\n  )\n\n# Add a label for clarity\ndf_colors$label &lt;- paste(c(\"Desaturated\", \"Original\", \"Saturated\"), \":\", df_colors$color)\n\n# Plot to see the saturation changes\ndf_colors |&gt;\n  ggplot(aes(x,y)) +\n  geom_label(aes(x = 0:2), y = 2, label = df_colors$label) +\n  geom_point(color = df_colors$color, shape = 15, size = 50) +\n  coord_cartesian(xlim = c(-1,3), ylim = c(0,3)) +\n  theme_void()\n\n\n\n\n\n\n\n\n\nYou might be asking how you could determine the original brightness or saturation of a color you provide. Currently, there is no function in artpack that does this, but it is planned for a future release.\nIn the meantime, if needed, you can absolutely use other methods to determine this. Take the color â€œ#748c3fâ€ for example. Going to Google.com and using their â€œColor pickerâ€ tool can let you easily see these values:\n\n\n\nGoogle color picker tool showing color #748c3f with HSL values displayed in bottom right: H:82Â°, S:38%, L:40%\n\n\nAn â€œHSLâ€ value is provided in the bottom right of the picker tool. The second value, â€œSâ€, is the saturation percentage of the color (38%), and the third value, â€œLâ€, is the â€œlightnessâ€ which is essentially the brightness (40%).\n\n\nMore Vignettes\nThe last update you might want to check out are the new and improved vignettes:\n\nBrief Examples has an updated example of some art that can be made with artpack.\nConnecting artpack Assets to ggplot2 Geoms is a new vignette that goes over the various artpack asset creations and their recommended ggplot2 geoms that can be used when creating art in R with artpack and ggplot2. It also gives a quick example of how to bring your newly created art data into a ggplot if you need that information.\nSee aRtpack in Action is a new vignette that shows you how to make an art piece from start to finish, which may be helpful for anyone just starting or those who just need an example of an entire workflow thatâ€™s possible with artpack.\n\n\n\nReminder\nartpack is still in its infancy and is currently developed and maintained by one person. Some weird stuff may happen when using artpack. If you come across any bugs or have any ideas about new features youâ€™d want to see implemented, or recommend improvements, please do so on artpackâ€™s github repository by opening a new issue here."
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html",
    "title": "Git Stash for Newbies.",
    "section": "",
    "text": "In this post:"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#stashing-with-a-terminal",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#stashing-with-a-terminal",
    "title": "Git Stash for Newbies.",
    "section": "Stashing with A Terminal",
    "text": "Stashing with A Terminal\nIf youâ€™re an R user like myself, you may favor using the RStudio IDE (Integrated Development Environment). While great for many things, it unfortunately does not have a built-in graphical user interface (GUI) for git stashes at the time of writing this. This means there are no accessible buttons to click to create a git stash like you would for creating a commit, pushing and pulling to repositories, or other standard git functions. If you use RStudio, the most accessible way to create and use git stashes within the IDE is to use the embedded terminal:\n\n Making a stash in RStudioâ€™s Git Terminal\n\n\nIf youâ€™re not using Rstudio, you can use any terminal/Command Line Interface (CLI) youâ€™d like. This could be Powershell on Windows operating systems, Terminal on Macs, or even Bash on Linux systems. The potential benefit of using a terminal is increased functionality with the possibility of a steeper learning curve or decreased accessibility due to the difficulty of learning to script in CLIs for most users."
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#stashing-with-third-party-gui-clients",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#stashing-with-third-party-gui-clients",
    "title": "Git Stash for Newbies.",
    "section": "Stashing with Third-party GUI Clients",
    "text": "Stashing with Third-party GUI Clients\nIf you donâ€™t feel like being bothered with terminals or just want to use a pretty GUI for your Git operations, you can always use third-party programs likeÂ GitHub Desktop, SourceTree, or GitKraken. These GUI clients absolutely take some of the pain out of doing the most common git procedures, stashes included.\nDifferent IDEs like Positron and VS Code can also be considered third-party GUI clients that allow you to use git stashes with git-flavored extensions from the OpenVSX Marketplace (for Positron) and the VS Code Marketplace (for VS Code).\nBecause third-party GUI clients can vary widely in their user interfaces and functionality, this post will only go over how to create and work with stashes via the Git terminal. Even if you are using a GUI, reading about the commands a git stash can take and what each of them do can help give a better understanding of stashes and what specific actions youâ€™ll need for your work. If youâ€™re not using the terminal, itâ€™s always a good idea to explore what functionalty your GUI client has as it can vary. For most users, the functionality a GUI client can provide is usually efficient for most use cases. However, if you start running into any friction while using a GUI client, it may be time to consider using a terminal if you havenâ€™t already."
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#making-a-stash",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#making-a-stash",
    "title": "Git Stash for Newbies.",
    "section": "Making a Stash",
    "text": "Making a Stash\nScenario: You jumped into working on a branch that hasnâ€™t been updated from the remote in a month and of course, you forgot to pull before touching anything. You want to make a stash to keep your current work safe so you can pull the updates in and deal with any conflicts later. You save the stash with a message to give a description of the work youâ€™re saving.\n\ngit stash -m \"premature analysis changes before pull\""
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#popping-the-last-stash-saved",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#popping-the-last-stash-saved",
    "title": "Git Stash for Newbies.",
    "section": "Popping the Last Stash Saved",
    "text": "Popping the Last Stash Saved\nScenario: So it turns out you wonâ€™t have any conflicts from that last scenario, so you simply want to throw your changes from that last stash back into your environment.\n\ngit stash pop"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#listing-stashes",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#listing-stashes",
    "title": "Git Stash for Newbies.",
    "section": "Listing Stashes",
    "text": "Listing Stashes\nScenario: After doing more work, you realize that youâ€™re missing some code you absolutely did write at some pointâ€¦ but canâ€™t find anywhere. You suspect itâ€™s in a different stash but donâ€™t know which one. So you want to see all your available stashes for this project.\n\ngit stash list"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#showing-a-stash",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#showing-a-stash",
    "title": "Git Stash for Newbies.",
    "section": "Showing a Stash",
    "text": "Showing a Stash\nScenario: You think youâ€™ve found the right stash. The one at index 2, but youâ€™re not entirely sure. You want to see a quick summary to see what changes are on this particular stash.\n\ngit stash show 2\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nSometimes, when you start using some commands like git stash show or git log the terminal may expect you to input something and wonâ€™t allow you input anything else. If this happens, you simply need to â€œescapeâ€ to revert the terminal back to itâ€™s original state. You can do so by inputting the letter q."
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#popping-a-specific-stash",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#popping-a-specific-stash",
    "title": "Git Stash for Newbies.",
    "section": "Popping a Specific Stash",
    "text": "Popping a Specific Stash\nScenario: You are sure the stash at index 2 is the correct choice, and you know that whatever work you do today will be good enough to commit to the branch, so you want to pop off that stash to continue your work while removing it from your stash list.\n\ngit stash pop 2"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#branching-a-stash",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#branching-a-stash",
    "title": "Git Stash for Newbies.",
    "section": "Branching a Stash",
    "text": "Branching a Stash\nScenario: Youâ€™re starting to realize that the scope of your work has crept away a bit. It now makes sense to have a dedicated branch thatâ€™s separate from the current one to continue this work. You want to name the branch â€œmisc-fixes.â€\nFirst, make the stashâ€¦\n\ngit stash -m \"misc fixes port\"\n\n\n\n\n\nâ€¦ then make the branch.\n\ngit stash branch misc-fixes"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#applying-a-stash",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#applying-a-stash",
    "title": "Git Stash for Newbies.",
    "section": "Applying a Stash",
    "text": "Applying a Stash\nScenario: Youâ€™re starting your work on the new â€œmisc-fixesâ€ branch and have made solid progress before taking a break from it. When you finally pick it up again, you realize that an ambitious function you wrote may need a tweak, but youâ€™re unsure where or how to implement it. You apply the stash (instead of popping it) so you can freely experiment without losing the integrity of your code. If you mess up, your original code will be in the stash list.\n\ngit stash apply"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#pushing-a-stash",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#pushing-a-stash",
    "title": "Git Stash for Newbies.",
    "section": "Pushing a Stash",
    "text": "Pushing a Stash\nScenario: Youâ€™ve switched to a different project someone else was working on because they asked you to help with a data-wrangling problem. Sadly, your brain is fried, and youâ€™re just making it worse. Instead of committing wrong/incomplete code, you decide to push ALL of your changes (even untracked ones) to a stash so you can remove your embarrassment from the branch as if nothing ever happened.\n\ngit stash push -u"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#dropping-a-stash",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#dropping-a-stash",
    "title": "Git Stash for Newbies.",
    "section": "Dropping a Stash",
    "text": "Dropping a Stash\nScenario: You donâ€™t know what you were thinking, bothering to push those changes to a stash. Your code is broken and makes no sense. Itâ€™s not even relevant. You want to put the stash out of its misery and ban it to the shadow realm.\n\ngit stash drop\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNOTE: You better be sure you want to do this. Git does not ask you if youâ€™re sureâ€¦ There are ways to recover stashes youâ€™ve accidentally dropped, but if youâ€™re a git newbie, itâ€™s not pretty, and itâ€™s out of the scope of this blog post."
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#clearing-a-stash",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#clearing-a-stash",
    "title": "Git Stash for Newbies.",
    "section": "Clearing a Stash",
    "text": "Clearing a Stash\nScenario: Youâ€™ve persevered. Whatever seemingly impossible problem you worked on is now complete and rolled into your main branch. All of the stashes on your project are no longer needed. You want to drop ALL of your stashes in one cathartic input.\n\ngit stash clear\n\n\n\n\n\n\n\nWarning\n\n\n\nNOTE: You better be sure you want to do this. Git does not ask you if youâ€™re sureâ€¦ There are ways to recover stashes youâ€™ve accidentally cleared, but if youâ€™re a git newbie, itâ€™s not pretty, and itâ€™s out of the scope of this blog post."
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#git-stash-apply--vs--git-stash-pop",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#git-stash-apply--vs--git-stash-pop",
    "title": "Git Stash for Newbies.",
    "section": "git stash apply -vs- git stash pop",
    "text": "git stash apply -vs- git stash pop\nIf youâ€™re just starting to explore git stashes, it may be confusing to know when to apply or pop a stash. Just remember that both of these commands will bring your stashed changes back into your working directory but will be handled differently in your git stash list:\n\n\nYou can think of git stash apply as â€œcopying and pastingâ€ your stashed changes into your directory. An intact copy stays in the stash list.\n\n\n\n\nYou can think of git stash pop as â€œmovingâ€ your stashed changes into your directory. The stash is removed from your stash list.\n\n\nWhile git stash apply could be good for the cautious newbie who doesnâ€™t want to get rid of something they may need, know that git stash pop or git stash drop is also important as you donâ€™t want to bloat your git stash list with stale work. You should make it a habit to periodically check your stashes to make sure theyâ€™re still needed. In other words, donâ€™t hoard your stashes!"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#stashing-staged-changes",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#stashing-staged-changes",
    "title": "Git Stash for Newbies.",
    "section": "Stashing Staged Changes",
    "text": "Stashing Staged Changes\nYou may have so many changes in your environment at the moment but only want to save/stash a few of them. You can stage those changes and stash them. By default, git does not stash staged changes. You can use this to your advantage to quickly group changes together for a stash:\nEither stage them via a GUI, or in the terminal with the -S option:\n\ngit add file-to-keep-1.R\ngit add file-to-keep-2.R\ngit stash -m \"two important updates\" -S"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#porting-stashed-changes-to-another-branch",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#porting-stashed-changes-to-another-branch",
    "title": "Git Stash for Newbies.",
    "section": "Porting Stashed Changes to Another Branch",
    "text": "Porting Stashed Changes to Another Branch\nIf, for any reason, you want to bring stashed changes into another branch that is already created, you can do so by switching to (checking out) the branch you want to bring the changes to and either pop or apply the changes to the branch.\nIf youâ€™re using a GUI, switch to the desired branch. If using the terminal, check the branch out:\n\ngit checkout the-other-branch\n\n\n\n\n\nThen pop or apply the stash (In this case, the stash at index 3):\n\ngit stash pop 3"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#naming-and-organization",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#naming-and-organization",
    "title": "Git Stash for Newbies.",
    "section": "Naming and Organization",
    "text": "Naming and Organization\nThe -m option lets you attach a message to a stash. This is a wonderful capability that can help you stay organized. Hereâ€™s just an example of some things you can insert into a stash message:\n\nThe date youâ€™re creating the stash\nA brief description of the work\nAction items/project statuses\nChallenges/things or people youâ€™re waiting on before work can continue\nWhat branch you need to move the changes to if applicable"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#referencing-stashes",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#referencing-stashes",
    "title": "Git Stash for Newbies.",
    "section": "Referencing Stashes",
    "text": "Referencing Stashes\nWhenever you use any stash command/option without referencing a specific stash, git will always choose the stash at index 0 in the stash list, which is whatever stash you saved last. The easiest way to reference your stashes is by index. You can easily see which stash is at which index with git stash list:\n\ngit stash list\n\n\n\n\n\nAlthough not as easy as just referencing the index, you can search for your git stashes via grep if you get in the habit of attaching messages to your stashes:\nLetâ€™s say you have a stash that you tagged as â€œIMPORTANTâ€. When using grep, it is case-sensitive. Meaning weâ€™d input this:\n\ngit stash list | grep \"IMPORTANT\"\n\nTo find the stash/index weâ€™re looking for (Index 1 in this case):"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#looking-at-the-stash-dates",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#looking-at-the-stash-dates",
    "title": "Git Stash for Newbies.",
    "section": "Looking at the Stash Dates",
    "text": "Looking at the Stash Dates\nAlthough itâ€™s an option for the git log command, you can use --date to display the date and time the stashes in the stash list were created:\nUse --date=local to see the full day and time the stashes were created.\n\ngit stash list --date=local\n\n\n\n\n\nUse --date=relative to see a relative time calculation like â€œ35 minutes agoâ€. This could come in handy if youâ€™ve made a lot of stashes without labeling them well, as you can gauge the time on the stash youâ€™re looking for.\n\ngit stash list --date=relative"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#abandoning-ship",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#abandoning-ship",
    "title": "Git Stash for Newbies.",
    "section": "Abandoning Ship",
    "text": "Abandoning Ship\nSometimes, popping or applying stashes into your environment may lead to some merge conflicts:\n\n\n\n\nIf this happens, donâ€™t forget that the first rule of resolving conflicts is to NOT panic. If for some reason you canâ€™t help but panic, you can always tell git â€œnevermindâ€ so you can deal with it later with the following command:\n\ngit reset --merge"
  },
  {
    "objectID": "post/git-stash-for-newbies/git-stash-for-newbies.html#perfection-can-halt-progress",
    "href": "post/git-stash-for-newbies/git-stash-for-newbies.html#perfection-can-halt-progress",
    "title": "Git Stash for Newbies.",
    "section": "Perfection Can Halt Progress",
    "text": "Perfection Can Halt Progress\nOne last bit of advice I want you to take from this is to not let fear or perfection stop you from making meaningful contributions to your project. Remember that the utility of git stashes lies in its ability to help you maintain a clean git/project environment. Donâ€™t fall victim to hoarding your work.\n\n\nPOV: Me explaining to someone why I canâ€™t push my work up to the remote yet.\n\n\nI am absolutely guilty of waiting to make commits/push work to remotes because itâ€™s not perfect. Things donâ€™t have to be perfect, especially for larger projects. The best approach to tackling large projects that will take a while to complete is designating project milestones/checkpoints. These can be agreed upon â€œstopping pointsâ€ in which you will determine whether your work is â€œgood enough for nowâ€ so it can be committed instead of stashed away.\n \nHopefully, Iâ€™ve given you enough information to start using some git stashes. If youâ€™d like to read the official git stash documentation yourself, you can do so here. If youâ€™d like more resources on git workflows in general, you can checkout the README for my 2024 Posit Conf talk â€œPlease let me Merge Before I Start Crying,â€ which has plenty of supplemental links to explore."
  },
  {
    "objectID": "post/i-participated-in-my-first-tidy-tuesday-project-recap/i-participated-in-my-first-tidy-tuesday-project-recap.html",
    "href": "post/i-participated-in-my-first-tidy-tuesday-project-recap/i-participated-in-my-first-tidy-tuesday-project-recap.html",
    "title": "I Participated in My First Tidy Tuesday! : Project Recap",
    "section": "",
    "text": "To kick off the year, I took the â€œleap of faithâ€ and participated in my first TidyTuesday! A weekly community activity hosted by the R4DSCommunity on Twitter that challenges those of all skill levels and disciplines to explore a data set and make a data visualization of it. This weekâ€™s data was from the Transit Costs Project.\nThis Tidy Tuesday was challenging mainly because I was on a crunch for time. However, I did not want to pass up an opportunity to practice with Plotly (for R). In my current position, Iâ€™m tasked with building some internal dashboards to keep track of a lot of opioid data. Using Plotly can allow for interactive/dynamic graphs (instead of static, non-moving graphs.)\nThis activity was great for practicing the obvious data cleaning and wrangling skills. I also got to practice conditional formatting (colors of the lollipops), ggplot manipulation, and lookup functions. Drawing conclusions from the data is not recommended due to the nature of the selected data sets. Tidy Tuesday really encourages developing your process as a data scientist to hone in on fundamental skills! That being said, donâ€™t read too much into it! If youâ€™re interested in the code used for this plotly plot, or the process used for the data, you can find it on my Github Repo here.\nFeel free to contact me directly! Respectful discourse towards efficient solutions or new insights is always welcomed!"
  },
  {
    "objectID": "post/making-circular-maps/making-circular-maps.html#latitude-vs.-longitude",
    "href": "post/making-circular-maps/making-circular-maps.html#latitude-vs.-longitude",
    "title": "Making Circular Maps in ggplot",
    "section": "Latitude vs.Â Longitude",
    "text": "Latitude vs.Â Longitude\nAs stated, you need to designate a POI that will act as the â€œcenterâ€ of your circular map. Once you decide on a place, youâ€™ll need to grab the latitude and longitude points and store them for use. One thing that ALWAYS trips me up without fail is discerning which value is latitude and which is longitude. It wasnâ€™t until recently that I learned of the â€œladderâ€ memory trick:\n\n\n\n\n\nIâ€™m embarrassed about how long it took me to remember thisğŸ¤¦ğŸ½â€â™€ï¸"
  },
  {
    "objectID": "post/making-circular-maps/making-circular-maps.html#acquiring-the-latitude-and-longitude-points",
    "href": "post/making-circular-maps/making-circular-maps.html#acquiring-the-latitude-and-longitude-points",
    "title": "Making Circular Maps in ggplot",
    "section": "Acquiring the Latitude and Longitude Points",
    "text": "Acquiring the Latitude and Longitude Points\nThere are multiple ways to go about figuring out the latitude and longitude points of your POI. The following is not an exhaustive list, but just what Iâ€™ve used in the past:\n\nGoogle Maps Search\nThis is the â€œManualâ€ way and may be needed if your POI is relatively new to mapping/GPS systems or if itâ€™s obscure. You can simply search for your POI in Google Maps, right-click on the exact point of the POI in the map, and click on the latitude and longitude points Google Maps provides. Clicking on this will automatically copy the values to your clipboard. Remember that these points are displayed in alphabetical order here. Meaning that latitude comes first.\n\n\n\n\n\nThis is absolutely the way I did it because thatâ€™s just where my brain was at that day.\n\n\nThe ggmap Package\nSuppose youâ€™ve already got aÂ Google Cloud Account. The ggmap package can help grab latitude and longitude points via its geocode function. This package is convenient but does come with a caveat. Google has recently changed its terms of service and now requires all Google Cloud Accounts to have an active credit card on file before using any generated APIs. As of February 2023, If you have a valid credit card to use and donâ€™t have a lot of data that needs to be geocoded, you can take advantage of aÂ new-member free trial of $300 worth of free credits for Googleâ€™s API services. After that, users can use up toÂ $200 worth of Google Maps API credits. (Please check this for yourself as things can always change!) This is more than enough credits for standard tasks to use the API sparingly without ever having to pay. Just be mindful not to overuse it. For example, donâ€™t constantly re-run your entire script while debugging and forget itâ€™s calling the API each time. If you arenâ€™t confident about not overusing the API, you may want to avoid this option.\n\nThe tidygeocoder Package\nIf ggmap is too much of a potential gamble, you can try using theÂ tidygeocoderÂ package. Iâ€™m absolutely biased towards tidygeocoder because I used it frequently at the last job that required me to geocode thousands of addresses for my local government. It was really clutch. It also has a handful of different types of geocoding functions and geolocation services to call from. A downside to this may be a lack of accuracy for some places (compared to Googleâ€™s service, but even Google isnâ€™t perfect.) tidygeocoder is worth looking into if youâ€™re interested in doing geospatial tasks like this in R."
  },
  {
    "objectID": "post/making-circular-maps/making-circular-maps.html#alternative-aesthetics",
    "href": "post/making-circular-maps/making-circular-maps.html#alternative-aesthetics",
    "title": "Making Circular Maps in ggplot",
    "section": "Alternative Aesthetics",
    "text": "Alternative Aesthetics\nSo what if you donâ€™t want to use a simple color palette? There are many ways to add variations to the aesthetics in the ggplot to introduce more complicated color schemes to your maps. For our example, though, letâ€™s look at just two ways to do this:\nEmbedding Color Data Into the Data Frame\nTo do it this way, we can add a vector of colors into the cropped data frame (the step where we use st_intersection() to get our final data set. We simply use map2() and add a mutate() line inside to add the color column that will store the hex color codes for each feature:\n\n#=============================================================================#\n#Cropping OSM data to fit circle-----------------------------------------------\n#=============================================================================#\n\n#Storing the new colors#\nfeature_colors &lt;- c( \"#43963C\", \"#FCE8E6\", \"#9e220d\", \"#9e6e0d\", \"#ffffff\")\n\n#Calculating intersections-----------------------------------------------------\n#Native pipe (|&gt;) does not evaluate this properly like magrittr's##\nosm_colors_df &lt;- map2(feature_names, feature_colors,  \n                             ~st_intersection(circle, \n                                              osm_features_all[[.x]] |&gt;\n                                                mutate(color = .y))) |&gt;\n  list_rbind()\n\n#=============================================================================#\n#Map aesthetic options---------------------------------------------------------\n#=============================================================================#\n\nmap_background &lt;- \"#d9d1a0\" #Tan Color\ntext_color &lt;- \"#000000\"\nouter_ring_color &lt;- \"#000000\" #Black\ninner_ring_color &lt;- \"#d9d1a0\" #Tan Color\nPOI_fill &lt;- '#190d9e' #Blue color\nPOI_color &lt;- '#000000' #Black\n\n\nNow we can just tweak the ggplot code a bit by adding the scale_color_manual() function and updating our geom_sf() function to include the new data frame osm_colors_df with added aesthetics for geometry, fill, and color.\n\nggplot() +\n  theme_void()+\n  theme(\n        plot.background = element_rect(fill = map_background, \n                                               color = NA),\n        plot.title = element_textbox_simple(\n          halign = .5, \n          color = text_color, \n          family = map_font, \n          size = 240, \n          face = 'bold', \n          fill = NA,\n          height = .1,\n          width = 1.5),\n        legend.position = \"none\"\n        ) +\n  scale_color_manual(values = rev(feature_colors),\n                     aesthetics = c(\"fill\", \"color\"))+\n  geom_sf(data = osm_colors_df, aes(geometry = geometry,\n                                    fill = color,\n                                    color = color))+\n  geom_text(data = center_POI, aes(POI[\"long\"], POI[\"lat\"], label = label), \n                        color = POI_color, \n                        size = 31,\n                        family = \"Inter\")+\n  geom_text(data = center_POI, aes(POI[\"long\"], POI[\"lat\"], label = label),\n            color = POI_fill, \n            size = 30,\n            family = \"Inter\") +\n  geom_point(data = center_POI, aes(POI[\"long\"], POI[\"lat\"]),\n            color = outer_ring_color, \n            shape = 21, \n            size = 399, \n            stroke = 10) +\n  geom_point(data = center_POI, aes(POI[\"long\"], POI[\"lat\"]), \n            color = inner_ring_color, \n            shape = 21, \n            size = 403, \n            stroke = 4) +\n  labs(title = title_text) +\n  geom_richtext(aes(x = POI[\"long\"], y = POI[\"lat\"] - .011),\n                label = caption_text, \n                text.color = text_color,\n                family = map_font, \n                lineheight = .1,\n                size = 50,\n                fill = NA,\n                hjust = .5,\n                label.color = NA)+\n  coord_sf(ylim = c(POI[\"lat\"] + .008,POI[\"lat\"] - .012))\n\n#ggsave(\"map_v2.png\",\n       #width = 16, \n       #height = 20, \n       #dpi = 300, \n       #units = \"in\")\n\nWhich changes our colors accordingly and gives us this after we use ggsave() with our set output size:\n\n\nThe data of the osm_colors_df object plotted in ggplot with a geom_sf() layer.\n\n\nLeaving Data in a List and Changing Colors in geom_sf()\n\nIf youâ€™re used to having multiple layers in your ggplot and would prefer to manually set each featureâ€™s color individually without using purrr, you can leave your data in a list like soâ€¦\n\n#Calculating intersections-----------------------------------------------------\n#Native pipe (|&gt;) does not evaluate this properly like magrittr's#\nosm_colors_list &lt;- map(feature_names, \n                            ~st_intersection(circle,osm_features_all[[.x]])) %&gt;%\n  set_names(., feature_names) \n\n\nAnd create separate layers for each feature in the list in your ggplot:\n\nggplot() +\n  theme_void()+\n  theme(\n        plot.background = element_rect(fill = \"#82a775\", \n                                               color = NA),\n        plot.title = element_textbox_simple(\n          halign = .5, \n          color = \"#ffffff\", \n          family = map_font, \n          size = 240, \n          face = 'bold', \n          fill = NA,\n          height = .1,\n          width = 1.5)\n        ) +\n  geom_sf(data = osm_colors_list$roads,\n          color = \"#B05f66\") +\n  geom_sf(data = osm_colors_list$buildings,\n          color = \"#64513b\",\n          fill = \"#A68662\",\n          linewidth = 2) +\n  geom_sf(data = osm_colors_list$landuse,\n          color = \"#734B09\",\n          fill = \"#D78C10\",\n          linewidth = 2) +\n  geom_sf(data = osm_colors_list$leisure,\n          color = \"#d1b39d\",\n          fill = \"#4F443B\",\n          linewidth = 2) +\n  geom_sf(data = osm_colors_list$natural,\n          color = \"#3b727c\",\n          fill = \"#5CB2C2\",\n          linewidth = 2,\n          linetype = 3) +\n  geom_text(data = center_POI, aes(POI[\"long\"], POI[\"lat\"], label = label), \n                        color = POI_color, \n                        size = 31,\n                        family = \"Inter\")+\n  geom_text(data = center_POI, aes(POI[\"long\"], POI[\"lat\"], label = label),\n            color = POI_fill, \n            size = 30,\n            family = \"Inter\") +\n  geom_point(data = center_POI, aes(POI[\"long\"], POI[\"lat\"]),\n            color = outer_ring_color, \n            shape = 21, \n            size = 399, \n            stroke = 10) +\n  geom_point(data = center_POI, aes(POI[\"long\"], POI[\"lat\"]), \n            color = inner_ring_color, \n            shape = 21, \n            size = 403, \n            stroke = 4) +\n  labs(title = title_text) +\n  geom_richtext(aes(x = POI[\"long\"], y = POI[\"lat\"] - .011),\n                label = caption_text, \n                text.color = \"#ffffff\",\n                family = map_font, \n                lineheight = .1,\n                size = 50,\n                fill = NA,\n                hjust = .5,\n                label.color = NA)+\n  coord_sf(ylim = c(POI[\"lat\"] + .008,POI[\"lat\"] - .012))\n\n#ggsave(\"map_v2.png\",\n       #width = 16, \n       #height = 20, \n       #dpi = 300, \n       #units = \"in\")\n\n\nWhich results in this after we use ggsave():\n\n\n\n\n\nThe data of the osm_colors_list object plotted in ggplot with multiple geom_sf() layers."
  },
  {
    "objectID": "post/making-waves/making-waves.html",
    "href": "post/making-waves/making-waves.html",
    "title": "Making Waves in ggplot: An Rtistry Tutorial",
    "section": "",
    "text": "The Original â€œWave Patchâ€ Piece Made in R\nA little while ago, I made an Rtistry piece that I named â€œWave Patch.â€ (Shown above). There seemed to be some interest in providing a tutorial on making waves like I did in Wave Patch. Iâ€™ll use this post to discuss the basic concepts behind making one set of waves that will hopefully set the reader up to take that knowledge, expand upon it, and make their own Rtistry!\nWhile things will always be explained when appropriate, this tutorial assumes that you have experience working in ggplot in the tidyverse, working with ggplot aesthetics, and creating functions.\nDonâ€™t want to read and just want the code? The full code for this tutorial is on my GitHub Repo here."
  },
  {
    "objectID": "post/making-waves/making-waves.html#lets-start-with-a-trig-refresher",
    "href": "post/making-waves/making-waves.html#lets-start-with-a-trig-refresher",
    "title": "Making Waves in ggplot: An Rtistry Tutorial",
    "section": "Letâ€™s Start with a Trig Refresher!",
    "text": "Letâ€™s Start with a Trig Refresher!\nSo, confession time. I have never taken a trigonometry class in my life! The closest I got was taking geometry in high school and I got a C. BUT, I was still able to make this piece, so no matter your math background, you can too! These waves are made with sine waves. You might be familiar with them already. We can code for basic sine waves in ggplot by setting up our data appropriately:\n\n# Library Load-In====\nlibrary(tidyverse) #For everything data#\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.4     âœ” readr     2.1.5\nâœ” forcats   1.0.0     âœ” stringr   1.5.2\nâœ” ggplot2   3.5.2     âœ” tibble    3.3.0\nâœ” lubridate 1.9.4     âœ” tidyr     1.3.1\nâœ” purrr     1.1.0     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n#Let's Start with a Trig Refresher#========================#\ntheta &lt;- seq(from = 0,\n             to = 2*pi, \n             length.out = 100)\n\nsine &lt;- tibble(x = theta,\n               y = sin(theta),\n               label = 1:length(theta))\n\n\nâ€¦ and plotting it like this:\n\n# A basic sine curve======\nsine %&gt;%\n  ggplot(aes(x=x,y=y))+\n  geom_line(color= \"red\", size = 3)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nâ„¹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\nAll we are doing with this code is setting up a sequence of points in our theta variable. Using the seq() function. Weâ€™re telling R â€œCreate 100 numbers between and including the values 0 to 2pi (6.283185). When we go to plot this data, we put theta on one axis (in this case, the x variable because I want my wave to be drawn horizontally on the plane), and then place the sine values of theta on the other axis. Note that these values donâ€™t have to be 0 and 2pi. In the next section, we will switch this up. But letâ€™s just take one more look at this wave with some labels attached:\n\n# A basic sine curve with more detail pointed out======\n\nsine %&gt;%\n  ggplot(aes(x=x,y=y, label = label))+\n  geom_vline(xintercept = 0, size = 2)+\n  geom_vline(xintercept = 2*pi, size = 2)+\n  geom_line(color= \"red\", size = 3)+\n  geom_point(color = \"blue\")+\n  ggrepel::geom_text_repel(max.overlaps = 20, size = 3)+\n  geom_text(aes(x = 0,y = -1),\n           label =paste(sprintf('\\u2190'),\"theta's '0'\"),\n           nudge_x = .5,\n           size = 3)+\n  geom_text(aes(x = 2*pi,y = 1),\n           label = paste(\"theta's '2*pi'\",sprintf('\\u2192')),\n           nudge_x = -.5,\n           size = 3)\n\nWarning in geom_text(aes(x = 0, y = -1), label = paste(sprintf(\"â†\"), \"theta's '0'\"), : All aesthetics have length 1, but the data has 100 rows.\nâ„¹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\nWarning in geom_text(aes(x = 2 * pi, y = 1), label = paste(\"theta's '2*pi'\", : All aesthetics have length 1, but the data has 100 rows.\nâ„¹ Please consider using `annotate()` or provide this layer with data containing\n  a single row.\n\n\n\n\n\n\n\n\n\n\nIf needed, take some time to review the more detailed code/plot of the labeled sine wave. Understanding how data is selected to create the visuals on the plot will set you up for understanding how you can manipulate these visuals in the future."
  },
  {
    "objectID": "post/setting-intentions/setting-intentions.html",
    "href": "post/setting-intentions/setting-intentions.html",
    "title": "Setting Intentions",
    "section": "",
    "text": "No doubt, 2020 has been extremely difficult for everyone. (Who would have known it would be so draining to be productive and just live during a global pandemic?) Many people were forced to adapt to a â€œnew normalâ€ (donâ€™t worry, I wonâ€™t use the â€œUâ€ word weâ€™re all tired of hearing.) Many of us in the U.S who were fortunate to remain employed had to adapt to working from home (WFH). This personally has not bothered me as Iâ€™m an advocate for WFH even during non-pandemic times due to the benefits it brings Iâ€™ve been fortunate enough to continue working during the pandemic and actually switch jobs to take baby steps into my data science career.\nGiven that the theme of 2020 seemed to be â€œinstabilityâ€, I thought it would be wonderful to have just one thing I could consider â€œstable.â€ My own little pocket on the web. I hope to document my progression into data science and finally make some contributions to the field. I have my reservations about this. Candidly, I consider myself a â€œbaby data scientist.â€ My path into data science was by no means â€œtraditional.â€ I will be the first to say that my weakness is not having a formal computer science or statistics degree. Back in my day, (*shudder* I sound old.) data science wasnâ€™t as well known or prominent as it is today. If you were majoring in computer science, it was because you were going to do hardcore computer programming. Retrospectively, a career in data science/coding made sense for me even in my adolescence. (I proudly spent hours learning CSS and HTML to have the best Myspace page. I have also always loved applied statistics; hindsight truly is 2020. Yes, that is a pun. No, Iâ€™m not sorry.)\nThe goal of this site is to help myself and anyone else while I progress into this field. I hope to offer a different perspective to solutions in data science based on needs/functionality. I am by no means an expert and I want to make that OK. I definitely am affected by imposter syndrome taking this route into data science but Iâ€™d like to serve as an example for others on a similar path. (You can learn more about imposter syndrome through a data scientistâ€™s perspective by watching fellow data scientist, Ken Jeeâ€™s , video on it here.) I want to encourage others to continue to push through and learn about this field despite the challenges. On a personal note, I want to learn all that I can so that I can advocate and push for more data science efforts in health research and mental health data analytics.\nSo, moving forward, Iâ€™ll be using the Exploration Corner to share various categories of posts that include:\n\nGeneral/Data Musings: Informal posts like this one that youâ€™re reading right now that are general or my thoughts/opinions on data-related things that I find.\nProject Recaps: These will be posts that briefly describe projects I have completed. Project recaps will differ from full walkthroughs as they will not be a step-by-step guide. It will generally explain a goal, data sources, a quick list of processes/packages used, and a link to the actual project and source code on Github.\nR Explorations: These posts will act as a playground for me personally. Iâ€™m reserving this space as a way to leave notes for myself that might help others. This can include deeper dives into packages and functions or even cheat sheets.\nR Walkthroughs: These posts will be targeted step-by-step guides on how Iâ€™ve done random things in R. I use R daily for my work and find myself doing different things daily. These will also include links to example data sets and project files on Github when applicable.\nAs I trek through my journey, I do plan to learn python and dive into D3.js. When I get to that point, Iâ€™ll add blog categories accordingly.\nWhere are you on your data science journey? Do you have any suggestions for different blog posts? Feel free to leave a comment below to share your thoughts or contact me directly! Respectful discourse is always welcomed!"
  },
  {
    "objectID": "post/thinking-outside-the-grid/thinking-outside-the-grid.html",
    "href": "post/thinking-outside-the-grid/thinking-outside-the-grid.html",
    "title": "Thinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.",
    "section": "",
    "text": "Before I write any further, I want to give a special shout out to @ijeamaka_a, @djnavarro, & @jiwanheo who I personally credit for inspiring me within the last month specifically (my only month being an aRtist so far)!\nSo, this post will be a bit different from my others. Iâ€™m going to talk about some very basic concepts and perspectives you can think about while starting your own Rtistry journey in ggplot. This includes basics on geoms, aesthetics, layering, etc. But then Iâ€™m also going to walk you through two of my Rtistry examples and code to get you started.\nThis article is intended for those who have some experience with ggplot building in R but may not have realized how to transition from making â€œregularâ€ visuals to Rtistry. This article goes over basic concepts that more seasoned users may already know. If you believe it is too basic, you can jump straight to the code for the finished pieces to see these basics applied together. Seeing how others have constructed things may help you understand how you can apply your programming knowledge to create Rtistry of your own! For those of you that need these basics, I hope this article is helpful and encourages you to start thinking outside of the ggplot grid and start creating your own pieces!\nDonâ€™t want to read and just want the code? Hereâ€™s the code for:"
  },
  {
    "objectID": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#introduction",
    "href": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#introduction",
    "title": "Thinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.",
    "section": "Introduction",
    "text": "Introduction\nFirst things first: letâ€™s get one thing straight, I am NOT an expert, nor am I a computational scientist or a professional generative artist. While knowledge of some â€œmath thingsâ€ can be super helpful, you donâ€™t need to know complex computational mathematics to make Rtistry (aRt). Granted, if you enjoy and want to create aRt similar to the works of Thomas Lin Pedersen and Danielle Navarro, then maybe you do! But as a beginner, itâ€™s important to remember that your Rtistry is your work and opportunity to learn, grow as an R programmer, and create pieces you can be proud of. Remember that your aRt is an expression of you and no one else and that there is no â€œrightâ€ way to do Rtistry. One of the things I love most about creating aRt is the fact that I donâ€™t have to get anything â€œright.â€ For those of us who use R for work/educational endeavors, we must ensure that our statistics, programming, and literally everything else is correct. Creating Rtistry can provide your mind with not only a creative outlet but a way to still practice programming in R in a low-stress environment where things donâ€™t have to be â€œright.â€\n\nWhy Rtistry?\nSome people may think of the concept of creating aRt and may think itâ€™s a waste of time since no analyses are performed. If you think that way, you have every right to that opinion. What I can share with you, though, is why I personally love creating Rtistry:\n\nGives my brain a rest from â€œreal workâ€\nAllows me to practice programming skills in a stress-free environment\nGives me satisfaction from flexing my creative skills\nGives me more content for professional portfolios"
  },
  {
    "objectID": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#ethics",
    "href": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#ethics",
    "title": "Thinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.",
    "section": "Ethics",
    "text": "Ethics\nWhile using othersâ€™ work as inspiration to give yourself ideas is OK, you should always strive to create something of your own merit. Just like in the physical art world, you may also find that some aRtists may not want to share their process or code with you. Those that are new to Rtistry may be shocked by this. Some newbies may even think that creators come off as standoffish or rude if they decline to share their work. This could be because of how supportive the R community usually is and how we are always seemingly ready to share our code.\nOne thing to remember is that a creator could decline to share their code for many reasons. Those decisions are personal and left up to each aRtist on an individual basis. The aRtists that do exceptionally unique work will have usually put a lot of effort and hours into their pieces to a point where it may even feel proprietary. Some aRtists choose to sell their outputs not only because they have made something truly personal to them, but because theyâ€™ve also made something unique that probably hasnâ€™t existed before.\nWhen you find an Rtistry piece that appeals to you, you could try to understand whatâ€™s happening behind the scenes instead of asking directly for the code. It tends to be a fun challenge to figure out whatâ€™s happening yourself. Itâ€™s a lot of work, yes, but I am willing to bet that if you use R for professional work, the work and study you do to figure out how to create your pieces will benefit you in the long run.\nWhat you choose to do with the pieces you create is entirely up to you. Some aRtists get their work printed for sale or personal use, some look into selling them as Non-fungible Tokens (NFTs) and some literally save their output and never save their code, completely erasing its footprint in a cathartic click of a button. Whatever you do, always give credit where credit is due; donâ€™t assume that everyone is willing to share their code with you (but if they do, always express gratitude and give credit for the assist); and try to be ethical in everything that you do."
  },
  {
    "objectID": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#geoms",
    "href": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#geoms",
    "title": "Thinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.",
    "section": "Geoms",
    "text": "Geoms\nIf you want to start making data aRt in ggplot, having some knowledge on ggplot geoms will prove to be very useful. If youâ€™ve ever participated in a #tidytuesday challenge or have made visuals in ggplot, youâ€™re probably familiar with them. The key to using geoms to create your aRt is to understand what type of data is expected for each geom. Some basic ones to start with are:\n\ngeom_point()\ngeom_line() & geom_path()\ngeom_segment() & geom_curve()\ngeom_polygon()\n\nThere is no limit to which geoms you can use for aRt in ggplot. Your only barrier would be not having your data formatted appropriately for whichever geom you wish to use. For example, if you want to use geom_segment() youâ€™d need to know that this function expects four different data points (x, xend, y, and yend). The geom functions will usually do a good job of throwing an error and letting you know if youâ€™re missing any data points. If youâ€™re interested, you can always learn more about ggplot with the official cheat sheet or book.\n\nGeoms Examples:\nYou can think of basic geoms as instruments (paintbrushes) in your Rtistry toolkit. Here are a few simple examples of how each can be used:\nGeom points can be used for textures, smaller details, or optical illusions like in the image Candy Rope:\n\n\n\nCandy Rope\n\n\n\nGeom line and path can be used to create linear details and abstract aRt :\n\n\n\nLinear Fury\n\n\n\nGeom segment & geom curve can be used for linear/curved details, or larger components:\n\n\n\nMoonscape\n\n\n\nGeom Polygon can be used to make any shape that can exist on ggplotâ€™s coordinate system, Like lots of randomized squares:\n\n\n\nBe Squared"
  },
  {
    "objectID": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#making-and-applying-rtistry-art-data-to-geoms",
    "href": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#making-and-applying-rtistry-art-data-to-geoms",
    "title": "Thinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.",
    "section": "Making and Applying (Rtistry) aRt Data to Geoms",
    "text": "Making and Applying (Rtistry) aRt Data to Geoms\nIf the geoms are the instruments in your toolkit, the data is your ink/paint. The data you provide to each geom will produce visuals on ggplotâ€™s coordinate system. Thinking about it broadly, to make one point on a basic ggplot you need at least one x and one y value:\n\nlibrary(tidyverse) #For everything data====\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\nâœ” dplyr     1.1.4     âœ” readr     2.1.5\nâœ” forcats   1.0.0     âœ” stringr   1.5.2\nâœ” ggplot2   3.5.2     âœ” tibble    3.3.0\nâœ” lubridate 1.9.4     âœ” tidyr     1.3.1\nâœ” purrr     1.1.0     \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n## Example 1: Data Frame====\nsingle_point &lt;- tibble(x=0, y=0)\n\n## Example 1 ggplot====\nsingle_point %&gt;%\n  ggplot(aes(x = x, y = y))+\n  geom_point()\n\n\n\n\nA Single Point\n\n\n\n\n\nHaving several x and y points is what will get you some shapes, lines, and other things:\n\n## Example 2: Data Frame====\nrandom_lines &lt;- tibble(x = sample(1:500, 50),\n                       y = 1:50)\n\n## Example 2: ggplot====\nrandom_lines %&gt;% \n  ggplot(aes(x=x, y=y, xend = median(x), yend = median(y)))+\n  geom_segment()\n\n\n\n\nRandom Lines\n\n\n\n\n\nThe magic happens when you can start viewing the grid differently. When you begin to understand the relationship the values in a data frame have with the ggplot coordinate system, it becomes easier to realize what data is needed to create your desired output. For example, if you want to create abstract art, you might practice making datasets with randomized values. If you want to make intentional pieces, you might spend time studying the axes of the ggplot and determine what range of values you need to make the figures you want. The process of creating data for Rtistry and applying them to geoms can be as simple or complicated as your creativity allows. Letâ€™s just go over a simple example with a basic square.\nWe know that a square consists of four lines. Each line has a start and endpoint. So, we at least need to make four points on our plot. Since each point consists of two values (x and y), weâ€™ll need eight values in total. Four x points and four y points.\n\n\n## Example 3: Data Frame====\nsquare &lt;- tibble(x = c(0,5,5,0), \n                 y = c(0,0,5,5),\n                 labels = 1:4)\n\n\nBecause we want to make a shape thatâ€™s closed (so we could potentially fill it with color), weâ€™d want to use geom_polygon(). You might be thinking â€œwhy not use geom_line() instead?â€ because a square consists of four lines, but letâ€™s look at that. If we make a data set of the points that are supposed to make a square but then pass it through to geom_line() or geom_path() functions, we get these instead:\n\n\n## Example 3: Geom_line() ggplot====\nsquare %&gt;%\n  ggplot(aes(x = x,\n             y = y,\n             label = labels))+\n  geom_line()+\n  geom_label()+\n  coord_equal()\n\n\n\n\nâ€œSquareâ€ made with geom_line()\n\n\n\n\n\n## Example 4: Geom_path() ggplot====\nsquare %&gt;%\n  ggplot(aes(x = x,\n             y = y,\n             label = labels))+\n  geom_path()+\n  geom_label()+\n  coord_equal()\n\n\n\n\nâ€œSquareâ€ made with geom_path()\n\n\n\n\n\ngeom_line() looks this way because it plots points in order by the x axis. Try to take a moment to compare the data and the result and understand why it came to be.\ngeom_path() looks closer to a square! But weâ€™re missing a side! This is because geom_path() doesnâ€™t create a fully closed shape by default. geom_path() is the same as geom_line() except it plots points in the order in which it appears in the dataset.\nNow letâ€™s use geom_polygon() with the same data set:\n\n\n# Example 5: Geom_polygon ggplot====\nsquare %&gt;%\n  ggplot(aes(x = x,\n             y = y,\n             label = labels))+\n  geom_polygon()+\n  geom_label()+\n  coord_equal()\n\n\n\n\nâ€œSquareâ€ made with geom_polygon()\n\n\n\n\n\nThere we go; An actual square. geom_polygon() is similar to how geom_path()â€™s process of drawing lines works. The only difference is that the start and endpoints are automatically connected and you can add a â€œfillâ€ aesthetic to your new shape. By default, ggplot does fill the square. You can set fill = NA to make it empty, but remember to set a color argument if you want to see the â€œborderâ€ of the polygon make its shape:\n\n\n# Example 6: Geom_Polygon ggplot with no fill====\nsquare %&gt;%\n  ggplot(aes(x = x,\n             y = y,\n             label = labels))+\n  geom_polygon(fill = NA, color = \"black\")+\n  geom_label()+\n  coord_equal()\n\n\n\n\nSquare - geom_polygon() ggplot with no fill\n\n\n\n\n\nAs a beginner, itâ€™s tempting to try and make every cool idea that comes to you, but itâ€™s a good idea to spend time with these basics first. You can explore creating aRt data sets with formulas you may be interested in or with any of the â€œnon-visualâ€ functions Iâ€™ll discuss later in the article. Once you feel comfortable creating aRt datasets and applying them to geoms, you might be able to find cool and unexpected ways to plot things!"
  },
  {
    "objectID": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#aesthetics",
    "href": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#aesthetics",
    "title": "Thinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.",
    "section": "Aesthetics",
    "text": "Aesthetics\nThe next important set of basics to learn about is ggplot aesthetics. Weâ€™ve already used aesthetics in the previous sectionâ€™s examples, but letâ€™s think about them a bit more. Each base ggplot and geom function comes with available aesthetics. If youâ€™ve ever made a ggplot visualization and changed any colors, shapes, etc., youâ€™re already familiar with the foundations needed to start customizing the look/style of your work.\nThereâ€™s two ways you can map aesthetics onto your visuals:\n\nThe aes() function in your initial ggplot() function\nDirectly into the geom function you wish to change.\n\nAs you explore what you want to do and how you want to style your data, you may find that you prefer one way over the other. If you get stuck on this part, take some time to think about what youâ€™d like to see on the grid and then think logically about which method would make sense.\nFor example, if you have a variable that contains hex color codes attached to each row in a dataset, it may make sense to set up the aesthetic in the aes() function since itâ€™s already connected to the data. If you have a circumstance where you only want one geom to be one color, or you want to map a different data set of aesthetics to the geom, you can put it into the actual function.\nA word of caution though, if you want to add values from a different dataset, make sure they have the same number of rows as the initial data set that you are piping into the initial ggplotâ€™s function. If they donâ€™t match up and you donâ€™t set the inherit.aes argument to FALSE in the geom, youâ€™ll get an error. There are ways to use different data sets in addition to the initial one used at the beginning of your ggplot call. Iâ€™ll touch on this in the layering section of this article. For now, letâ€™s take a quick look into setting aesthetics in our square example:\nLetâ€™s say we want to color our square purple and make colored dots on each point of the square. Because the polygon will only be filled with one color, we can set that in the geom_polygon() call. If we add a color variable to our data set with individual hex color codes attached to each observation, we can place it in the aes() function and get our desired output with the following code:\n\n\n# Example 7: Geom_Polygon ggplot with colored points====\n\n## Example 7: Data Frame====\nsquare_color_points &lt;- tibble(x = c(0,5,5,0),\n                 y = c(0,0,5,5),\n                 colors = c(\"#c0d943\",\"#027337\",\"#d12017\",\"#000a96\"))\n                 \n## Example 7: Geom_Polygon ggplot with colored points====\nsquare_color_points %&gt;%\n  ggplot(aes(x = x,\n             y = y))+\n  geom_polygon(fill = \"#4b1980\")+\n  geom_point(color = square_color_points$colors)+\n  coord_equal()\n\n\n\n\nSquare- geom_polygon() with colored points\n\n\n\n\n\nWe can also change multiple aesthetics at once. We can change the size of our points too:\n\n\n# Example 8: Geom_Polygon ggplot with colored points and Random Sizes====\nsquare_color_points %&gt;%\n  ggplot(aes(x = x,\n             y = y))+\n  geom_polygon(fill = \"#4b1980\")+\n  geom_point(color = square_color_points$colors,\n             size = sample(1:20, nrow(square_color_points)))+\n  coord_equal()\n\n\n\n\nSquare - geom_polygon() with randomly sized points\n\n\n\n\n\nAs you get more comfortable with aesthetics, you will find that there may be different ways to explore these settings programmatically using various ideas or functions. One of the greatest things about Rtistry is realizing that you may already have the programming knowledge necessary to use these basic components to create amazing things.\nAt the end of the day, if you find yourself stuck on how to do something, it may be helpful to search google, the RStudio Community forums, or even Stack Overflow for the answers to programming questions that may help you piece together your Rtistry. In my experience, Iâ€™ve always had the best results when I take a moment to stop and think about what I am asking R to do programmatically. R doesnâ€™t know that I want to randomize colors for an image, but it will know if I want it to pick random hex color values from a vector by using the sample() function. I can then apply that result to an aesthetic option and get the desired output.\nIf I were googling for the answer to this example, I wouldnâ€™t type â€œhow to randomize colors of geom_point()â€ but instead Iâ€™d type â€œhow to randomly pick values from a vector in R programming.â€ It may take a little bit to understand this thought process, but you are programming after all, so try to approach any troubleshooting as if you were coding for â€œactual workâ€."
  },
  {
    "objectID": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#using-non-visual-functions-for-your-visuals",
    "href": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#using-non-visual-functions-for-your-visuals",
    "title": "Thinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.",
    "section": "Using â€œnon-visualâ€ Functions For Your Visuals",
    "text": "Using â€œnon-visualâ€ Functions For Your Visuals\nThe first time I realized that you could pass additional functions into aesthetic options - my mind was blown! I did not realize that anything other than a string of a hex color could go into a color aesthetic in ggplot. My mind was so stuck on how I learned to code for ggplot. It was also bound by the fact that I never needed to think about setting any options outside of regular color â€œstringsâ€ for my everyday work. Take the random data below. We could change the colors of these random points by applying some random colorsâ€¦\n\n\n## Example 9: Data Frame====\nrandom_points &lt;- tibble(x = 1:100,\n                        y = sample(1:100))\n\n## Example 9: ggplot of randomized points====\nrandom_points %&gt;%\n  ggplot(aes(x=x, y=y))+\n  geom_point()\n\n\n\n\nGgplot of randomized points\n\n\n\n\n\n\n## Example 10: ggplot of randomized points with randomized colors====\nrandom_points %&gt;%\n  ggplot(aes(x=x, y=y))+\n  geom_point(color = sample(RColorBrewer::brewer.pal(5,\"PRGn\"), nrow(random_points), replace = TRUE))\n\n\n\n\nGgplot of randomized points with randomized colors\n\n\n\n\n\nâ€¦Or by placing a logical function in the color aesthetic for geom_point(). For example, we can tell R that we only want to apply randomized colors to any data points that have a y value thatâ€™s less than 50, otherwise observations with a y value thatâ€™s greater than or equal to 50 will just be colored black with an ifelse() function:\n\n\n# Example 11: ggplot of randomized points with randomized colors and logic applied====\nrandom_points %&gt;%\n  ggplot(aes(x=x, y=y))+\n  geom_point(color = ifelse(random_points$y &lt; 50,\n                            sample(RColorBrewer::brewer.pal(5,\"PRGn\"), nrow(random_points), replace = TRUE),\n                            \"black\"))\n\n\n\n\nGgplot of randomized points with randomized colors and logic applied\n\n\n\n\n\nSince there is no limit to the different types of functions a user can make, the possibilities of different functions that can be added to aesthetics seems endless. A few functions that might help you not only in aesthetics, but working with your data prepping are listed below to get you started:\n\n\nsample() â€“ Randomly take a sample from elements of an object\nrep() â€“ Replicate (repeat) elements in a vector or list\nseq() â€“ Generates numeric sequences\nrunif() â€“ Returns a random composition of numbers with a uniform distribution\ndnorm() & rnorm() â€“ Creates a normal density distribution and random normal distribution of numbers\nTrigonometric Functions (cospi(),cos(),sin(), etc.) â€“ Results in the computation of various trigonometric functions.\nCrossing(), expand(), nesting() â€“ Tidyr functions that expand data frames to include possible combinations of values.\nControl-flow constructs (while, repeat,if, for, etc.) â€“ Can be used to create iterations, patterns, and functions of your own.\nApply family functions (lapply, sapply, etc.) â€“ Can be used to apply functions on different objects like matrices, vectors, or lists.\n\n\nRemember that this is not an exhaustive list, but just a taste of some commonly used functions to hopefully get the gears turning about different ways you can manipulate your ggplot aesthetics and actual Rtistry data."
  },
  {
    "objectID": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#layering",
    "href": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#layering",
    "title": "Thinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.",
    "section": "Layering",
    "text": "Layering\nThe last basic concept in this post is ggplot layering. Adding layers with the layer() function or even annotations with the annotate() function is very useful as it allows the user to add different layers of data. You can also achieve this by adding geom functions as you would normally, but if you ever want to add geoms that pull from different data sources this way, you need to set the inherit.aes argument to FALSE, as this will then allow the ggplot to build without error.\nThese multiple ways of layering allows for endless possibilities as piecing together an image this way provides a bit more flexibility. Take the two datasets below. One is intended to just create some lines with geom_segment(), and the other is intended to just create circles in between each line with geom_point(). Because we want 4 lines and 3 circles, the amount of data needed to map these things donâ€™t match up. We can tell this on a quick glance by seeing that the number of rows in each data set donâ€™t match up:\n\n\n## Example 12: Lines_data Data Frame====\nLines_data &lt;-  tibble(x = rep(1, 4),\n                      xend = rep(5, 4),\n                      y = seq(0,6, by = 2),\n                      yend = y )\n\n## Example 12: Circles_data Data Frame====\nCircles_data &lt;- tibble(x = 3,\n                       y = unique(abs(seq(0,6, by = 2) - 1)),\n                       size = 1:3)\n\n##Logic Check: Do these dataframes have the same number of row?##\nnrow(Lines_data) == nrow(Circles_data)\n\n[1] FALSE\n\n\n\nIf we try to add these together by just using a geom function ,geom_point(), and supplying the Circles_data directly into geom_point() without typing inherit.aes = FALSE, the console will throw an error:\n\n\n## Example 12: Lines_data and Circles_data error====\nLines_data %&gt;%\n  ggplot(aes(x=x, y=y, xend = xend, yend = yend))+\n  geom_segment(size = 15)+\n  geom_point(data = Circles_data, aes(x=x, y=y, size = size)) \n\n\nThis error tells you that object xend is not found. This is because we are attempting to override the data frame that is attached to the entire ggplot (Lines_data) with Circles_data now and xend definitely does not exist in Circles_data and therefore â€œcanâ€™t be found.â€ To fix this specific example and get the desired results, simply add inherit.aes = FALSE into the geom_point() function. If desired, you also could just move the aesthetics for Lines_data into the geom_segment() function but as you will find, there are multiple ways to get to the same result. For this example though, weâ€™ll just add the inherit.aes argument to geom_point().\n\n\n## Example 12: Adding Lines_data and Circles_data together with inherit.aes in geom====\n\nLines_data %&gt;%\n  ggplot(aes(x=x, y=y, xend = xend, yend = yend))+\n  geom_segment(size = 15)+\n  geom_point(data = Circles_data, aes(x=x, y=y, size = size), inherit.aes = FALSE)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nâ„¹ Please use `linewidth` instead.\n\n\n\n\n\nggplot of Lines_data and Circles_data layered together with the addition of geom_point()\n\n\n\n\n\nWe can also use the layer() function or the annotate() function to achieve similar results. Both methods are used in the example below:\n\n\n# Example 13: Adding Lines_data and Circles_data together with layer function====\nLines_data %&gt;%\n  ggplot(aes(x=x, y=y, xend = xend, yend = yend))+\n  geom_segment(size = 15)+\n  layer(geom = \"point\",\n        data = Circles_data,\n        stat = \"identity\",\n        position = \"identity\",\n        mapping = aes(x=x, y=y, size = size),\n        inherit.aes = FALSE)\n\n\n\n\nggplot of Lines_data and Circles_data layered together with the layer() function\n\n\n\n\n\n\n# Example 14: Adding Lines_data and Circles_data together with annotate function====\nLines_data %&gt;%\n  ggplot(aes(x=x, y=y, xend = xend, yend = yend))+\n  geom_segment(size = 15)+\n  annotate(geom = \"point\",\n           x= Circles_data$x, \n           y= Circles_data$y, \n           size = Circles_data$size)\n\n\n\n\nggplot of Lines_data and Circles_data layered together with the annotate() function\n\n\n\n\n\nBoth functions produce similar images. The layer() and annotate() functions have their own pros and cons based on what youâ€™d like to do. As shown in the code snippets, each method of layering in ggplot is similar but has its own differences that may be favored in certain situations. Iâ€™d encourage you to read and explore these methods of layering a bit more, and to see what works best to execute your ideas."
  },
  {
    "objectID": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#planet-quad-art-example",
    "href": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#planet-quad-art-example",
    "title": "Thinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.",
    "section": "Planet Quad â€“ aRt Example",
    "text": "Planet Quad â€“ aRt Example\n \n\n\n\nPlanet Quad\n\n\n\n\nNow that weâ€™ve gone over some technical basics, letâ€™s look at two Rtistry examples Iâ€™ve created. The first is Planet Quad. The creation of Planet Quad demonstrates how we can utilize other packages like patchwork and cowplot to create our own Rtisrty. Letâ€™s break this down step-by-step.\nEach layer in ggplot is built on top of each other in the order in which it appears in the code. For this image, that means we want the space/stars background to be behind our planets- so we can start with that first.\nWe want four different plots with a similar design in different colors, so we can start by creating a named vector of the background colors we want to use. I always use hex colors, but you can use whatever format youâ€™d like. Iâ€™ll name mine Space_colors:\n\n\n# Library Load-In====\nlibrary(tidyverse) # For everything data\nlibrary(cowplot) # For placing plots on top of each other easily with ggdraw and draw_image\n\n\nAttaching package: 'cowplot'\n\n\nThe following object is masked from 'package:lubridate':\n\n    stamp\n\nlibrary(patchwork) # For packaging up the plots in the final image\n\n\nAttaching package: 'patchwork'\n\n\nThe following object is masked from 'package:cowplot':\n\n    align_plots\n\n# Star Backgrounds====\n\n## Making four different stars \"backgrounds\" with four different colors====\nSpace_colors &lt;- c(\"Topleft\"=\"#000000\",\n                  \"Topright\"=\"#130321\",\n                  \"Bottomleft\"=\"#330500\",\n                  \"Bottomright\"=\"#8a4500\")\n\n\nNext, we want to create the data for the stars in our backgrounds. Because I want the image to look pretty filled in, Iâ€™ll apply the crossing() function to the data in this tibble that Iâ€™ll name stars:\n\n\n# Making a data set that will be used to create all star backgrounds====\ndf_stars &lt;- tibble(crossing(x = seq(1,2000,100),\n                         y = seq(1,2000,100)))\n\n\nNext, we want to make a list because weâ€™ll run iterations of our df_stars dataset through a ggplot call that will also iterate through our vector Space_colors. This will result in a list of four similar plots that all have a different color scheme. Weâ€™ll name this list All_stars and name the plots inside of the list to make it easier to track each plot as our session continues:\n\n\n## Making the list to hold the \"space\" plots====\nAll_stars &lt;- list()\n\n## Iterating through the \"space_colors\" to make four different plots====\nfor(i in seq_along(Space_colors)){\n  \n  All_stars[[i]] &lt;- df_stars %&gt;%\n    ggplot(aes(x = x, y = y))+\n    geom_jitter(size = sample(c(.02,.04,.06,.8),nrow(df_stars), replace = TRUE), color = \"white\")+\n    theme_void()+\n    theme(plot.background = element_rect(fill = Space_colors[i], color = \"#ffffff\", size = 6)) \n}\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nâ„¹ Please use the `linewidth` argument instead.\n\n## Naming the plots just to help keep track of what's going where====\nnames(All_stars) &lt;- names(Space_colors)\n\n\nNow we can check and look at one of our plots by typing All_stars$Topleft in the console to verify that it looks like what we were expecting:\n\nAll_stars$Topleft\n\n\n\n\nThe â€œTopleftâ€ image in the All_stars list. A ggplot of the stars data\n\n\n\n\n\nNow, we can work on our planets. The planets are actually just a geom_density2d_filled() plot that will go through four iterations of the planet data set with its coordinate system set to [coord_polar()](https://ggplot2.tidyverse.org/reference/coord_polar.html. Just like we did for the stars data, we also want four very similar plots with different colors. Again, we can make a similar function to create a list of these plots. We just need to generate four different iterations of the data set and pick some colors for the planet surfaces. Letâ€™s start with picking color palettes for planets and different colors for the border lines of each planet. We can place each palette into a list called Planet_colors and each border color into a vector called Planet_borders:\n\n\n# Planet Creations====\n## Setting the color palettes for each planet quad====\nPlanet_colors &lt;- list(\"Topleft\" = c(\"#194157\",\"#008dd7\",\"#085b88\",\"#26925e\",\"#095c88\"),\n                      \"Topright\" = c(\"#480463\",\"#392242\",\"#1e0329\",\"#bf9232\",\"#120b17\"),\n                      \"Bottomleft\" = c(\"#47322d\",\"#6b1c09\",\"#a30000\",\"#6b1d09\",\"#851205\"),\n                      \"Bottomright\" = c(\"#c7a602\",\"#998523\",\"#ba690d\",\"#755b3d\",\"#dbab39\"))\n\n## Setting the colors of each planet's borders====\nPlanet_borders &lt;- c(\"Topright\" = \"#333333\",\n                    \"Topright\" = \"#120b17\",\n                    \"Bottomleft\" = \"#260f09\",\n                    \"Bottomright\" = \"#5c523a\")\n\nWeâ€™ll create some randomly sampled data to draw out our planets to encourage some weirdness in its final presentation. Weâ€™ll name the dataset planet:\n\n\n# Making a dataset that will be used to create all the planets====\nplanet &lt;- tibble(crossing(x = sample(1:1000,100, replace = TRUE),\n               y = sample(1:2000, 100, replace = TRUE)))\n\n\nNow weâ€™ll create our list, named All_planets, that will be filled with our four different planets after it runs through our for-loop:\n\n\n## Making the list to hold the \"planet\" plots====\nAll_planets &lt;- list()\n\n## Iterating through the \"planet_colors\" to make four different planet plots====\nfor(i in seq_along(Planet_colors)){\n  \n  All_planets[[i]] &lt;- planet %&gt;%\n    ggplot(aes(x = x, y = y))+\n    scale_fill_manual(values = sample(Planet_colors[[i]],100, replace = TRUE))+ #100 is just a arbitrary \"safe\" number I picked. geom_density does background calcs to create levels that varies based on data.\n    geom_density2d_filled(color = Planet_borders[i], size = 2)+\n    coord_polar(clip = \"on\")+\n    theme_void()+\n    theme(legend.position = \"none\")\n}\n\n## Naming the plots just to help keep track of what's going where====\nnames(All_planets) &lt;- names(Planet_colors)\n\n\nAll these plots are now in our list All_planets. We can peek at one by typing All_planets$Bottomright into the console. Because a seed hasnâ€™t been set anywhere, yours may look different than mine and thatâ€™s all right!\n\nAll_planets$Bottomright\n\n\n\n\nThe â€œBottomrightâ€ image in the All_stars list. A ggplot of the stars data\n\n\n\n\n\nNow we can save all these planet plots as images out into the directory so we can load them right back in as png files. Please note that if you are following along, you may have to alter the directory to avoid errors as this directory is located within my Data_aRt GitHub repo in my Planet Quad project file.\n\n\n# Saving Planets into the directory====\nfor(i in seq_along(All_planets)){\n  \nggsave(paste0(\"planets/\",\n              names(All_planets)[i],\n              \"_planet.png\"),\n       All_planets[[i]],\n       bg = \"transparent\", \n       device = \"png\")\n}\n\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\nSaving 7 x 5 in image\n\n\n  \n\n\n\nA snapshot of the processed PNG files in my personal working directory locally.\n\n\n\n\nNext, we need to bring the processed png files back into the environment. We can do this with the png package. Because Iâ€™m only using this once, I chose to call in the readPNG() function directly from the package instead of loading the package itself. Weâ€™ll store the images in a list called Planet_PNGs.\n\n\n# Loading Planets back into the environment as PNGs====\nPlanet_PNGs &lt;- list()\n\nfor(i in seq_along(All_planets)){\n  \nPlanet_PNGs[[i]] &lt;- png::readPNG(paste0(\"planets/\",\n                                        names(All_planets)[i],\n                                        \"_planet.png\"))\n}\n\n## Setting names to keep track of the planets====\nnames(Planet_PNGs) &lt;- names(All_planets)\n\n\nNow that we have png files, we can place these â€œon topâ€ of our star backgrounds we made earlier using the ggdraw() and draw_image() functions from the cowplot package with for-loops. This time, weâ€™ll store them in a list called Combined_plots:\n\n\n# Combining both the stars and planets to create four plots in total====\nCombined_plots &lt;- list()\n\nfor(i in seq_along(All_planets)){\n  \n  Combined_plots[[i]] &lt;- ggdraw(All_stars[[i]]) +\n                                  draw_image(Planet_PNGs[[i]])\n}\n\n## Setting names to keep track of the plots===\nnames(Combined_plots) &lt;- names(Planet_PNGs)\n\n\nJust like before, we can take a peek at any of the plots in the Combined_plots list to make sure it looks as expected. Iâ€™ll use Combined_plots$Bottomleft in the console to see:\n\nCombined_plots$Bottomleft\n\n\n\n\nThe stars and planet plots combined\n\n\n\n\n\nLooking good! Almost done! Now we can pluck() each of our plots out and save them to individual objects! Because thereâ€™s only four of them, Iâ€™ll just copy and paste that code because this is Rtistry and itâ€™s totally OK to be lazy. Itâ€™s your work. Itâ€™s your aRt . Do what you want!\n\n\n## Plucking out all the individual plots===\nTopleft &lt;- Combined_plots %&gt;% pluck(\"Topleft\")\nTopright &lt;- Combined_plots %&gt;% pluck(\"Topright\")\nBottomright &lt;- Combined_plots %&gt;% pluck(\"Bottomright\")\nBottomleft &lt;- Combined_plots %&gt;% pluck(\"Bottomleft\")\n\n\nFinally, we use pacthworkâ€™s layout syntax to combine these plots into one image:\n\n\n# Final output construction with patchwork functions====\nPlanet_Quad &lt;- (Topleft + Topright) / (Bottomleft + Bottomright)\n\n# View the piece#\nPlanet_Quad\n\n\nAnd voila! We have our finished piece! Iâ€™ve noticed that sometimes patchwork may render in some borders around these images if ggsave() is used. In these cases, I just export using the Export button in the RStudio IDE."
  },
  {
    "objectID": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#rainbow-rose-art-example",
    "href": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#rainbow-rose-art-example",
    "title": "Thinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.",
    "section": "Rainbow Rose â€“ aRt Example",
    "text": "Rainbow Rose â€“ aRt Example\n \n\n\n\nRainbow Rose\n\n\n\n\nFinally, weâ€™re at our last example! Rainbow Rose is an Rtistry piece that showcases one way trigonometric functions can be used to create cool results. This Rtistry piece was created from a beautiful accident when I mistyped some code while attempting to draw a circle from scratch in ggplot (yes, the geom_circle() function from ggforce exists, but I was trying to improve my manual ggplot skills ğŸ¤·ğŸ¾ï¸).\n\nTo start out, we need to set up some specifications that will alter how the data is plotted onto ggplotâ€™s Cartesian coordinate system. This includes calculating the â€œthetaâ€(angles) of our intended circle, the number of divisions/data points we want in the dataset â€œnâ€, and the radial setting we wish to have for the visual. Because we want to give an effect that starts from the center of the image, we set the radial setting, â€œrâ€ to a vector that spans from 1 to our â€œnâ€ value.\n\n\n# Library Load-In====\nlibrary(tidyverse) # For everything data\n\n# Setting parameters to prep ggplot to plot data in a \"circular\" fashion on the Cartesian coordinate system====\n\n## Angle \"slices\"/ Sine/Cosine Frequency====\ntheta &lt;- seq(0, 40*pi, length = 100) \n\n## Number of divisions/rows in the data wanted====\nn &lt;- 500\n\n## \"Radial\" setting of the \"circle\" to create \"n\" different marks====\nr = 1:n\n\n\nNext, Iâ€™ll use one of my favorite color palettes that I found for one of my #TidyTuesday submissions. Iâ€™ll store them in a vector simply called â€œcolorsâ€:\n\n\n## Setting up the custom color palette====\ncolors &lt;- c(\"#af3918\", \"#a21152\", \"#822b75\",\"#612884\",\"#154baf\",\n            \"#0b82b9\", \"#277e9d\",\"#488e35\",\"#e3a934\",\"#b2336a\")\n\n\nNow Iâ€™ll create a simple data frame. Iâ€™ll create my x and y variables using the cos() and sin() functions respectively:\n\n\n# Placing everything into a dataset====\ndata &lt;- tibble(x = cos(theta)*r,\n               y = sin(theta)*r)\n\n\nFinally, weâ€™ll put everything together. Using geom_path() on this dataset and passing our colors vector into it creates our Rainbow Rose!\n\n\n# Pulling it all together====\nRainbow_Rose &lt;- data %&gt;%\n  ggplot(aes(x = x, y = y, color = color))+\n  geom_path(color = rep(colors, each = n/10), size = 1)+\n  theme_void()+\n  theme(legend.position = \"none\",\n        panel.background = element_rect(fill = \"black\"))\n\n# View it #\nRainbow_Rose\n\n\n\n\nRainbow Rose - Finished\n\n\n\n\n\nMesmerizing! Play around and investigate the options used to try and understand how/why ggplot generated the data this way.\nFor example, if we change geom_path() to geom_line() we get this:\n\n\n\n\n\n\nRainbow Rose with geom_line() instead of geom_path()\n\n\n\n\n\nStill pretty, but a completely different piece! Earlier in the article I mentioned the difference between geom_path() and geom_line() . Given their differences, does it make sense why this version looks this way? These are just some of the questions you can think about and ask yourself while youâ€™re on your Rtistry journey!"
  },
  {
    "objectID": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#theres-a-package-for-that",
    "href": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#theres-a-package-for-that",
    "title": "Thinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.",
    "section": "Thereâ€™s a Package for That",
    "text": "Thereâ€™s a Package for That\nIf you read all of this and still feel intimidated, thatâ€™s OK. You can still try to get into Rtistry with some of the following packages: \n\naRtsy developed by Koen Derks â€œAims to make generative aRt accessible to the general public in a straightforward and standardized mannerâ€\nAmbient developed by Thomas Lin Pedersen and Jordan Peck(FastNoise) â€œâ€¦is a an R package that provides access to the FastNoise C++ library for generating noise.â€\nGgvoroni developed by Robert Garrett and Thomas Fisher â€œWith ggvoronoi we can easily draw Voronoi diagram heatmaps, with help from packages deldir and ggplot2.â€\ncontouR developed by Ijeamaka Anyene â€œcontouR is a package that is a wraparound for ggplot2::geom_contour() to use for generative aRt .â€\nJasmines developed by Danielle Navarro â€œThe jasmines package is what Danielle uses to make a lot of her generative artwork with R. Internally it relies heavily on the ambient package, and you may need to install the developer version of ambient to make it work.â€"
  },
  {
    "objectID": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#final-remarks",
    "href": "post/thinking-outside-the-grid/thinking-outside-the-grid.html#final-remarks",
    "title": "Thinking Outside The Grid - A â€œbare bonesâ€ intro to Rtistry concepts in R using ggplot.",
    "section": "Final Remarks",
    "text": "Final Remarks\nThis concludes The Tidy Trekker Intro to Data Art post! I really hope that those of you who are just trying to start out in Rtistry found this to be useful. While the basics content truly is basic, it really is a good chunk of the foundation needed to eventually progress into more complex generative aRt . Sometimes it can be difficult to disseminate the how-tos or guides for a creative process. As you saw with the Rainbow Rose piece, sometimes aRt can be created by accident. Those accidents can only be unique to you. The best way to improve your Rtistry skills is to just jump in and play. Use the time to zone out, relax, and engage with data in a way you may not have before.\nHave you started your Rtistry journey? Do you think some crucial basics were left out of this post? Feel free to contact me directly! Respectful discourse is always welcome!"
  },
  {
    "objectID": "post/where-have-i-been/where-have-i-been.html",
    "href": "post/where-have-i-been/where-have-i-been.html",
    "title": "Where Have I Been?",
    "section": "",
    "text": "So, it has been a good five months since I last made a post on The Tidy Trekker. I can assure you that I am alive and kicking! Though I know I do not have any obligations or posting schedules, I would prefer not to go that long without posting anything at all. I know itâ€™ll happen sometimes, but I love adding content here and interacting with others about it over on Twitter (you can follow me there if you havenâ€™t already, itâ€™s a good time! Lots of data, lots of memes, and lots of R stuff).\nI just wanted to make a more low-key, short, and personal post to take a moment, stop, and say hello to any readers out there. How are you guys? How is the pandemic treating you on your end of the universe? Well, for me, itâ€™s been an interesting challenge, and by â€œinterestingâ€ I mean kind of sucky.\n\n\n\n\n\n\nLife sucks sometimes. Itâ€™s OK to say it.\n\n\n\n\n\nI had a lot of challenges, setbacks, and downright painful things thrown at me this year. These things threw me off track for a bit. While Iâ€™m not ready to talk about everything, I can touch on a few things. My last Tidy Trekker post was in April. Around this time, I was finishing up my TarotreadR app for the Shiny contest this year. I actually just wrote up a post about that experience as it was the first Shiny app I ever made. You can read more about that here if youâ€™d like.\nDuring all of this, I was also hospitalized for a bit but then was able to go to Rochester (NY) for my birthday when I got out. When I got back, my efforts moved towards wrapping up some projects at work as I was preparing to leave the country in August for my wedding anniversary. While I was doing that, I finally landed a second job as a contracted Data Analyst (finally, some good stuff)!\nI eventually got through work, and a whole bunch of other responsibilities, to finally receive my reward: an anniversary trip to Mexico. When I stepped foot onto the resort, I nearly wept. I was so grateful and privileged to be able to just escape everything for a bit given the year Iâ€™d been having.\n\n\n\n\n\n\n\n\nOne of the gifts my husband gave me in Mexico.\n\n\n\n\n\nBut now vacation is over and Iâ€™m back in reality. Having the time away was really important for me to think about the next steps Iâ€™d like to consider for my career. Currently, Iâ€™m still in love with my position and have been learning so much and am so grateful for it. Moving forward, Iâ€™d like to focus more on a few things:\n\n\nStrengthening my knowledge of statistical methodology\nWorking on improving the efficiency of my programming in general\nGetting familiar with Python and SQL\nTrying to complete a tiny ML project before the year is up\n\n\nI plan to use The Tidy Trekker to document these endeavors, but given that I am starting a contracted position, I will have to play everything by ear of course.\nHow has your 2021 been so far? Howâ€™s life? Got any updates you want to share? Feel free to contact me directly! Respectful discourse is always welcomed!"
  },
  {
    "objectID": "talks/collages_and_patterns/collages_and_patterns.html#description",
    "href": "talks/collages_and_patterns/collages_and_patterns.html#description",
    "title": "Collages and Patterns: Making Art in R",
    "section": "Description",
    "text": "Description\n\nThis talk will briefly introduce the concept of creating generative art in R (Rtistry) but then focus on a concept that seems to allude most: how to create the data required for generative art. While knowledge of generative art is not required to attend, this talk does assume that attendees are comfortably familiar with the tidyverse, especially ggplot2. Attendees will learn some basic concepts involved in creating collages and patterns in ggplot2 by focusing on the logic required to generate randomized and non-randomized data sets for their rtistry! All scripts, slides, and talk materials will be available for use and review at the start of the talk."
  },
  {
    "objectID": "talks/collages_and_patterns/collages_and_patterns.html#slides",
    "href": "talks/collages_and_patterns/collages_and_patterns.html#slides",
    "title": "Collages and Patterns: Making Art in R",
    "section": "Slides",
    "text": "Slides\nThe slides for the presentation is available on GitHub here."
  },
  {
    "objectID": "talks/collages_and_patterns/collages_and_patterns.html#recorded-presentation",
    "href": "talks/collages_and_patterns/collages_and_patterns.html#recorded-presentation",
    "title": "Collages and Patterns: Making Art in R",
    "section": "Recorded Presentation",
    "text": "Recorded Presentation\nThis presentation was recorded and is now accessible on YouTube here"
  },
  {
    "objectID": "talks/collages_and_patterns/collages_and_patterns.html#talk-materials-and-github-repository",
    "href": "talks/collages_and_patterns/collages_and_patterns.html#talk-materials-and-github-repository",
    "title": "Collages and Patterns: Making Art in R",
    "section": "Talk Materials and GitHub Repository",
    "text": "Talk Materials and GitHub Repository\nThis talk has a supplemental GitHub repository that can be accessed here"
  },
  {
    "objectID": "talks/functions_in_rtistry/functions_for_rtistry.html#description",
    "href": "talks/functions_in_rtistry/functions_for_rtistry.html#description",
    "title": "Making Functions For Rtistry",
    "section": "Description",
    "text": "Description\n\nWhile you donâ€™t have to be an R expert to attend, some of the material expects that the viewer has a basic understanding of using the ggplot2 package and functional programming basics in R. This talk will go over the benefits of using functions from Base R and the Purrr package, different types of functions that can be created for generative art, and more. The workshop will end with a live coding rtistry session that viewers can follow along with. The code created in the live coding session will be available shortly after the session on GitHub."
  },
  {
    "objectID": "talks/functions_in_rtistry/functions_for_rtistry.html#slides",
    "href": "talks/functions_in_rtistry/functions_for_rtistry.html#slides",
    "title": "Making Functions For Rtistry",
    "section": "Slides",
    "text": "Slides\nThe slides for the presentation is available on GitHub here."
  },
  {
    "objectID": "talks/functions_in_rtistry/functions_for_rtistry.html#recorded-presentation",
    "href": "talks/functions_in_rtistry/functions_for_rtistry.html#recorded-presentation",
    "title": "Making Functions For Rtistry",
    "section": "Recorded Presentation",
    "text": "Recorded Presentation\nThis presentation was recorded but the link has not been provided by R-Ladies Johannesburg yet."
  },
  {
    "objectID": "talks/functions_in_rtistry/functions_for_rtistry.html#talk-materials-and-github-repository",
    "href": "talks/functions_in_rtistry/functions_for_rtistry.html#talk-materials-and-github-repository",
    "title": "Making Functions For Rtistry",
    "section": "Talk Materials and GitHub Repository",
    "text": "Talk Materials and GitHub Repository\nThis talk has a supplemental GitHub repository that can be accessed here"
  },
  {
    "objectID": "talks/making_a_case/making_a_case.html#description",
    "href": "talks/making_a_case/making_a_case.html#description",
    "title": "Itâ€™s All About Perspective: Making A Case for Generative Art",
    "section": "Description",
    "text": "Description\n\nâ€œItâ€™s All About Perspectiveâ€ is a retrospective journey that aims to invite participants to learn about generative art while focusing on â€œwhyâ€ people should create it and its potential place in Data Science. This talk is suitable for all disciplines and artistic abilities. This talk aims to expand the participantâ€™s perspective on generative art with the following concepts:\n\n\nWhat is generative art and how can it be created in R or Python\nJustifications for generative art within Data Science\nExamples of programming skills that are transferable between generative art and pragmatic data science projects"
  },
  {
    "objectID": "talks/making_a_case/making_a_case.html#slides",
    "href": "talks/making_a_case/making_a_case.html#slides",
    "title": "Itâ€™s All About Perspective: Making A Case for Generative Art",
    "section": "Slides",
    "text": "Slides\nThe slides for the presentation is available on GitHub here."
  },
  {
    "objectID": "talks/making_a_case/making_a_case.html#recorded-presentation",
    "href": "talks/making_a_case/making_a_case.html#recorded-presentation",
    "title": "Itâ€™s All About Perspective: Making A Case for Generative Art",
    "section": "Recorded Presentation",
    "text": "Recorded Presentation\nThis presentation was recorded and is now accessible on YouTube here"
  },
  {
    "objectID": "talks/making_a_case/making_a_case.html#talk-materials-and-github-repository",
    "href": "talks/making_a_case/making_a_case.html#talk-materials-and-github-repository",
    "title": "Itâ€™s All About Perspective: Making A Case for Generative Art",
    "section": "Talk Materials and GitHub Repository",
    "text": "Talk Materials and GitHub Repository\nThis talk has a supplemental GitHub repository that can be accessed here"
  },
  {
    "objectID": "talks/please_let_me_merge/please_let_me_merge.html#description",
    "href": "talks/please_let_me_merge/please_let_me_merge.html#description",
    "title": "Please Let Me Merge Before I Start Crying: And Other Things Iâ€™ve Said At The Git Terminal",
    "section": "Description",
    "text": "Description\n\nJust like novice drivers can learn to confidently (and safely!) merge onto (seemingly) intimidating highways, those new to collaborating with Git can also conquer Git merges with some exposure and preparation.\n\nThis talk will go over:\n\nDifferent ways R users can interact with Git\nWhat Git merges and Git merge conflicts are\nReal-life examples of Git merges\nAdvice on resolving Git merges\nSuggestions for cleaner workflows to promote better Git merges"
  },
  {
    "objectID": "talks/please_let_me_merge/please_let_me_merge.html#slides",
    "href": "talks/please_let_me_merge/please_let_me_merge.html#slides",
    "title": "Please Let Me Merge Before I Start Crying: And Other Things Iâ€™ve Said At The Git Terminal",
    "section": "Slides",
    "text": "Slides\nThe slides for the presentation is available on GitHub here."
  },
  {
    "objectID": "talks/please_let_me_merge/please_let_me_merge.html#recorded-presentation",
    "href": "talks/please_let_me_merge/please_let_me_merge.html#recorded-presentation",
    "title": "Please Let Me Merge Before I Start Crying: And Other Things Iâ€™ve Said At The Git Terminal",
    "section": "Recorded Presentation",
    "text": "Recorded Presentation\nThis presentation was recorded and is now accessible on YouTube here."
  },
  {
    "objectID": "talks/please_let_me_merge/please_let_me_merge.html#talk-materials-and-github-repository",
    "href": "talks/please_let_me_merge/please_let_me_merge.html#talk-materials-and-github-repository",
    "title": "Please Let Me Merge Before I Start Crying: And Other Things Iâ€™ve Said At The Git Terminal",
    "section": "Talk Materials and GitHub Repository",
    "text": "Talk Materials and GitHub Repository\nThis talk has a supplemental GitHub repository that can be accessed here"
  }
]